<!DOCTYPE html PUBLIC "-//IETF//DTD HTML//EN"><html><head><title>SIGGRAPH 2023 Papers</title></head><body>
<center>
<h1><a href="https://s2023.siggraph.org/">SIGGRAPH 2023</a> papers on the web</h1>
</center>

<p>
Page maintained by <a href="http://kesen.huang.googlepages.com/">Ke-Sen Huang</a>. 
If you have additions or changes, send an <a href="mailto:kesen.huang@gmail.com?subject=SIG%20Papers%202023">e-mail</a>.
</p>

<p>
<b>Information here is provided with the permission of the ACM</b>

</p><p>
Note that when possible I link to the page containing the link to the actual PDF or PS of the preprint.  
I prefer this as it gives some context to the paper and avoids possible copyright problems with direct linking.  
Thus you may need to search on the page to find the actual document.
</p>

<p>
<b>ACM Digital Library:</b>
	ACM Transactions on Graphics (TOG) Volume 42, Issue 4 (July 2023) Proceedings of ACM SIGGRAPH 2023
</p>

<p>
<a href="http://www.acm.org/"><img alt="ACM DOI" src="ACM-big.png" border="0" width="48" height="48"></a> <b>ACM Digital Library (DOI)</b> Link for the paper &nbsp;
<img alt="Paper Abstract" src="Abstract-big.png" border="0" width="48" height="48"> <b>Paper Abstract</b>	 &nbsp;
<a href="http://iconka.com"><img alt="Author version" src="Preprint-big.png" border="0" width="48" height="48"></a> <b>Author Preprint</b> &nbsp;
<img alt="Paper Video" src="Video-big.png" border="0" width="48" height="48"> <b>Paper Video</b> &nbsp;

</p><p>
<img alt="Paper Presentation" src="Ppt-big.png" border="0" width="48" height="48"> <b>Paper Presentation</b> &nbsp;
<img alt="Paper Images" src="Images-big.png" border="0" width="48" height="48"> <b>Paper Images</b> &nbsp;
<img alt="Paper Data" src="Data-big.png" border="0" width="48" height="48"> <b>Paper Data</b>  &nbsp;
<img alt="Demo Program or Source Code" src="Code-big.png" border="0" width="48" height="48"> <b>Demo Program or Source Code</b>	 
<img alt="Related Links" src="URL-big.png" border="0" width="48" height="48"> <b>Related Links</b>
	 

<!--

<h2></h2>

<dt><B></B>
	<a href=""><img alt="ACM DOI" src="ACM.png" border="0"></a>
	<a href=""><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href=""><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href=""><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href=""><img alt="Paper Presentation" src="Ppt.png" border="0"></a>
	<a href=""><img alt="Paper Images" src="Images.png" border="0"></a>
	<a href=""><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href=""><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	<a href=""><img alt="Related Links" src="URL.png" border="0"></a>
	<img src="new.gif"></dt>
<dd>
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><B></B>
	<a href=""><img alt="ACM DOI" src="ACM.png" border="0"></a>
	<a href=""><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href=""><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href=""><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href=""><img alt="Paper Presentation" src="Ppt.png" border="0"></a>
	<a href=""><img alt="Paper Images" src="Images.png" border="0"></a>
	<a href=""><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href=""><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	<a href=""><img alt="Related Links" src="URL.png" border="0"></a>
	(<B>TOG Paper</B>)
	<img src="new.gif"></dt>
<dd>
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

-->
</p><p>
<a href="sig2023-changelog.html">Changelog</a>
</p>

<h2>A Material World</h2>
<dl>

<dt><b>A Sparse Non-parametric BRDF Model</b>
	<a href="https://hal.science/hal-03654734/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://hal.science/hal-03654734/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://liu.se/en/employee/tanto11">Tanaboon Tongbuasirilai</a>, 
<a href="https://liu.se/en/employee/jonun48">Jonas Unger</a> 
(<a href="https://liu.se/en">Linkoping University</a>), 
<a href="https://people.rennes.inria.fr/Christine.Guillemot/">Christine Guillemot</a> 
(<a href="https://www.inria.fr/en">INRIA</a>), 
<a href="https://liu.se/en/employee/miaeh27">Ehsan Miandji</a> 
(<a href="https://liu.se/en">Linkoping University</a>)
</dd>

<dt><b>SpongeCake: A Layered Microflake Surface Appearance Model</b>
	<a href="https://wangningbei.github.io/2022/SpongeCake.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://wangningbei.github.io/2022/SpongeCake.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://wangningbei.github.io/">Beibei Wang</a>* 
(<a href="https://en.nankai.edu.cn/">Nankai University</a> and <a href="https://english.njust.edu.cn/">Nanjing University of Science and Technology</a>), 
Wenhua Jin* 
(<a href="https://english.njust.edu.cn/">Nanjing University of Science and Technology</a>),
<a href="http://www.miloshasan.net/">Milos Hasan</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://sites.cs.ucsb.edu/~lingqi/">Ling-Qi Yan</a> 
(<a href="https://www.ucsb.edu/">University of California, Santa Barbara</a>)
*Authors contributed equally.
</dd>

<dt><b>A Practical Wave Optics Reflection Model for Hair and Fur</b>
	<a href="https://mandyxmq.github.io/research/wavefiber_3d.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://mandyxmq.github.io/research/wavefiber_3d.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://mandyxmq.github.io/research/wavefiber_3d.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://mandyxmq.github.io/">Mengqi (Mandy) Xia</a> 
(<a href="https://www.cornell.edu/">Cornell University</a> and <a href="https://www.epfl.ch/en/">EPFL</a>), 
<a href="https://www.graphics.cornell.edu/~bjw/">Bruce Walter</a> 
(<a href="https://www.cornell.edu/">Cornell University</a>), 
Christophe Hery, 
Olivier Maury
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a>), 
<a href="https://michielssen.engin.umich.edu/">Eric Michielssen</a> 
(<a href="https://umich.edu/">University of Michigan</a>), 
<a href="https://www.cs.cornell.edu/~srm/">Steve Marschner</a> 
(<a href="https://www.cornell.edu/">Cornell University</a>)

</dd>

<dt><b>Microfacet theory for non-uniform heightfields</b>
	<a href="https://research.nvidia.com/labs/rtr/microfacet-theory-non-uniform-heightfields/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/rtr/microfacet-theory-non-uniform-heightfields/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="http://www.eugenedeon.com/">Eugene d'Eon</a>, 
<a href="https://research.nvidia.com/person/benedikt-bitterli">Benedikt Bitterli</a>, 
<a href="https://research.nvidia.com/person/andrea-weidlich">Andrea Weidlich</a>, 
<a href="https://research.nvidia.com/person/tizian-zeltner">Tizian Zeltner</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>)
</dd>

<dt><b>Generating Procedural Materials From Text or Image Prompts</b>
	<a href="https://yiweihu.netlify.app/uploads/hu2023gen/project.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://yiweihu.netlify.app/uploads/hu2023gen/project.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://yiweihu.netlify.app/">Yiwei Hu</a> 
(<a href="https://www.yale.edu/">Yale University</a> and <a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://research.adobe.com/person/paul-guerrero/">Paul Guerrero</a>, 
<a href="http://www.miloshasan.net/">Milos Hasan</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://graphics.cs.yale.edu/people/holly-rushmeier">Holly Rushmeier</a> 
(<a href="https://www.yale.edu/">Yale University</a>), 
<a href="https://valentin.deschaintre.fr/">Valentin Deschaintre</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>)
</dd>

<dt><b>A Realistic Surface-based Cloth Rendering Model</b>
	<a href="http://junqiuzhu.com/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://junqiuzhu.com/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://junqiuzhu.com/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="http://junqiuzhu.com/">Junqiu Zhu</a> 
(<a href="https://www.ucsb.edu/">University of California, Santa Barbara</a>), 
<a href="http://giga.cps.unizar.es/~ajarabo/">Adrian Jarabo</a>, 
<a href="http://www.aliagabadal.com/">Carlos Aliaga</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs Research</a>), 
<a href="https://sites.cs.ucsb.edu/~lingqi/">Ling-Qi Yan</a> 
(<a href="https://www.ucsb.edu/">University of California, Santa Barbara</a>), 
<a href="https://mattchiangvfx.com/">Matt Jen-Yuan Chiang</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs Research</a>)
</dd>

</dl>

<h2>Geometric Optimization</h2>
<dl>

<dt><b>Geometric Optimisation via Spectral Shifting</b>
	<a href="https://romeric.github.io/goss.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://romeric.github.io/goss.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://romeric.github.io/goss.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://romeric.github.io/index.html">Roman Poya</a> 
(<a href="https://www.sw.siemens.com/en-US/">Siemens Digital Industries Software</a>), 
Rogelio Ortigosa 
(<a href="https://www.upct.es/">Technical University of Cartagena</a>), 
<a href="https://www.tkim.graphics/">Theodore Kim</a> 
(<a href="https://www.yale.edu/">Yale University</a>)
</dd>

<dt><b>Winding Numbers on Discrete Surfaces</b>
	<a href="https://markjgillespie.com/Research/WNoDS/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://markjgillespie.com/Research/WNoDS/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://nzfeng.github.io/">Nicole Feng</a>, 
<a href="https://markjgillespie.com/">Mark Gillespie</a>, 
<a href="https://www.cs.cmu.edu/~kmcrane/">Keenan Crane</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
</dd>

<dt><b>Flexible Isosurface Extraction for Gradient-based Mesh Optimization</b>
	<a href="https://research.nvidia.com/labs/toronto-ai/flexicubes/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/toronto-ai/flexicubes/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/toronto-ai/flexicubes/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="http://www.cs.toronto.edu/~shenti11/">Tianchang Shen</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://research.nvidia.com/person/jacob-munkberg">Jacob Munkberg</a>, 
<a href="https://research.nvidia.com/person/jon-hasselgren">Jon Hasselgren</a>, 
<a href="https://kangxue.org/">Kangxue Yin</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="http://www.cs.toronto.edu/~zianwang/">Zian Wang</a>, 
<a href="https://www.cs.toronto.edu/~wenzheng/">Wenzheng Chen</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://zgojcic.github.io/">Zan Gojcic</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://www.utoronto.ca/">University of Toronto</a>), 
<a href="https://nmwsharp.com/">Nicholas Sharp</a>, 
<a href="https://www.cs.toronto.edu/~jungao/">Jun Gao</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>) 
</dd>

<dt><b>Topology Driven Approximation to Rational Surface-surface Intersection via Interval Algebraic Topology Analysis</b>
	</dt>
<dd>
<a href="http://www.mmrc.iss.ac.cn/~jcheng/">Jin-San Cheng</a>, 
Bingwei Zhang 
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a> and <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>), 
Yikun Xiao, 
<a href="http://www.cad.zju.edu.cn/home/liming/">Ming Li</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>)
</dd>

<dt><b>A Fast Geometric Multigrid Method for Curved Surfaces</b>
	<a href="https://rubenwiersma.nl/gravomg"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://rubenwiersma.nl/gravomg"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://graphics.tudelft.nl/gravo_mg"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://rubenwiersma.nl/">Ruben Timotheues Wiersma</a>* 
(<a href="http://www.tudelft.nl/">Delft University of Technology</a>), 
<a href="http://graphics.tudelft.nl/ahmad-nasikun/">Ahmad Nasikun</a>* 
(<a href="https://ugm.ac.id/">Universitas Gadjah Mada</a> and <a href="http://www.tudelft.nl/">Delft University of Technology</a>) 
<a href="https://graphics.tudelft.nl/~eisemann/">Elmar Eisemann</a>, 
<a href="https://graphics.tudelft.nl/~klaus/">Klaus Hildebrandt</a> 
(<a href="http://www.tudelft.nl/">Delft University of Technology</a>) 
* both authors contributed equally
</dd>

<dt><b>A Convex Optimization Framework for Regularized Geodesic Distances</b>
	<a href="https://arxiv.org/abs/2305.13101"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.13101"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Michal Edelstein
(<a href="http://www.technion.ac.il/en">Technion - Israel Institute of Technology</a>), 
<a href="https://www.ndguillen.com/">Nestor Guillen</a> 
(<a href="https://www.txst.edu/">Texas State University</a>), 
<a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>), 
<a href="https://mirela.net.technion.ac.il/">Mirela Ben-Chen</a> 
(<a href="http://www.technion.ac.il/en">Technion - Israel Institute of Technology</a>)
</dd>

</dl>

<h2>Motion Recipes and Simulation</h2>
<dl>

<dt><b>Anatomically Detailed Simulation of Human Torso</b>
	<a href="https://tml.stanford.edu/publications/2023/anatomically-detailed-simulation-human-torso"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://tml.stanford.edu/publications/2023/anatomically-detailed-simulation-human-torso"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://tml.stanford.edu/publications/2023/anatomically-detailed-simulation-human-torso"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://tml.stanford.edu/people/seunghwan-lee">Seunghwan Lee</a>, 
<a href="https://tml.stanford.edu/people/yifeng-jiang">Yifeng Jiang</a>, 
<a href="https://tml.stanford.edu/people/karen-liu">C. Karen Liu</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>)
</dd>

<dt><b>HACK: Learning a Parametric Head and Neck Model for High-fidelity Animation</b>
	<a href="https://arxiv.org/abs/2305.04469"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.04469"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=0TCW0lPgK0E"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/ZoneLikeWonderland/HACK-Model"><img alt="Paper Data" src="Data.png" border="0"></a>
	</dt>
<dd>
Longwen Zhang*, 
Zijun Zhao*, 
Xinzhou Cong*, 
Qixuan Zhang 
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a> and <a href="https://deemos.com/">Deemos Technology Co., Ltd.</a>), 
Shuqi Gu, 
Yuchong Gao, 
Rui Zheng 
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a>), 
Wei Yang 
(<a href="http://english.hust.edu.cn/">Huazhong University of Science and Technology</a>), 
Lan Xu, 
<a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54832/page.htm">Jingyi Yu</a> 
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a>) 
* Equal contributions
</dd>

<dt><b>Bidirectional GaitNet: A Bidirectional Prediction Model of Human Gait and Anatomical Conditions</b>
	<a href="https://sites.google.com/mrl.snu.ac.kr/jungnam/home"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://youtu.be/_Ey8VvKIgAM"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://sites.google.com/mrl.snu.ac.kr/jungnam/home">Jungnam Park</a> 
(<a href="http://snu.ac.kr/">Seoul National University</a>), 
Moon Seok Park 
(<a href="https://www.snubh.org/dh/en/">Seoul National University Bundang Hospital</a>), 
<a href="https://mrl.snu.ac.kr/~jehee/">Jehee Lee</a> 
(<a href="https://kr.ncsoft.com/kr/index.do">NCsoft</a> and <a href="http://snu.ac.kr/">Seoul National University</a>), 
<a href="https://sites.google.com/view/jungdam/">Jungdam Won</a> 
(<a href="http://snu.ac.kr/">Seoul National University</a>)
</dd>

<dt><b>Acting as Inverse Inverse Planning</b>
	<a href="https://arxiv.org/abs/2305.16913"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.16913"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/kach/acting-as-inverse-inverse-planning"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://cs.stanford.edu/~kach/">Kartik Chandra</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>), 
<a href="https://cseweb.ucsd.edu/~tzli/">Tzu-Mao Li</a> 
(<a href="https://ucsd.edu/">UC San Diego</a>), 
<a href="http://web.mit.edu/cocosci/josh.html">Joshua Tenenbaum</a>, 
<a href="http://people.csail.mit.edu/jrk/">Jonathan Ragan-Kelley</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>)
</dd>

<dt><b>PoseVocab: Learning Joint-structured Pose Embeddings for Human Avatar Modeling</b>
	<a href="https://lizhe00.github.io/projects/posevocab/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://lizhe00.github.io/projects/posevocab/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://lizhe00.github.io/projects/posevocab/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/lizhe00/posevocab"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://lizhe00.github.io/">Zhe Li</a>, 
<a href="https://zhengzerong.github.io/">Zerong Zheng</a>, 
Yuxiao Liu,
Boyao Zhou,
<a href="http://www.liuyebin.com/">Yebin Liu</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>) 
</dd>

<dt><b>DARAM: Dynamic Avatar-human Motion Remapping Technique for Realistic Virtual Stair Ascending Motions</b>
	<a href="https://ssw03270.github.io/2023-05/t1"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://ssw03270.github.io/2023-05/t1"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
SooBin Lim, 
<a href="https://ssw03270.github.io/">SeungWon Seo</a>, 
<a href="https://siamiz88.github.io/">HyeongYeop Kang</a> 
(<a href="https://www.khu.ac.kr/eng/main/index.do">Kyung Hee University</a>) 
</dd>

</dl>

<h2>Character Animation: Knowing What To Do With Your Hands</h2>
<dl>

<dt><b>GestureDiffuCLIP: Gesture Diffusion Model With CLIP Latents</b>
	<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://pku-mocca.github.io/GestureDiffuCLIP-Page/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://aubrey-ao.github.io/">Tenglong Ao</a>, 
Zeyi Zhang 
(<a href="https://english.pku.edu.cn/">Peking University</a>), 
<a href="https://libliu.info/">Libin Liu</a> 
(<a href="https://english.pku.edu.cn/">Peking University</a> and National Key Lab of General AI)
</dd>

<dt><b>Bodyformer: Semantics-guided 3D Body Gesture Synthesis With Transformer</b>
	<a href="https://i.cs.hku.hk/~taku/publication.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Kunkun Pang
(<a href="http://www.gdas.gd.cn/en/">Guangdong Academy of Sciences</a>), 
Dafei Qin, 
<a href="https://evelynfan.github.io/">Yingruo Fan</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a>), 
Julian Habekost
(<a href="https://www.ed.ac.uk/">The University of Edinburgh</a>), 
<a href="https://sites.google.com/view/takaaki-shiratori/home">Takaaki Shiratori</a> 
(<a href="https://about.meta.com/realitylabs/">Reality Labs Research at Meta</a>), 
<a href="https://nii-yamagishilab.github.io/author/junichi-yamagishi/">Junichi Yamagishi</a> 
(<a href="https://www.nii.ac.jp/en/">National Institute of Informatics</a>), 
<a href="https://homepages.inf.ed.ac.uk/tkomura/">Taku Komura</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a>) 
</dd>

<dt><b>Listen, Denoise, Action! Audio-Driven Motion Synthesis with Diffusion Models</b>
	<a href="https://www.speech.kth.se/research/listen-denoise-action/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.speech.kth.se/research/listen-denoise-action/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.speech.kth.se/research/listen-denoise-action/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.kth.se/profile/simonal?l=en">Simon Alexanderson</a> 
(<a href="https://www.kth.se/en">KTH Royal Institute of Technology</a> and <a href="https://www.motorica.ai/">motorica.ai</a>), 
<a href="https://nagyrajmund.github.io/">Rajmund Nagy</a>, 
<a href="https://www.kth.se/profile/beskow?l=en">Jonas Beskow</a> 
(<a href="https://www.kth.se/en">KTH Royal Institute of Technology</a>), 
<a href="https://people.kth.se/~ghe/">Gustav Eje Henter</a> 
(<a href="https://www.kth.se/en">KTH Royal Institute of Technology</a> and <a href="https://www.motorica.ai/">motorica.ai</a>)
</dd>

<dt><b>How Important Are Detailed Hand Motions for Communication for a Virtual Character Through the Lens of Charades?</b>
	<a href="https://research.birmingham.ac.uk/en/publications/how-important-are-detailed-hand-motions-for-communication-for-a-v"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.birmingham.ac.uk/en/publications/how-important-are-detailed-hand-motions-for-communication-for-a-v"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Alex Adkins 
(<a href="https://www.clemson.edu/">Clemson University</a>), 
<a href="https://alinen.net/">Aline Normoyle</a> 
(<a href="https://www.cs.brynmawr.edu/">Bryn Mawr College</a>), 
Lorraine Lin, 
Yu Sun 
(<a href="https://www.clemson.edu/">Clemson University</a>), 
<a href="http://yutingye.info/">Yuting Ye</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs Research</a>), 
<a href="https://research.birmingham.ac.uk/en/persons/max-di-luca">Massimiliano Di Luca</a> 
(<a href="https://www.birmingham.ac.uk/index.aspx">University of Birmingham</a> and <a href="https://about.meta.com/realitylabs/">Meta Reality Labs Research</a>), 
Sophie Jorg
(<a href="https://www.clemson.edu/">Clemson University</a>) 
</dd>

<dt><b>Contact Edit: Artist Tools for Intuitive Modeling of Hand-Object Interactions</b>
	<a href="https://nzfeng.github.io/research/ContactEdit/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://nzfeng.github.io/research/ContactEdit/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.andrew.cmu.edu/user/aslakshm/">Arjun S. Lakshmipathy</a>, 
<a href="https://nzfeng.github.io/">Nicole Feng</a>, 
Yu Xi Lee, 
<a href="https://www.momahler.com/">Moshe Mahler</a>, 
<a href="http://graphics.cs.cmu.edu/nsp/index.html">Nancy S. Pollard</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
</dd>

<dt><b>Synthesizing Dexterous Nonprehensile Pregrasp for Ungraspable Objects</b>
	<a href="https://tml.stanford.edu/publications/2023/synthesizing-dexterous-nonprehensile-pregrasp-ungraspable-objects"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://tml.stanford.edu/publications/2023/synthesizing-dexterous-nonprehensile-pregrasp-ungraspable-objects"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/Ericcsr/contact_planning_dexterous_hand"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Sirui Chen
(<a href="https://www.hku.hk/">The University of Hong Kong</a>), 
<a href="https://tml.stanford.edu/people/albert-wu">Albert Wu</a>, 
<a href="https://tml.stanford.edu/people/karen-liu">C. Karen Liu</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>)
</dd>

</dl>

<h2>Geometric Abstractions: Not Just for Cubists</h2>
<dl>

<dt><b>ShapeCoder: Discovering Abstractions for Visual Programs From Unstructured Primitives</b>
	<a href="https://github.com/rkjones4/shapecoder"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://rkjones4.github.io/">R. Kenny Jones</a> 
(<a href="https://www.brown.edu/">Brown University</a>), 
<a href="https://research.adobe.com/person/paul-guerrero/">Paul Guerrero</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://www0.cs.ucl.ac.uk/staff/n.mitra/">Niloy J. Mitra</a> 
(<a href="https://research.adobe.com/">Adobe Research</a> and <a href="http://www.ucl.ac.uk/">University College London</a>), 
<a href="https://dritchie.github.io/">Daniel Ritchie</a> 
(<a href="https://www.brown.edu/">Brown University</a>) 
</dd>

<dt><b>The Visual Language of Fabrics</b>
	<a href="https://valentin.deschaintre.fr/text2fabric"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://valentin.deschaintre.fr/text2fabric"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://valentin.deschaintre.fr/text2fabric"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://valentin.deschaintre.fr/text2fabric"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://valentin.deschaintre.fr/">Valentin Deschaintre</a>* 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://webdiis.unizar.es/~juliagv/">Julia Guerrero Viu</a>*, 
<a href="http://giga.cps.unizar.es/~diegog/">Diego Gutierrez</a> 
(<a href="https://i3a.unizar.es/es">Universidad de Zaragoza - I3A</a>), 
<a href="https://perso.telecom-paristech.fr/boubek/">Tamy Boubekeur</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://webdiis.unizar.es/~bmasia/">Belen Masia</a> 
(<a href="https://i3a.unizar.es/es">Universidad de Zaragoza - I3A</a>) 
* Equal contribution 
</dd>

<dt><b>ArrangementNet: Learning Scene Arrangements for Vectorized Indoor Scene Modeling</b>
	<a href="https://github.com/zssjh/ArrangementNet"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Jingwei Huang, 
Shanshan Zhang, 
Bo Duan, 
Yanfeng Zhang, 
Xiaoyang Guo, 
Mingwei Sun 
(<a href="https://www.huawei.com/">Huawei</a>), 
<a href="https://ericyi.github.io/">Li Yi</a> 
(<a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>)
</dd>

<dt><b>Juxtaform: Interactive Visual Summarization for Exploratory Shape Design</b>
	<a href="https://www.dgp.toronto.edu/projects/juxtaform/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.dgp.toronto.edu/projects/juxtaform/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.dgp.toronto.edu/projects/juxtaform/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://karranpandey.github.io/">Karran Pandey</a>, 
<a href="http://www.cs.toronto.edu/~fanny/index.html">Fanny Chevalier</a>, 
<a href="https://www.dgp.toronto.edu/~karan/">Karan Singh</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a>)
</dd>

<dt><b>Patternshop: Editing Point Patterns by Image Manipulation</b>
	<a href="https://xchhuang.github.io/patternshop/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://xchhuang.github.io/patternshop/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://xchhuang.github.io/patternshop/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://xchhuang.github.io/patternshop/index.html"><img alt="Paper Presentation" src="Ppt.png" border="0"></a>
	</dt>
<dd>
<a href="https://people.mpi-inf.mpg.de/~xhuang/">Xingchang Huang</a> 
(<a href="https://www.mpi-inf.mpg.de/home">Max Planck Institute for Informatics</a>), 
<a href="https://www.homepages.ucl.ac.uk/~ucactri/">Tobias Ritschel</a> 
(<a href="https://www.ucl.ac.uk/">University College London</a>), 
<a href="https://people.mpi-inf.mpg.de/~hpseidel/english.html">Hans-Peter Seidel</a> 
(<a href="https://www.mpi-inf.mpg.de/home">Max Planck Institute for Informatics</a>), 
<a href="http://www.lix.polytechnique.fr/~memari/">Pooran Memari</a> 
(<a href="https://www.lix.polytechnique.fr/">LIX-Inria</a>), 
<a href="https://sampling.mpi-inf.mpg.de/">Gurprit Singh</a> 
(<a href="https://www.mpi-inf.mpg.de/home">Max Planck Institute for Informatics</a>)
</dd>

<dt><b>Local Deformation for Interactive Shape Editing</b>
	<a href="https://www.cs.columbia.edu/cg/local-deformation/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.cs.columbia.edu/cg/local-deformation/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.cs.columbia.edu/cg/local-deformation/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.cs.columbia.edu/~honglinchen/">Honglin Chen</a>, 
<a href="http://www.cs.columbia.edu/~cxz/">Changxi Zheng</a> 
(<a href="http://www.columbia.edu/">Columbia University</a>), 
<a href="http://www.kevinwampler.com/homepage/index.html">Kevin Wampler</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>)
</dd>

</dl>

<h2>Image and Video Editing</h2>
<dl>

<dt><b>Eventfulness for Interactive Video Alignment</b>
	</dt>
<dd>

<a href="https://jiatiansun.github.io/">Jiatian Sun</a>, 
Longxiulin Deng 
(<a href="https://www.cornell.edu/">Cornell University</a>), 
<a href="https://www.robots.ox.ac.uk/~afourast/">Triantafyllos Afouras </a> 
(<a href="https://ox.ac.uk/">University of Oxford</a> and <a href="https://ai.facebook.com/">Meta AI</a>), 
<a href="https://andrewowens.com/">Andrew Owens</a> 
(<a href="https://umich.edu/">The University of Michigan</a>), 
<a href="http://abedavis.com/">Abe Davis</a> 
(<a href="https://www.cornell.edu/">Cornell University</a>)
</dd>

<dt><b>Parsing-conditioned Anime Translation: A New Dataset and Method</b>
	<a href="https://github.com/zsl2018/StyleAnime"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://github.com/zsl2018/StyleAnime"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://drive.google.com/file/d/13C7Jphi8dYkY_0HoqIZeXAIkppyKlzmQ/view?usp=share_link"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/zsl2018/StyleAnime"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Zhansheng Li 
(<a href="https://www.scut.edu.cn/en/">South China University of Technology</a> and <a href="https://www.smu.edu.sg/">Singapore Management University</a>), 
<a href="https://cnnlstm.github.io/">Yangyang Xu</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a> and <a href="https://www.scut.edu.cn/en/">South China University of Technology</a>), 
<a href="http://nxzhao.com/">Nanxuan Zhao</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
Yang Zhou 
(<a href="https://www.scut.edu.cn/en/">South China University of Technology</a> and <a href="https://www.smu.edu.sg/">Singapore Management University</a>), 
<a href="https://ivi.fnwi.uva.nl/vislab/author/yongtuo-liu/">Yongtuo Liu</a> 
(<a href="https://www.uva.nl/en">University of Amsterdam</a> and <a href="https://www.scut.edu.cn/en/">South China University of Technology</a>), 
<a href="http://dahua.site/">Dahua Lin</a> 
(<a href="https://cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong</a>), 
<a href="http://www.shengfenghe.com/">Shengfeng He</a> 
(<a href="https://www.smu.edu.sg/">Singapore Management University</a>)
</dd>

<dt><b>FactorMatte: Redefining Video Matting for Re-composition Tasks</b>
	<a href="https://factormatte.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://factormatte.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://factormatte.github.io/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/jaclyngu/FactorMatte"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/jaclyngu/FactorMatte"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.cs.cornell.edu/~zeqigu/">Zeqi Gu</a>, 
<a href="https://www.cs.cornell.edu/~wenqixian/">Wenqi Xian</a>, 
<a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a> 
(<a href="https://tech.cornell.edu/">Cornell Tech</a> and <a href="https://www.cornell.edu/">Cornell University</a>), 
<a href="http://abedavis.com/">Abe Davis</a> 
(<a href="https://www.cornell.edu/">Cornell University</a>)
</dd>

<dt><b>Computational Long Exposure Mobile Photography</b>
	<a href="https://motion-mode.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://motion-mode.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://motion-mode.github.io/"><img alt="Paper Data" src="Data.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.tabellion.org/et/">Eric Tabellion</a>, 
Nikhil Karnad, 
Noa Glaser, 
Ben Weiss, 
David Jacobs, 
<a href="https://research.google/people/106214/">Yael Pritch</a> 
(<a href="https://research.google/">Google Research</a>)
</dd>

<dt><b>Zero-shot Image-to-image Translation</b>
	<a href="https://pix2pixzero.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://pix2pixzero.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/pix2pixzero/pix2pix-zero"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://gauravparmar.com/">Gaurav Parmar</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>), 
<a href="http://krsingh.cs.ucdavis.edu/">Krishna Kumar Singh</a>, 
<a href="http://richzhang.github.io/">Richard Zhang</a>, 
<a href="https://yijunmaverick.github.io/">Yijun Li</a>, 
<a href="https://research.adobe.com/person/jingwan-lu/">Jingwan Lu</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
</dd>

<dt><b>Key-Locked Rank One Editing for Text-to-Image Personalization</b>
	<a href="https://research.nvidia.com/labs/par/Perfusion/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/par/Perfusion/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://yoadtew.github.io/">Yoad Tewel</a>, 
<a href="https://rinongal.github.io/">Rinon Gal</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://english.tau.ac.il/">Tel-Aviv University</a>), 
<a href="https://research.nvidia.com/person/gal-chechik">Gal Chechik</a>, 
<a href="https://research.nvidia.com/person/yuval-atzmon">Yuval Atzmon</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>) 
</dd>

</dl>

<h2>Magical Sketching</h2>
<dl>

<dt><b>HiGAN+: Handwriting Imitation GAN With Disentangled Representations</b>
	<a href="https://github.com/ganji15/HiGANplus"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://github.com/ganji15">Ji Gan</a> 
(<a href="http://cqupt.ciss.org.cn/">Chongqing University of Posts and Telecommunications</a> and <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>), 
Weiqiang Wang 
(<a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>), 
Jiaxu Leng, 
Xinbo Gao 
(<a href="http://cqupt.ciss.org.cn/">Chongqing University of Posts and Telecommunications</a>) 
</dd>

<dt><b>A Method for Animating Children's Drawings of the Human Figure</b>
	<a href="https://arxiv.org/abs/2303.12741"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2303.12741"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/facebookresearch/AnimatedDrawings"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="http://hjessmith.com/html/">Harrison Jesse Smith</a> 
(<a href="https://ai.facebook.com/research/">Meta AI Research</a>), 
<a href="https://scholar.google.com/citations?user=3yPjBLQAAAAJ&amp;hl=en">Qingyuan Zheng</a> 
(<a href="https://www.tencent.com/en-us/about.html">Tencent America</a>), 
<a href="https://people.csail.mit.edu/liyifei/">Yifei Li</a> 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a>), 
Somya Jain 
(<a href="https://ai.facebook.com/research/">Meta AI Research</a>), 
<a href="https://www.cs.cmu.edu/~jkh/">Jessica Hodgins</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>)
</dd>

<dt><b>VideoDoodles: Hand-drawn Animations on Videos With Scene-aware Canvases</b>
	<a href="https://em-yu.github.io/research/videodoodles/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://em-yu.github.io/research/videodoodles/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://em-yu.github.io/research/videodoodles/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://em-yu.github.io/">Emilie Yu</a> 
(<a href="https://www.inria.fr/fr/centre-inria-universite-cote-azur">Centre Inria dâ€™Universite Cote dâ€™Azur</a>), 
<a href="http://kmatzen.com/">Kevin Matzen</a>, 
<a href="http://www.cuongnd.com/">Cuong Nguyen</a>, 
<a href="http://www.oliverwang.info/">Oliver Wang</a>, 
<a href="https://rubaiathabib.me/">Rubaiat Habib Kazi</a> 
(<a href="https://www.adobe.com/">Adobe</a>), 
<a href="https://www-sop.inria.fr/members/Adrien.Bousseau/">Adrien Bousseau</a> 
(<a href="https://www.inria.fr/fr/centre-inria-universite-cote-azur">Centre Inria dâ€™Universite Cote dâ€™Azur</a> and <a href="https://www.tudelft.nl/en/">TU Delft</a>)
</dd>

<dt><b>StripMaker: Perception-driven Learned Vector Sketch Consolidation</b>
	<a href="https://www.cs.ubc.ca/labs/imager/tr/2023/stripmaker/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.cs.ubc.ca/labs/imager/tr/2023/stripmaker/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.cs.ubc.ca/labs/imager/tr/2023/stripmaker/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.cs.ubc.ca/~chenxil/">Chenxi Liu</a> 
(<a href="https://www.ubc.ca/">University of British Columbia</a>), 
<a href="https://sites.google.com/view/toshikiaoki">Toshiki Aoki</a> 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a>), 
<a href="http://www-labs.iro.umontreal.ca/~bmpix/">Mikhail Bessmeltsev</a> 
(<a href="https://www.umontreal.ca/">Universite de Montreal</a>)
<a href="https://www.cs.ubc.ca/~sheffa/">Alla Sheffer</a> 
(<a href="https://www.ubc.ca/">University of British Columbia</a>)
</dd>

<dt><b>Semi-supervised Reference-based Sketch Extraction Using a Contrastive Learning Framework</b>
	<a href="https://chanuku.github.io/Semi_ref2sketch/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://chanuku.github.io/Semi_ref2sketch/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://chanuku.github.io/Semi_ref2sketch/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/Chanuku/4skst"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/Chanuku/semi_ref2sketch_code"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://vml.kaist.ac.kr/main/people/person/155">Chang Wook Seo</a>, 
<a href="https://vml.kaist.ac.kr/main/people/person/140">Amirsaman Ashtari</a>, 
<a href="https://vml.kaist.ac.kr/main/people/person/1">Junyong Noh</a> 
(<a href="https://www.kaist.ac.kr/en/">KAIST</a>)
</dd>

<dt><b>AniFaceDrawing: Anime Portrait Exploration during Your Sketching</b>
	<a href="http://www.jaist.ac.jp/~xie/AniFaceDrawing.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://www.jaist.ac.jp/~xie/AniFaceDrawing.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://www.jaist.ac.jp/~xie/AniFaceDrawing.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="http://www.jaist.ac.jp/~xie/AniFaceDrawing.html"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Zhengyu Huang, 
<a href="www.jaist.ac.jp/~xie/">Haoran Xie</a> 
(<a href="https://www.jaist.ac.jp/english/">JAIST</a>), 
<a href="https://sites.google.com/view/tsukasafukusato">Tsukasa Fukusato</a> 
(<a href="https://www.waseda.jp/top/en/">Waseda University</a>), 
<a href="http://www.jaist.ac.jp/~miyata/">Kazunori Miyata</a> 
(<a href="https://www.jaist.ac.jp/english/">JAIST</a>)
</dd>

</dl>

<h2>Procedural Modeling</h2>
<dl>

<dt><b>Rhizomorph: The Coordinated Function of Shoots and Roots</b>
	<a href="https://storage.googleapis.com/pirk.io/projects/rhizomorph/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://storage.googleapis.com/pirk.io/projects/rhizomorph/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://storage.googleapis.com/pirk.io/projects/rhizomorph/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Bosheng Li 
(<a href="https://www.purdue.edu/">Purdue University</a>), 
<a href="https://jonathank.de/research/index.html">Jonathan Klein</a>, 
<a href="http://dmichels.de/">Dominik L. Michels</a> 
(<a href="https://www.kaust.edu.sa/">KAUST</a>), 
<a href="https://www.cs.purdue.edu/homes/bbenes/">Bedrich Benes</a> 
(<a href="https://www.purdue.edu/">Purdue University</a>), 
<a href="http://www.pirk.io/">Soren Pirk</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://www.researchgate.net/profile/Wojtek-Palubicki">Wojtek Palubicki</a> 
(<a href="https://amu.edu.pl/en">Adam Mickiewicz University</a>)
</dd>

<dt><b>Example-based Procedural Modeling Using Graph Grammars</b>
	<a href="https://paulmerrell.org/grammar/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://paulmerrell.org/grammar/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://paulmerrell.org/grammar/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://paulmerrell.org/grammar/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://paulmerrell.org/">Paul Merrell</a> 
(Independent researcher)
</dd>

<dt><b>Large-scale Terrain Authoring Through Interactive Erosion Simulation</b>
	<a href="https://perso.liris.cnrs.fr/eric.galin/2024-2020.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://perso.liris.cnrs.fr/eric.galin/2024-2020.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=gCP7jzcPLyQ"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/H-Schott/StreamPowerErosion"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Hugo Schott, 
<a href="https://aparis69.github.io/">Axel Paris</a>, 
Lucie Fournier, 
<a href="https://perso.liris.cnrs.fr/eguerin/new/">Eric Guerin</a>, 
<a href="https://perso.liris.cnrs.fr/eric.galin/">Eric Galin</a> 
(<a href="https://www.univ-lyon1.fr/">Univ Lyon</a> / <a href="https://www.insa-lyon.fr/">INSA Lyon</a> / <a href="https://www.cnrs.fr/en">CNRS</a> / <a href="https://www.univ-lyon1.fr/en">UCBL</a> / <a href="https://liris.cnrs.fr/en">LIRIS</a> / UMR5205) 
</dd>

<dt><b>Forming Terrains by Glacial Erosion</b>
	<a href="https://perso.liris.cnrs.fr/eric.galin/2024-2020.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://perso.liris.cnrs.fr/eric.galin/2024-2020.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=xfk_J4VhdWA"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://www-sop.inria.fr/members/Guillaume.Cordonnier/">Guillaume Cordonnier</a> 
(<a href="https://www.inria.fr/en">Inria</a> and <a href="https://univ-cotedazur.fr/">Universite Cote dâ€™Azur</a>), 
<a href="https://jouvetg.github.io/">Guillaume Jouvet</a> 
(<a href="https://www.unil.ch/central/en/home.html">University of Lausanne</a>), 
<a href="https://perso.liris.cnrs.fr/apeytavi/website/">Adrien Peytavie</a> 
(<a href="https://www.univ-lyon1.fr/">Univ Lyon</a> / <a href="https://www.insa-lyon.fr/">INSA Lyon</a> / <a href="https://www.cnrs.fr/en">CNRS</a> / <a href="https://www.univ-lyon1.fr/en">UCBL</a> / <a href="https://liris.cnrs.fr/en">LIRIS</a> / UMR5205), 
Jean Braun  
(<a href="https://www.helmholtz.de/ueber-uns/helmholtz-zentren/zentren-a-z/zentrum/helmholtz-zentrum-potsdam-deutsches-geoforschungszentrum-gfz/">Helmholtz Centre Potsdam</a> and <a href="https://www.uni-potsdam.de/en/university-of-potsdam">University of Potsdam</a>), 
<a href="https://www.lix.polytechnique.fr/vista/vista-member/marie-paule_cani/">Marie-Paule Cani</a> 
(<a href="https://www.polytechnique.edu/en">Ecole Polytechnique</a>), 
<a href="https://www.cs.purdue.edu/homes/bbenes/">Bedrich Benes</a> 
(<a href="http://www.purdue.edu/">Purdue University</a>), 
<a href="https://perso.liris.cnrs.fr/eric.galin/">Eric Galin</a>, 
<a href="https://perso.liris.cnrs.fr/eguerin/new/">Eric Guerin</a> 
(<a href="https://www.univ-lyon1.fr/">Univ Lyon</a> / <a href="https://www.insa-lyon.fr/">INSA Lyon</a> / <a href="https://www.cnrs.fr/en">CNRS</a> / <a href="https://www.univ-lyon1.fr/en">UCBL</a> / <a href="https://liris.cnrs.fr/en">LIRIS</a> / UMR5205), 
<a href="https://sit.uct.ac.za/contacts/james-gain">James Gain</a> 
(<a href="https://uct.ac.za/">University of Cape Town</a>)
</dd>

<dt><b>Procedural Metamaterials: A Unified Procedural Graph for Metamaterial Design</b>
	<a href="https://cfg.mit.edu/publications/procedural-metamaterials"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://cfg.mit.edu/publications/procedural-metamaterials"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="http://www.lianemakatura.com/">Liane Makatura</a>*, 
<a href="https://bohanwang123.com/">Bohan Wang</a>* 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a>), 
Yi-Lu Chen
(<a href="https://ist.ac.at/en/home/">IST Austria</a>), 
<a href="http://zhao.mit.edu/teams/bolei-deng/">Bolei Deng</a> 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a>), 
<a href="https://pub.ista.ac.at/~wojtan/">Chris Wojtan</a> 
<a href="https://ist.ac.at/en/research/bickel-group/">Bernd Bickel</a>, 
(<a href="https://ist.ac.at/en/home/">IST Austria</a>), 
<a href="https://cdfg.csail.mit.edu/wojciech">Wojciech Matusik</a> 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a>) 
* joint first authors
</dd>

<dt><b>UrbanBIS: A Large-scale Benchmark for Fine-grained Urban Building Instance Segmentation</b>
	<a href="https://vcc.tech/UrbanBIS"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://vcc.tech/UrbanBIS"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://vcc.tech/UrbanBIS"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://vcc.tech/UrbanBIS"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://vcc.tech/UrbanBIS"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Guoqing Yang, 
Fuyou Xue, 
Qi Zhang, 
Ke Xie 
(<a href="https://en.szu.edu.cn/">Shenzhen University</a>), 
<a href="https://www.cse.cuhk.edu.hk/~cwfu/">Chi-Wing Fu</a> 
(<a href="http://www.cuhk.edu.hk/">The Chinese University of Hong Kong</a>), 
<a href="https://vcc.tech/~huihuang">Hui Huang</a> 
(<a href="https://en.szu.edu.cn/">Shenzhen University</a>)
</dd>

</dl>

<h2>XR Displays and Perception: Seeing What's in Front of Your Eyes</h2>
<dl>

<dt><b>Split-Lohmann Multifocal Displays</b>
	<a href="https://imaging.cs.cmu.edu/split_lohmann/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://imaging.cs.cmu.edu/split_lohmann/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://imaging.cs.cmu.edu/split_lohmann/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://imaging.cs.cmu.edu/split_lohmann/"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/Image-Science-Lab-cmu/SplitLohmann"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://yingsiqin.github.io/">Yingsi Qin</a>, 
<a href="https://wyharveychen.github.io/">Wei-Yu Chen</a>, 
<a href="https://www.cs.cmu.edu/~motoole2/">Matthew O'Toole</a>, 
<a href="https://www.ece.cmu.edu/directory/bios/sankaranarayanan-aswin.html">Aswin C. Sankaranarayanan</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>)
</dd>

<dt><b>The Statistics of Eye Movements and Binocular Disparities in VR Gaming Headsets Should Drive Headset Design</b>
	<a href="https://dro.dur.ac.uk/36175/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://dro.dur.ac.uk/36175/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="http://aviaizenman.com/profile.html">Avi M. Aizenman</a> 
(<a href="https://www.berkeley.edu/">University of California, Berkeley</a>), 
<a href="https://www.durham.ac.uk/staff/georgios-a-koulieris/">George A. Koulieris</a> 
(<a href="https://www.durham.ac.uk/">Durham University</a>), 
Agostino Gibaldi, 
Vibhor Sehgal, 
Dennis M. Levi, 
Martin S. Banks 
(<a href="https://www.berkeley.edu/">University of California, Berkeley</a>) 
</dd>

<dt><b>Etendue Expansion in Holographic Near Eye Displays Through Sparse Eye-box Generation Using Lens Array Eyepiece</b>
	</dt>
<dd>
Minseok Chae, 
Kiseung Bang, 
Dongheon Yoo, 
<a href="https://laser.snu.ac.kr/members/professor">Yoonchan Jeong</a> 
(<a href="https://en.snu.ac.kr/">Seoul National University</a>)
</dd>

<dt><b>OpenMPD: A Low-level Presentation Engine for Multimodal Particle-based Displays</b>
	<a href="https://discovery.ucl.ac.uk/id/eprint/10169091/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://discovery.ucl.ac.uk/id/eprint/10169091/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://uclic.ucl.ac.uk/people/roberto-antonio-montano-murillo">Roberto Montano Murillo</a>, 
<a href="https://ryujihirayama.github.io/web/index.html">Ryuji Hirayama</a>, 
<a href="https://uclic.ucl.ac.uk/people/diego-martinez-plasencia">Diego Martinez Plasencia</a> 
(<a href="https://www.ucl.ac.uk/">University College London</a>)
</dd>

<dt><b>Perceptual Visibility Model for Temporal Contrast Changes in Periphery</b>
	<a href="https://www.pdf.inf.usi.ch/publications.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.cs.rug.nl/svcg/People/CaraTursun">Cara Tursun</a> 
(<a href="https://www.usi.ch/en">Universita della Svizzera italiana</a> and <a href="https://www.rug.nl/?lang=en">University of Groningen</a>), 
<a href="https://www.pdf.inf.usi.ch/people/piotr/">Piotr Didyk</a> 
(<a href="https://www.usi.ch/en">Universita della Svizzera italiana</a>)
</dd>

<dt><b>Perspective-correct VR Passthrough Without Reprojection</b>
	</dt>
<dd>
Grace Kuo
Eric Penner
Seth Moczydlowski
Alex Ching
Douglas Lanman
Nathan Matsuda
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

</dl>

<h2>Contours, Conformality, Coarsening, and Coordinates</h2>
<dl>

<dt><b>ConTesse: Accurate Occluding Contours for Subdivision Surfaces</b>
	<a href="https://dgp.toronto.edu/~hertzman/contesse/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://dgp.toronto.edu/~hertzman/contesse/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://dgp.toronto.edu/~hertzman/contesse/"><img alt="Paper Data" src="Data.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.cs.ubc.ca/~chenxil/">Chenxi Liu</a> 
(<a href="https://www.ubc.ca/">University of British Columbia</a>), 
<a href="https://www.labri.fr/perso/pbenard/">Pierre Benard</a> 
(<a href="https://www.u-bordeaux.fr/en">University of Bordeaux</a> / <a href="http://www.cnrs.fr/index.html">CNRS</a> / <a href="https://www.bordeaux-inp.fr/en">Bordeaux INP</a> / <a href="https://www.inria.fr/en">INRIA</a> / <a href="https://www.labri.fr/en">LaBRI</a>), 
<a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://hooshi.gitlab.io/">Shayan Hoshyari</a> 
(<a href="https://www.adobe.com/">Adobe</a>)
</dd>

<dt><b>Differential Operators on Sketches via Alpha Contours</b>
	<a href="http://www-labs.iro.umontreal.ca/~bmpix/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Mariia Myronova, 
<a href="https://wwwnev.github.io/">William Neveu</a>, 
<a href="http://www-labs.iro.umontreal.ca/~bmpix/">Mikhail Bessmeltsev</a> 
(<a href="https://www.umontreal.ca/">Universite de Montreal</a>)
</dd>

<dt><b>Min-Deviation-Flow in Bi-directed Graphs for T-Mesh Quantization</b>
	<a href="https://www.algohex.eu/publications/bimdf-quantization/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.algohex.eu/publications/bimdf-quantization/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.algohex.eu/publications/bimdf-quantization/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.algohex.eu/team/heistermann/">Martin Heistermann</a> 
(<a href="https://www.unibe.ch/index_eng.html">University of Bern</a>), 
<a href="https://www.algohex.eu/team/warnett/">Jethro Warnett</a> 
(<a href="https://www.ox.ac.uk/">University of Oxford</a>), 
<a href="https://www.algohex.eu/team/bommes/">David Bommes</a> 
(<a href="https://www.unibe.ch/index_eng.html">University of Bern</a>)
</dd>

<dt><b>Efficient Embeddings in Exact Arithmetic</b>
	</dt>
<dd>
Ugo Finnendahl
Dimitrios Bogiokas
Pablo Robles Cervantes
Marc Alexa
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>Spectral Coarsening using Hodge Laplacians</b>
	<a href="https://homepages.inf.ed.ac.uk/ksubr/research.html#SIGG23"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Alexandros Keros, 
<a href="https://homepages.inf.ed.ac.uk/ksubr/">Kartic Subr</a> 
(<a href="https://www.ed.ac.uk/">The University of Edinburgh</a>)
</dd>

<dt><b>Polynomial 2D Green Coordinates for Polygonal Cages</b>
	<a href="https://portfolio.exppad.com/research.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://research.adobe.com/person/elie-michel/">Elie Michel</a>, 
<a href="https://research.adobe.com/person/jean-thiery/">Jean-Marc Thiery</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>) 
</dd>

</dl>

<h2>Fabricating Appearance</h2>
<dl>

<dt><b>Scratch-based Reflection Art via Differentiable Rendering</b>
	<a href="https://wangningbei.github.io/2023/DiffGlints.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://wangningbei.github.io/2023/DiffGlints.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://wangningbei.github.io/2023/DiffGlints.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Pengfei Shen*,
Ruizeng Li*  
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>), 
<a href="https://wangningbei.github.io/">Beibei Wang</a> 
(<a href="https://en.nankai.edu.cn/">Nankai University</a> and <a href="https://english.njust.edu.cn/">Nanjing University of Science and Technology</a>), 
<a href="http://staff.ustc.edu.cn/~lgliu/">Ligang Liu</a> 
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>)
(* Joint first authors)
</dd>

<dt><b>Meso-facets for Goniochromatic 3D Printing</b>
	</dt>
<dd>
Lubna Abu Rmaileh
Alan Brunton
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>Skin-Screen: A Computational Fabrication Framework for Color Tattoos</b>
	<a href="https://misop.github.io/projects/ComputationalTattoo/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://misop.github.io/projects/ComputationalTattoo/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://misop.github.io/projects/ComputationalTattoo/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://misop.github.io/">Michal Piovarci</a> 
(<a href="https://ist.ac.at/en/home/">IST Austria</a>), 
<a href="https://achapiro.github.io/">Alexandre Chapiro</a> 
(Independent), 
<a href="https://ist.ac.at/en/research/bickel-group/">Bernd Bickel</a> 
(<a href="https://ist.ac.at/en/home/">IST Austria</a>)
</dd>

<dt><b>Orientable Dense Cyclic Infill for Anisotropic Appearance Fabrication</b>
	<a href="https://xavierchermain.github.io/fdm_aa/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://xavierchermain.github.io/fdm_aa/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://youtu.be/aUDzZrlRnNU"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://xavierchermain.github.io/">Xavier Chermain</a>, 
<a href="https://members.loria.fr/CZanni/">Cedric Zanni</a>, 
<a href="https://sites.google.com/site/jonasmartinezbayona/">Jonas MartÃ­nez</a>, 
Pierre-Alexandre Hugron, 
<a href="https://www.antexel.com/sylefeb/">Sylvain Lefebvre</a> 
(<a href="http://welcome.univ-lorraine.fr/en">Universite de Lorraine</a> / <a href="http://www.cnrs.fr/index.html">CNRS</a> / <a href="https://www.inria.fr/en/centre/nancy">Inria</a>) 
</dd>

<dt><b>Stealth Shaper: Reflectivity Optimization as Surface Stylization</b>
	<a href="https://kenji-tojo.github.io/publications/stealthshaper/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://kenji-tojo.github.io/publications/stealthshaper/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://kenji-tojo.github.io/publications/stealthshaper/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://kenji-tojo.github.io/publications/stealthshaper/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://kenji-tojo.github.io/">Kenji Tojo</a> 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a>), 
<a href="https://faculty.runi.ac.il/arik/site/index.asp">Ariel Shamir</a> 
(<a href="https://www.runi.ac.il/en">Reichman University</a>), 
<a href="https://ist.ac.at/en/research/bickel-group/">Bernd Bickel</a> 
(<a href="https://ist.ac.at/en/home/">IST Austria</a>), 
<a href="https://cgenglab.github.io/en/authors/admin/">Nobuyuki Umetani</a> 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a>)
</dd>

<dt><b>Gloss-aware Color Correction for 3D Printing</b>
	<a href="https://www.pdf.inf.usi.ch/projects/ColorGlossPrinting/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.pdf.inf.usi.ch/projects/ColorGlossPrinting/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://arcanous98.github.io/">Jorge Condor</a> 
(<a href="https://www.usi.ch/it">Universita della Svizzera italiana</a>), 
<a href="https://misop.github.io/">Michal Piovarci</a>, 
<a href="https://ist.ac.at/en/research/bickel-group/">Bernd Bickel</a> 
(<a href="https://ist.ac.at/en/home/">IST Austria</a>), 
<a href="https://www.pdf.inf.usi.ch/people/piotr/">Piotr Didyk</a> 
(<a href="https://www.usi.ch/it">Universita della Svizzera italiana</a>)
</dd>

</dl>

<h2>Inverse Rendering: Does Anybody Know How I Got Here?</h2>
<dl>

<dt><b>Recursive Control Variates for Inverse Rendering</b>
	<a href="https://rgl.epfl.ch/publications/Nicolet2023Recursive"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://rgl.epfl.ch/publications/Nicolet2023Recursive"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://rgl.epfl.ch/publications/Nicolet2023Recursive"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://bnicolet.com/">Baptiste Nicolet</a> 
(<a href="https://www.epfl.ch/en/">EPFL</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://research.nvidia.com/person/fabrice-rousselle">Fabrice Rousselle</a>, 
<a href="https://jannovak.info/">Jan Novak</a>, 
<a href="https://research.nvidia.com/person/alex-keller">Alexander Keller</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://rgl.epfl.ch/people/wjakob">Wenzel Jakob</a> 
(<a href="https://www.epfl.ch/en/">EPFL</a>), 
<a href="https://tom94.net/">Thomas Muller</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>)
</dd>

<dt><b>Film Grain Rendering and Parameter Estimation</b>
	</dt>
<dd>
kaixuan zhang
Jingxian Wang
Daizong Tian
Thrasyvoulos Pappas
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>Revisiting Controlled Mixture Sampling for Rendering Applications</b>
	<a href="https://graphics.cg.uni-saarland.de/publications/hua-2023-sig-cms.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://graphics.cg.uni-saarland.de/publications/hua-2023-sig-cms.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/qingqhua/ControlledMixtureSampling"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://graphics.cg.uni-saarland.de/people/hua.html">Qingqin Hua</a>, 
<a href="https://graphics.cg.uni-saarland.de/people/grittmann.html">Pascal Grittmann</a> 
(<a href="https://www.uni-saarland.de/en/home.html">Saarland University</a>), 
<a href="https://graphics.cg.uni-saarland.de/people/slusallek.html">Philipp Slusallek</a> 
(<a href="https://www.uni-saarland.de/en/home.html">Saarland University</a> and <a href="https://www.dfki.de/en/web">DFKI</a>)
</dd>

<dt><b>Inverse Global Illumination using a Neural Radiometric Prior</b>
	<a href="https://inverse-neural-radiosity.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://inverse-neural-radiosity.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://inverse-neural-radiosity.github.io/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.cs.umd.edu/~saeedhd">Saeed Hadadan</a> 
(<a href="https://www.umd.edu/">University of Maryland, College Park</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.cs.umd.edu/people/geng">Geng Lin</a> 
(<a href="https://www.umd.edu/">University of Maryland, College Park</a>), 
<a href="https://research.nvidia.com/person/jan-novak">Jan Novak</a>, 
<a href="https://research.nvidia.com/person/fabrice-rousselle">Fabrice Rousselle</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.cs.umd.edu/~zwicker/">Matthias Zwicker</a> 
(<a href="https://www.umd.edu/">University of Maryland, College Park</a>) 
</dd>

<dt><b>Parameter-space ReSTIR for Differentiable and Inverse Rendering</b>
	<a href="https://weschang.com/publications/restir-dr/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://weschang.com/publications/restir-dr/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://weschang.com/publications/restir-dr/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://weschang.com/">Wesley Chang</a>, 
<a href="https://github.com/vedavamadathil">Venkataram Sivaram</a> 
(<a href="https://ucsd.edu/">UC San Diego</a>), 
<a href="https://www.cim.mcgill.ca/~derek/">Derek Nowrouzezahrai</a> 
(<a href="https://www.mcgill.ca/">McGill University</a>), 
<a href="https://cs.uwaterloo.ca/~thachisu/">Toshiya Hachisuka</a> 
(<a href="https://uwaterloo.ca/">University of Waterloo</a>), 
<a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>, 
<a href="https://cseweb.ucsd.edu/~tzli/">Tzu-Mao Li</a> 
(<a href="https://ucsd.edu/">UC San Diego</a>) 
</dd>

<dt><b>Differentiable Heightfield Path Tracing with Accelerated Discontinuities</b>
	<a href="https://www.dgp.toronto.edu/~hsuehtil/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Xiaochun Tong 
(<a href="https://uwaterloo.ca/">University of Waterloo</a>), 
<a href="https://www.dgp.toronto.edu/~hsuehtil/">Hsueh-Ti Derek Liu</a> 
(<a href="https://corp.roblox.com/research/">Roblox Research</a>), 
<a href="https://cs.gmu.edu/~ygingold/">Yotam Gingold</a> 
(<a href="https://www.gmu.edu/">George Mason University</a>), 
<a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://research.adobe.com/">Adobe Research</a>) 
</dd>

</dl>

<h2>Full-Body XR: Beyond The Headset</h2>
<dl>

<dt><b>EgoLocate: Real-time Motion Capture, Localization, and Mapping With Sparse Body-mounted Sensors</b>
	<a href="https://xinyu-yi.github.io/EgoLocate/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://xinyu-yi.github.io/EgoLocate/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://xinyu-yi.github.io/EgoLocate/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/Xinyu-Yi/EgoLocate"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://xinyu-yi.github.io/">Xinyu Yi</a> 
(<a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>), 
<a href="https://calciferzh.github.io/">Yuxiao Zhou</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="https://people.mpi-inf.mpg.de/~mhaberma/">Marc Habermann</a>, 
<a href="https://people.mpi-inf.mpg.de/~golyanik/">Vladislav Golyanik</a> 
(<a href="http://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics</a>),  
Shaohua Pan 
(<a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>), 
<a href="http://www.mpi-inf.mpg.de/~theobalt/">Christian Theobalt</a> 
(<a href="http://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics</a>),  
<a href="http://xufeng.site/">Feng Xu</a> 
(<a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>) 
</dd>

<dt><b>Differential Frequency Heterodyne Time-of-flight Imaging for Instantaneous Depth and Velocity Estimation</b>
	</dt>
<dd>
Yunpu Hu
Masatoshi Ishikawa
Leo Miyashita
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>MoireTag: Angular Measurement and Tracking with a Passive Marker</b>
	<a href="https://vccimaging.org/Publications/Simeng2023MoireTag/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://vccimaging.org/Publications/Simeng2023MoireTag/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://vccimaging.org/Publications/Simeng2023MoireTag/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://vccimaging.org/People/simeng/">Simeng Qiu</a>, 
<a href="https://vccimaging.org/People/amatah/">Hadi Amata</a>, 
<a href="https://vccimaging.org/People/heidriw/">Wolfgang Heidrich</a> 
(<a href="https://www.kaust.edu.sa/en">KAUST</a>)
</dd>

<dt><b>Toward Optimized VR/AR Ergonomics: Modeling and Predicting User Neck Muscle Contraction</b>
	<a href="https://www.immersivecomputinglab.org/publication/toward-optimized-vr-ar-ergonomics-modeling-and-predicting-user-neck-muscle-contraction/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.immersivecomputinglab.org/publication/toward-optimized-vr-ar-ergonomics-modeling-and-predicting-user-neck-muscle-contraction/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=XO8VR1tJoaI"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/NYU-ICL/xr-ergonomics-neck-comfort"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://yunxiangzhang.github.io/">Yunxiang Zhang</a>, 
<a href="https://kenchen10.github.io/">Kenneth Chen</a>, 
<a href="https://qisun.me/">Qi Sun</a> 
(<a href="https://www.nyu.edu/">New York University</a>)
</dd>

<dt><b>In the Blink of an Eye: Event-based Emotion Recognition</b>
	<a href="https://www.cs.wm.edu/~ppeers/showPublication.php?id=Zhang:2023:ITB"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.cs.wm.edu/~ppeers/showPublication.php?id=Zhang:2023:ITB"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://xinyangdut.github.io/intelligent_bionic_system/index.html#0"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/zhanghaiwei1234/Single-eye-Emotion-Recognition"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Haiwei Zhang, 
<a href="https://zhangjiqing.com/">Jiqing Zhang</a> 
(<a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>), 
<a href="https://dongshuhao.github.io/">Bo Dong</a> 
(<a href="https://www.cs.princeton.edu/">Princeton University</a>), 
<a href="https://www.cs.wm.edu/~ppeers/">Pieter Peers</a> 
(<a href="https://www.wm.edu/">College of William &amp; Mary</a>), 
Wenwei Wu, 
Xiaopeng Wei 
(<a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>), 
<a href="https://www.cs.princeton.edu/~fheide/">Felix Heide</a> 
(<a href="https://www.cs.princeton.edu/">Princeton University</a>), 
<a href="https://xinyangdut.github.io/">Xin Yang</a> 
(<a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>)
</dd>

<dt><b>Towards Attention-Aware Foveated Rendering</b>
	<a href="https://www.computationalimaging.org/publications/attention-aware/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.computationalimaging.org/publications/attention-aware/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.computationalimaging.org/publications/attention-aware/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.bkrajancich.com/">Brooke Krajancich</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>), 
<a href="https://kellnhofer.xyz/">Petr Kellnhofer</a> 
(<a href="https://www.tudelft.nl/en/">TU Delft</a>), 
<a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>) 
</dd>

</dl>

<h2>Neural Light Transport</h2>
<dl>

<dt><b>Deep Appearance Prefiltering</b>
	<a href="http://civc.ucsb.edu/graphics/Papers/TOG2022_DAP/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://civc.ucsb.edu/graphics/Papers/TOG2022_DAP/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="http://www.ece.ucsb.edu/~sbako/">Steve Bako</a>, 
<a href="http://www.ece.ucsb.edu/~psen/">Pradeep Sen</a> 
(<a href="http://www.ece.ucsb.edu/">University of California, Santa Barbara</a>), 
<a href="http://kaplanyan.com/">Anton Kaplanyan</a> 
(<a href="https://research.facebook.com/">Facebook Reality Labs</a>)
</dd>

<dt><b>Neural Prefiltering for Correlation-aware Levels of Detail</b>
	<a href="https://weiphil.github.io/portfolio/neural_lod"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://weiphil.github.io/portfolio/neural_lod"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://weiphil.github.io/portfolio/neural_lod"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://weiphil.github.io/portfolio/neural_lod"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://weiphil.github.io/portfolio/">Philippe Weier</a> 
(<a href="https://www.uni-saarland.de/en/home.html">Saarland University</a>), 
Tobias Zirr, 
<a href="http://kaplanyan.com/">Anton Kaplanyan</a> 
(<a href="https://www.intel.com">Intel Corporation</a>), 
<a href="https://sites.cs.ucsb.edu/~lingqi/">Ling-Qi Yan</a> 
(<a href="https://www.ucsb.edu/">University of California, Santa Barbara</a>), 
<a href="https://graphics.cg.uni-saarland.de/people/slusallek.html">Philipp Slusallek</a> 
(<a href="https://www.uni-saarland.de/en/home.html">Saarland University</a>)
</dd>

<dt><b>Neural Parametric Mixtures for Path Guiding</b>
	<a href="https://neuropara.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://neuropara.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://neuropara.github.io/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Honghao Dong, 
<a href="https://cs.pku.edu.cn/info/1562/3800.htm">Guoping Wang</a>, 
Sheng Li 
(<a href="https://english.pku.edu.cn/">Peking University</a>)
</dd>

<dt><b>Focal Path Guiding for Light Transport Simulation</b>
	<a href="https://graphics.cg.uni-saarland.de/publications/rath-2023-focal-guiding.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://graphics.cg.uni-saarland.de/publications/rath-2023-focal-guiding.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/iRath96/focal-guiding"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://graphics.cg.uni-saarland.de/people/rath.html">Alexander Rath</a>, 
<a href="https://graphics.cg.uni-saarland.de/people/yazici.html">Omercan Yazici</a>, 
<a href="https://graphics.cg.uni-saarland.de/people/slusallek.html">Philipp Slusallek</a> 
(<a href="https://www.uni-saarland.de/en/home.html">Saarland University</a>)
</dd>

<dt><b>Progressive Null-tracking for Volumetric Rendering</b>
	<a href="https://cs.dartmouth.edu/~wjarosz/publications/misso23progressive.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://cs.dartmouth.edu/~wjarosz/publications/misso23progressive.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://cs.dartmouth.edu/~wjarosz/publications/misso23progressive.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/ZackMisso/ProgressiveNullTracking_Siggraph2023"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Zackary Misso 
(<a href="https://home.dartmouth.edu/">Dartmouth College</a>), 
<a href="https://www.yiningkarlli.com/">Yining Karl Li</a>, 
Brent Burley, 
Daniel Teece 
(<a href="https://disneyanimation.com/">Walt Disney Animation Studios</a>), 
<a href="https://www.cs.dartmouth.edu/~wjarosz/">Wojciech Jarosz</a> 
(<a href="https://home.dartmouth.edu/">Dartmouth College</a>)
</dd>

<dt><b>Denoising-aware Adaptive Sampling for Monte Carlo Ray Tracing</b>
	<a href="https://arthurfirmino.com/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://arthurfirmino.com/">Arthur Firmino</a> 
(<a href="https://luxion.com/">Luxion</a> and <a href="https://www.dtu.dk/english/">Technical University of Denmark</a>), 
<a href="http://www.imm.dtu.dk/~jerf/">Jeppe Revall Frisvad</a> 
(<a href="https://www.dtu.dk/english/">Technical University of Denmark</a>), 
<a href="http://graphics.ucsd.edu/~henrik/">Henrik Wann Jensen</a> 
(<a href="https://luxion.com/">Luxion</a>)
</dd>

</dl>

<h2>Thin and Thinner: Modeling Shells and Hair</h2>
<dl>

<dt><b>Complex Wrinkle Field Evolution</b>
	<a href="https://zhenchen-jay.github.io/publication/cwf/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://zhenchen-jay.github.io/publication/cwf/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/zhenchen-jay/Complex-Wrinkle-Field"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://zhenchen-jay.github.io/">Zhen Chen</a> 
(<a href="https://www.utexas.edu/">The University of Texas at Austin</a>), 
<a href="https://research.adobe.com/person/danny-kaufman/">Danny Kaufman</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://imagine.inrialpes.fr/people/mskouras/index.htm">Melina Skouras</a> 
(<a href="https://www.univ-grenoble-alpes.fr/">Univ. Grenoble Alpes</a> / <a href="https://www.inria.fr/en">Inria</a> / <a href="https://www.cnrs.fr/fr">CNRS</a>), 
<a href="https://www.cs.utexas.edu/users/evouga/">Etienne Vouga</a> 
(<a href="https://www.utexas.edu/">The University of Texas at Austin</a>)
</dd>

<dt><b>Computational Exploration of Multistable Elastic Knots</b>
	<a href="https://infoscience.epfl.ch/record/302408"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://infoscience.epfl.ch/record/302408"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://people.epfl.ch/294145">Vidulis Michele</a>, 
<a href="https://people.epfl.ch/301217">Ren Yingying</a> 
(<a href="https://www.epfl.ch/en/">EPFL</a>), 
<a href="https://julianpanetta.com/">Julian Panetta</a> 
(<a href="https://www.ucdavis.edu/">University of California, Davis</a>), 
<a href="https://www.dgp.toronto.edu/~eitan/">Eitan Grinspun</a> 
(<a href="http://www.toronto.edu/">University of Toronto</a>), 
<a href="https://people.epfl.ch/mark.pauly">Mark Pauly</a> 
(<a href="https://www.epfl.ch/en/">EPFL</a>)
</dd>

<dt><b>Sag-free Initialization for Strand-based Hybrid Hair Simulation</b>
	<a href="https://graphics.cs.utah.edu/research/projects/sag-free-hair/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://graphics.cs.utah.edu/research/projects/sag-free-hair/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://graphics.cs.utah.edu/research/projects/sag-free-hair/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://chichenghsu.com/">Jerry Hsu</a> 
(<a href="http://www.utah.edu/">University of Utah</a>) and <a href="https://www.lightspeed-studios.com/">LightSpeed Studios</a>), 
Tongtong Wang, 
Zherong Pan, 
<a href="https://gaoxifeng.github.io/">Xifeng Gao</a> 
(<a href="https://www.lightspeed-studios.com/">LightSpeed Studios</a>), 
<a href="http://www.cemyuksel.com/">Cem Yuksel</a> 
(<a href="http://www.utah.edu/">University of Utah</a> and <a href="https://corp.roblox.com/research/">Roblox Research</a>), 
<a href="https://kuiwuchn.github.io/">Kui Wu</a> 
(<a href="https://www.lightspeed-studios.com/">LightSpeed Studios</a>)
</dd>

<dt><b>CT2Hair: High-fidelity 3D Hair Modeling Using Computed Tomography</b>
	<a href="http://yuefanshen.net/CTHair"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://yuefanshen.net/CTHair"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://yuefanshen.net/CTHair"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="http://yuefanshen.net/CTHair"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/facebookresearch/CT2Hair"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://jhonve.github.io/">Yuefan Shen</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a> and <a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a>), 
<a href="http://www-scf.usc.edu/~saitos/">Shunsuke Saito</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a>), 
<a href="https://ziyanw1.github.io/">Ziyan Wang</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a> and <a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a>), 
<a href="https://www.linkedin.com/in/olivier-maury-7abaa0/">Olivier Maury</a>, 
<a href="https://sites.google.com/view/chengleiwu/">Chenglei Wu</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a>), 
<a href="https://www.cs.cmu.edu/~jkh/">Jessica Hodgins</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>), 
<a href="http://youyizheng.net/">Youyi Zheng</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>), 
<a href="https://sites.google.com/view/gjnam">Giljoo Nam</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a>) 
</dd>

<dt><b>Interactive Hair Simulation on the GPU Using ADMM</b>
	<a href="https://research.nvidia.com/publication/2023-08_interactive-hair-simulation-gpu-using-admm"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/publication/2023-08_interactive-hair-simulation-gpu-using-admm"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://gdaviet.fr/">Gilles Daviet</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>)
</dd>

<dt><b>Multi-layer Thick Shells</b>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://yunuoch.github.io/">Yunuo Chen</a> 
<a href="https://xpandora.github.io/">Tianyi Xie</a>, 
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>), 
<a href="http://www.cemyuksel.com/">Cem Yuksel</a> 
(<a href="http://www.utah.edu/">University of Utah</a> and <a href="https://corp.roblox.com/research/">Roblox Research</a>), 
<a href="https://research.adobe.com/person/danny-kaufman/">Danny Kaufman</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://yangzzzy.github.io/">Yin Yang</a> 
(<a href="http://www.utah.edu/">University of Utah</a>), 
<a href="https://www.math.ucla.edu/~cffjiang/">Chenfanfu Jiang</a>, 
<a href="https://www.math.ucla.edu/~minchen/">Minchen Li</a> 
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>)
</dd>

</dl>

<h2>Cloud Rendering: Your GPU Is Somewhere Else</h2>
<dl>

<dt><b>Trim Regions for Online Computation of From-Region Potentially Visible Sets</b>
	<a href="https://www.tugraz.at/institute/icg/research/team-schmalstieg/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.tugraz.at/institute/icg/research/team-schmalstieg/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.tugraz.at/institute/icg/research/team-schmalstieg/team/philip-voglreiter">Philip Voglreiter</a> 
(<a href="https://www.tugraz.at">Graz University of Technology</a> and <a href="https://www.vrvis.at/">VRVis Forschungs GmbH</a>), 
<a href="https://www.cg.tuwien.ac.at/staff/BernhardKerbl">Bernhard Kerbl</a> 
(<a href="https://www.tuwien.at/">TU Wien</a> and <a href="https://www.inria.fr/en">Inria</a>, <a href="https://univ-cotedazur.fr/">Universite Cote d'Azur</a>), 
Alexander Weinrauch, 
Joerg Hermann Mueller, 
<a href="https://thomasneff.github.io/">Thomas Neff</a>, 
<a href="https://www.markussteinberger.net/">Markus Steinberger</a>, 
<a href="https://www.tugraz.at/institute/icg/research/team-schmalstieg/">Dieter Schmalstieg</a> 
(<a href="https://www.tugraz.at">Graz University of Technology</a>)
</dd>

<dt><b>Potentially Visible Hidden-volume Rendering for Multi-view Warping</b>
	<a href="http://cg.skku.edu/pub/2023-kim-siggraph-pvhv"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://cg.skku.edu/pub/2023-kim-siggraph-pvhv"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://cg.skku.edu/pub/2023-kim-siggraph-pvhv"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Janghun Kim, 
<a href="http://cg.skku.edu/slee/">Sungkil Lee</a> 
(<a href="http://www.skku.edu/eng/">Sungkyunkwan University,</a>)
</dd>

<dt><b>Effect-based Multi-viewer Caching for Cloud-native Rendering</b>
	</dt>
<dd>
Alexander Weinrauch
Wolfgang Tatzgern
Pascal Stadlbauer
Alexis Crickx
Jozef Hladky
Arno Coomans
Martin Winter
Joerg H. Mueller

<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href="https://www.markussteinberger.net/">Markus Steinberger</a> 
(<a href="https://www.tugraz.at">Graz University of Technology</a>)
</dd>

<dt><b>Random-Access Neural Compression of Material Textures</b>
	<a href="https://research.nvidia.com/labs/rtr/neural_texture_compression/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/rtr/neural_texture_compression/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/rtr/neural_texture_compression/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/rtr/neural_texture_compression/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Karthik Vaidyanathan*, 
<a href="https://research.nvidia.com/person/marco-salvi">Marco Salvi</a>*, 
<a href="https://research.nvidia.com/person/bart-wronski">Bartlomiej Wronski</a>*, 
<a href="https://research.nvidia.com/person/tomas-akenine-moller">Tomas Akenine-Moller</a>, 
<a href="https://research.nvidia.com/person/pontus-ebelin">Pontus Ebelin</a>, 
<a href="https://research.nvidia.com/person/aaron-lefohn">Aaron Lefohn</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>) 
*Equal contributors
</dd>

<dt><b>MERF: Memory-Efficient Radiance Fields for Real-time View Synthesis in Unbounded Scenes</b>
	<a href="https://creiser.github.io/merf/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://creiser.github.io/merf/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://creiser.github.io/merf/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/google-research/google-research/tree/master/merf"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://creiser.github.io/">Christian Reiser</a> 
(<a href="https://research.google/">Google Research</a> / <a href="https://tuebingen.ai/">Tubingen AI Center</a> / <a href="https://uni-tuebingen.de/">University of Tubingen</a>), 
<a href="https://szeliski.org/RichardSzeliski.htm">Rick Szeliski</a>, 
<a href="https://dorverbin.github.io/">Dor Verbin</a>, 
<a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, 
<a href="https://bmild.github.io/">Ben Mildenhall</a> 
(<a href="https://research.google/">Google Research</a>), 
<a href="https://www.cvlibs.net/">Andreas Geiger</a> 
(<a href="https://tuebingen.ai/">Tubingen AI Center</a> and <a href="https://uni-tuebingen.de/">University of Tubingen</a>), 
<a href="https://jonbarron.info/">Jon Barron</a>, 
<a href="https://phogzone.com/">Peter Hedman</a> 
(<a href="https://research.google/">Google Research</a>)
</dd>

<dt><b>An Extensible, Data-oriented Architecture for High-performance, Many-world Simulation</b>
	<a href="https://madrona-engine.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://madrona-engine.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.linkedin.com/in/brennan-shacklett-41818810a/">Brennan Shacklett</a>, 
Luc Guy Rosenzweig, 
<a href="https://zhiqiangxie.com/">Zhiqiang Xie</a> 
Bidipta Sarkar, 
(<a href="https://www.stanford.edu/">Stanford University</a>), 
<a href="https://www.andrewszot.com/">Andrew Szot</a>, 
<a href="https://wijmans.xyz/">Erik Wijmans</a> 
(<a href="https://www.gatech.edu/">Georgia Institute of Technology</a>), 
<a href="http://vladlen.info/">Vladlen Koltun</a> 
(<a href="https://www.apple.com/">Apple</a>), 
<a href="https://www.cc.gatech.edu/~dbatra/index.html">Dhruv Batra</a> 
<a href="http://graphics.stanford.edu/~kayvonf/">Kayvon Fatahalian</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>)
</dd>

</dl>

<h2>Diffusion for Geometry</h2>
<dl>

<dt><b>Locally Attentional SDF Diffusion for Controllable 3D Shape Generation</b>
	<a href="https://zhengxinyang.github.io/projects/LAS-Diffusion.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://zhengxinyang.github.io/projects/LAS-Diffusion.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/Zhengxinyang/LAS-Diffusion"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://zhengxinyang.github.io/">Xin-Yang Zheng</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>), 
<a href="https://haopan.github.io/">Hao Pan</a> 
(<a href="http://research.microsoft.com/en-us/labs/asia/">Microsoft Research Asia</a>), 
<a href="https://wang-ps.github.io/">Peng-Shuai Wang</a> 
(<a href="https://www.pku.edu.cn/">Peking University</a>), 
<a href="http://research.microsoft.com/en-us/um/people/xtong/xtong.html">Xin Tong</a>, 
<a href="https://xueyuhanlang.github.io/">Yang Liu</a> 
(<a href="http://research.microsoft.com/en-us/labs/asia/">Microsoft Research Asia</a>), 
<a href="https://www.microsoft.com/en-us/research/people/hshum/">Heung-Yeung Shum</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a> and <a href="https://www.idea.edu.cn/">International Digital Economy Academy</a>)
</dd>

<dt><b>3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models</b>
	<a href="https://1zb.github.io/3DShape2VecSet/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://1zb.github.io/3DShape2VecSet/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://1zb.github.io/3DShape2VecSet/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/1zb/3DShape2VecSet"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://1zb.github.io/">Biao Zhang</a> 
(<a href="https://www.kaust.edu.sa/en/">KAUST</a>), 
<a href="https://tangjiapeng.github.io/">Jiapeng Tang</a>, 
<a href="https://www.niessnerlab.org/">Matthias Niessner</a> 
(<a href="https://www.tum.de/en/">Technical University of Munich</a>), 
<a href="https://peterwonka.net/">Peter Wonka</a> 
(<a href="https://www.kaust.edu.sa/en/">KAUST</a>)
</dd>

<dt><b>Adaptive Local Basis Functions for Shape Completion</b>
	<a href="https://arxiv.org/abs/2307.08348"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2307.08348"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/yinghdb/adaptive-local-basis-functions"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Hui Ying,
<a href="https://tianjiashao.com/">Tianjia Shao</a>, 
He Wang
(<a href="http://www.zju.edu.cn/">Zhejiang University</a>), 
<a href="https://yangzzzy.github.io/">Yin Yang</a> 
(<a href="http://www.utah.edu/">University of Utah</a>), 
<a href="http://kunzhou.net/">Kun Zhou</a> 
(<a href="http://www.zju.edu.cn/">Zhejiang University</a>)
</dd>

<dt><b>Iterative alpha-(de)Blending: A Minimalist Deterministic Diffusion Model</b>
	<a href="https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/tchambon/IADB"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html">Eric Heitz</a> 
(<a href="https://unity.com/">Unity Technologies</a>), 
<a href="https://belcour.github.io/blog/">Laurent Belcour</a> 
(<a href="https://www.intel.com">Intel Corporation</a>), 
Thomas Chambon 
(<a href="https://unity.com/">Unity Technologies</a>)
</dd>

<dt><b>Modulating Pretrained Diffusion Models for Multimodal Image Synthesis</b>
	<a href="https://mcm-diffusion.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://mcm-diffusion.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://cusuh.github.io/">Cusuh Ham</a>, 
<a href="https://faculty.cc.gatech.edu/~hays">James Hays</a> 
(<a href="https://www.gatech.edu/">Georgia Institute of Technology</a>), 
<a href="https://research.adobe.com/person/jingwan-lu/">Jingwan Lu</a>, 
<a href="https://krsingh.cs.ucdavis.edu/">Krishna Kumar Singh</a>, 
<a href="https://zzutk.github.io/">Zhifei Zhang</a>, 
<a href="https://www.tobiashinz.com/">Tobias Hinz</a> 
(<a href="https://www.adobe.com/">Adobe Inc.</a>)
</dd>

<dt><b>COFS COntrolable Furniture Layout Synthesis</b>
	<a href="https://arxiv.org/abs/2205.14657"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2205.14657"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://cemse.kaust.edu.sa/people/person/wamiq-para">Wamiq Reyaz Para</a> 
(<a href="https://www.kaust.edu.sa/en/">KAUST</a>), 
<a href="https://research.adobe.com/person/paul-guerrero/">Paul Guerrero</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://www0.cs.ucl.ac.uk/staff/n.mitra/">Niloy J. Mitra</a> 
(<a href="https://research.adobe.com/">Adobe Research</a> and <a href="http://www.ucl.ac.uk/">University College London</a>), 
<a href="https://peterwonka.net/">Peter Wonka</a> 
(<a href="https://www.kaust.edu.sa/en/">KAUST</a>)
</dd>

</dl>

<h2>Pushing the Boundaries</h2>
<dl>

<dt><b>Coupling Conduction, Convection and Radiative Transfer in a Single Path-Space: Application to Infrared Rendering</b>
	<a href="https://www.irit.fr/STORM/site/coupling-conduction-convection-and-radiative-transfer-in-a-single-path-space/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.irit.fr/STORM/site/coupling-conduction-convection-and-radiative-transfer-in-a-single-path-space/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.irit.fr/STORM/site/coupling-conduction-convection-and-radiative-transfer-in-a-single-path-space/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://megane-bati.github.io/">Megane Bati</a>, 
Stephane Blanco 
(<a href="https://www.univ-tlse3.fr/">Univ. Toulouse</a>), 
Christophe Coustet, 
Vincent Eymet, 
Vincent Forest 
(<a href="https://www.meso-star.com/projects/misc/about-en.html">Meso-Star</a>), 
Richard Fournier 
(<a href="https://www.univ-tlse3.fr/">Univ. Toulouse</a>), 
<a href="http://jacques.gautrais.net/Jacques_Gautrais/Jacques_Gautrais.html">Jacques Gautrais</a> 
(<a href="https://www.univ-tlse3.fr/">Univ. Toulouse</a> and <a href="https://www.cnrs.fr/fr">CNRS</a>), 
<a href="https://www.irit.fr/recherches/STORM/MelladoNicolas/">Nicolas Mellado</a>, 
<a href="https://www.irit.fr/~Mathias.Paulin/index.html">Mathias Paulin</a> 
(<a href="https://www.univ-tlse3.fr/">Univ. Toulouse</a>), 
Benjamin Piaud 
(<a href="https://www.meso-star.com/projects/misc/about-en.html">Meso-Star</a>)
</dd>

<dt><b>Walk on Stars: A Grid-Free Monte Carlo Method for PDEs with Neumann Boundary Conditions</b>
	<a href="https://arxiv.org/abs/2302.11815"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2302.11815"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="http://rohansawhney.io/">Rohan Sawhney</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.bailey-miller.com/">Bailey Miller</a>, 
<a href="https://www.cs.cmu.edu/~igkioule/">Ioannis Gkioulekas</a> 
<a href="https://www.cs.cmu.edu/~kmcrane/">Keenan Crane</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
</dd>

<dt><b>A Practical Walk-on-Boundary Method for Boundary Value Problems</b>
	<a href="https://rsugimoto.net/WoBforBVPsProject/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://rsugimoto.net/WoBforBVPsProject/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://rsugimoto.net/">Ryusuke Sugimoto</a>, 
<a href="https://tyxchen.github.io/">Terry Chen</a>, 
Yiti Jiang, 
<a href="https://cs.uwaterloo.ca/~c2batty/">Christopher Batty</a>, 
<a href="https://cs.uwaterloo.ca/~thachisu/">Toshiya Hachisuka</a> 
(<a href="https://uwaterloo.ca/">University of Waterloo</a>)
</dd>

<dt><b>Boundary Value Caching for Walk on Spheres</b>
	<a href="https://arxiv.org/abs/2302.11825"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2302.11825"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.bailey-miller.com/">Bailey Miller</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
<a href="http://rohansawhney.io/">Rohan Sawhney</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.cs.cmu.edu/~kmcrane/">Keenan Crane</a>, 
<a href="https://www.cs.cmu.edu/~igkioule/">Ioannis Gkioulekas</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
</dd>

<dt><b>Generalizing Shallow Water Simulations with Dispersive Surface Waves</b>
	<a href="https://research.nvidia.com/publication/2023-08_generalizing-shallow-water-simulations-dispersive-surface-waves"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/publication/2023-08_generalizing-shallow-water-simulations-dispersive-surface-waves"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="http://www.stefan-jeschke.com/">Stefan Jeschke</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://pub.ista.ac.at/~wojtan/">Chris Wojtan</a> 
(<a href="https://ist.ac.at/en/home/">IST Austria</a>)
</dd>

<dt><b>Beyond Chainmail: Computational Modeling of Discrete Interlocking Materials</b>
	<a href="https://tangpengbin.github.io/publications/DIM/DIM.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://tangpengbin.github.io/publications/DIM/DIM.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://tangpengbin.github.io/publications/DIM/DIM.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>

<a href="https://tangpengbin.github.io/">Pengbin Tang</a> 
(<a href="https://www.umontreal.ca/">Universite de Montreal</a> and <a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="http://crl.ethz.ch/people/coros/index.html">Stelian Coros</a>, 
<a href="https://n.ethz.ch/~bthomasz/index.html">Bernhard Thomaszewski</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>)
</dd>

</dl>

<h2>Character Animation</h2>
<dl>

<dt><b>Composite Motion Learning With Task Control</b>
	<a href="https://github.com/xupei0610/CompositeMotion"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.03286"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://youtu.be/mcRAxwoTh3E"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/xupei0610/CompositeMotion"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Pei Xu
(<a href="http://www.clemson.edu/">Clemson University</a> and <a href="https://www.roblox.com/">Roblox</a>), 
Xiumin Shang
(<a href="https://www.ucmerced.edu/">University of California, Merced</a>), 
<a href="https://people.computing.clemson.edu/~vbz/">Victor Zordan</a> 
(<a href="https://www.roblox.com/">Roblox</a> and <a href="http://www.clemson.edu/">Clemson University</a>), 
<a href="https://people.computing.clemson.edu/~ioannis/">Ioannis Karamouzas</a> 
(<a href="http://www.clemson.edu/">Clemson University</a>) 
</dd>

<dt><b>Example-based Motion Synthesis via Generative Motion Matching</b>
	<a href="http://weiyuli.xyz/GenMM/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://weiyuli.xyz/GenMM/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://weiyuli.xyz/GenMM/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/wyysf-98/GenMM"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="http://weiyuli.xyz/">Weiyu Li</a> 
(<a href="https://www.sdu.edu.cn/">Shandong University</a>), 
<a href="https://xuelin-chen.github.io/">Xuelin Chen</a> 
(<a href="https://ai.tencent.com/">Tencent AI Lab</a>), 
<a href="https://peizhuoli.github.io/">Peizhuo Li</a>, 
<a href="https://igl.ethz.ch/people/sorkine/">Olga Sorkine-Hornung</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="https://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a> 
(<a href="https://english.pku.edu.cn/">Peking University</a>)
</dd>

<dt><b>Learning Physically Simulated Tennis Skills from Broadcast Videos</b>
	<a href="https://cs.stanford.edu/~haotianz/research/vid2player3d/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://cs.stanford.edu/~haotianz/research/vid2player3d/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://cs.stanford.edu/~haotianz/research/vid2player3d/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://cs.stanford.edu/~haotianz/">Haotian Zhang</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>), 
<a href="https://www.ye-yuan.com/">Ye Yuan</a>, 
<a href="https://research.nvidia.com/labs/srl/authors/viktor-makoviychuk/">Viktor Makoviychuk</a>, 
<a href="https://nv-tlabs.github.io/author/yunrong-guo/">Yunrong Guo</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> / <a href="https://www.utoronto.ca/">University of Toronto</a> / <a href="https://vectorinstitute.ai/">Vector Institute</a>), 
<a href="https://xbpeng.github.io/">Xue Bin Peng</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://www.sfu.ca/">Simon Fraser University</a>), 
<a href="http://graphics.stanford.edu/~kayvonf/">Kayvon Fatahalian</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>)
</dd>

<dt><b>DOC: Differentiable Optimal Control for Retargeting Motions Onto Legged Robots</b>
	<a href="https://la.disneyresearch.com/publication/doc-differentiable-optimal-control-for-retargeting-motions-onto-legged-robots/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://la.disneyresearch.com/publication/doc-differentiable-optimal-control-for-retargeting-motions-onto-legged-robots/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://la.disneyresearch.com/publication/doc-differentiable-optimal-control-for-retargeting-motions-onto-legged-robots/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Ruben Grandia 
(<a href="https://www.disneyresearch.com/">Disney Research</a>), 
Farbod Farshidian 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>), 
Espen Knoop, 
<a href="https://schumacher.graphics/">Christian Schumacher</a> 
(<a href="https://www.disneyresearch.com/">Disney Research</a>), 
Marco Hutter 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="http://baecher.info/">Moritz Bacher</a> 
(<a href="https://www.disneyresearch.com/">Disney Research</a>)
</dd>

<dt><b>CALM: Conditional Adversarial Latent Models for Directable Virtual Characters</b>
	<a href="https://research.nvidia.com/labs/par/calm/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/par/calm/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/par/calm/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/NVlabs/CALM"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://research.nvidia.com/person/chen-tessler">Chen Tessler</a>, 
<a href="https://research.nvidia.com/person/yoni-kasten">Yoni Kasten</a>, 
<a href="https://research.nvidia.com/labs/toronto-ai/author/yunrong-guo/">Yunrong Guo</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://research.nvidia.com/person/shie-mannor">Shie Mannor</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://www.technion.ac.il/en/home-2/">Technion - Israel Institute of Technology</a>), 
<a href="https://research.nvidia.com/person/gal-chechik">Gal Chechik</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://www.biu.ac.il/en">Bar-Ilan University</a>), 
<a href="https://xbpeng.github.io/">Xue Bin Peng</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://www.sfu.ca/">Simon Fraser University</a>)
</dd>

<dt><b>RSMT: Real-time Stylized Motion Transition for Characters</b>
	<a href="https://arxiv.org/abs/2306.11970"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2306.11970"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/yuyujunjun/RSMT-Realtime-Stylized-Motion-Transition"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://yuyujunjun.github.io/">Xiangjun Tang</a>, 
Linjun Wu
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>), 
<a href="https://eps.leeds.ac.uk/computing/staff/868/dr-he-wang">He Wang</a> 
(<a href="https://www.leeds.ac.uk/">University of Leeds</a>), 
Bo Hu, 
Xu Gong, 
Yuchen Liao, 
Songnan Li, 
Qilong Kou 
(<a href="https://www.tencent.com">Tencent Technology Co., Ltd.</a>), 
<a href="http://www.cad.zju.edu.cn/home/jin/">Xiaogang Jin</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>) 
</dd>

</dl>

<h2>Colorful Topics In Imaging</h2>
<dl>

<dt><b>Image Vectorization and Editing via Linear Gradient Layer Decomposition</b>
	<a href="https://cragl.cs.gmu.edu/gradientlayers/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://cragl.cs.gmu.edu/gradientlayers/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://cragl.cs.gmu.edu/gradientlayers/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://zhengjun-du.github.io/">Zheng-Jun Du</a> 
(<a href="http://www.studyinqinghai.com/">Qinghai University</a> and <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>), 
Liang-Fu Kang 
(<a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>), 
<a href="https://jianchaotan.github.io/">Jianchao Tan</a> 
(<a href="https://ir.kuaishou.com/">Kuaishou Technology</a>), 
<a href="https://cs.gmu.edu/~ygingold/">Yotam Gingold</a> 
(<a href="https://www.gmu.edu/">George Mason University</a>), 
<a href="https://cg.cs.tsinghua.edu.cn/people/~kun/">Kun Xu</a> 
(<a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>)
</dd>

<dt><b>ColorfulCurves: Palette-aware Lightness Control and Color Editing via Sparse Optimization</b>
	<a href="https://cragl.cs.gmu.edu/colorfulcurves/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://cragl.cs.gmu.edu/colorfulcurves/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://cragl.cs.gmu.edu/colorfulcurves/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/tedchao/ColorfulCurves"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://mason.gmu.edu/~cchao8/">Cheng-Kang (Ted) Chao</a> 
(<a href="https://www.gmu.edu/">George Mason University</a>), 
Jason Klein 
(<a href="https://www.cornell.edu/">Cornell University</a>), 
<a href="https://jianchaotan.github.io/">Jianchao Tan</a> 
(<a href="https://ir.kuaishou.com/">Kuaishou Technology</a>), 
<a href="https://www.jiechevarria.com/">Jose Echevarria</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://cs.gmu.edu/~ygingold/">Yotam Gingold</a> 
(<a href="https://www.gmu.edu/">George Mason University</a>)
</dd>

<dt><b>Seeing Photons in Color</b>
	<a href="https://wisionlab.com/project/seeing-photons-in-color/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://wisionlab.com/project/seeing-photons-in-color/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://wisionlab.com/project/seeing-photons-in-color/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://sizhuoma.netlify.app/">Sizhuo Ma</a> 
(<a href="https://www.wisc.edu/">University of Wisconsin-Madison</a> and <a href="https://research.snap.com/">Snap Research</a>), 
<a href="https://wisionlab.com/people/varun-sundar/">Varun Sundar</a> 
(<a href="https://www.wisc.edu/">University of Wisconsin-Madison</a>), 
Paul Mos, 
Claudio Bruschini, 
<a href="https://people.epfl.ch/edoardo.charbon?lang=en">Edoardo Charbon</a> 
(<a href="https://www.epfl.ch/en/">EPFL</a>), 
<a href="https://wisionlab.com/people/mohit-gupta/">Mohit Gupta</a> 
(<a href="https://www.wisc.edu/">University of Wisconsin-Madison</a>)
</dd>

<dt><b>Guided Linear Upsampling</b>
	<a href="https://arxiv.org/abs/2307.09582"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2307.09582"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Shuangbing Song, 
Fan Zhong, 
Tianju Wang, 
Xueying Qin, 
<a href="http://irc.cs.sdu.edu.cn/~chtu/index.html">Changhe Tu</a> 
(<a href="https://www.en.sdu.edu.cn/">Shandong University</a>) 
</dd>

<dt><b>Language-based Photo Color Adjustment for Graphic Designs</b>
	<a href="https://arxiv.org/abs/2308.03059"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2308.03059"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Zhenwei Wang
(<a href="http://www.cityu.edu.hk/">City University of Hong Kong</a>), 
<a href="http://nxzhao.com/">Nanxuan Zhao</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
Gerhard Hancke, 
<a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a> 
(<a href="http://www.cityu.edu.hk/">City University of Hong Kong</a>)
</dd>

<dt><b>Algebraic Smooth Occluding Contours</b>
	<a href="https://arxiv.org/abs/2306.01973"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2306.01973"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="http://ryanjcapouellez.com/">Ryan Capouellez</a>, 
<a href="https://jcdai.github.io/">Jiacheng Dai</a> 
(<a href="https://www.nyu.edu/">New York University</a>), 
<a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://cims.nyu.edu/gcl/denis.html">Denis Zorin</a> 
(<a href="https://www.nyu.edu/">New York University</a>) 
</dd>

</dl>

<h2>Surfaces, Strips, Lights</h2>
<dl>

<dt><b>Singularity Computation for Rational Parametric Surfaces Using Moving Planes</b>
	</dt>
<dd>
<a href="http://www.mmrc.iss.ac.cn/~xhjia/">Xiaohong Jia</a> 
(<a href="https://english.ucas.ac.cn/">University of the Chinese Academy of Sciences</a>), 
<a href="http://staff.ustc.edu.cn/~chenfl/econtact.htm">Falai Chen</a> 
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>), 
<a href="https://yaoshanshan.github.io/math/">Shanshan Yao</a> 
(<a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications</a>)
</dd>

<dt><b>Differentiable Stripe Patterns for Inverse Design of Structured Surfaces</b>
	<a href="http://crl.ethz.ch/publications/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://crl.ethz.ch/publications/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://inf.ethz.ch/people/people-atoz/person-detail.MjgyNzk2.TGlzdC8zMDQsLTIxNDE4MTU0NjA=.html">Juan Sebastian Montes Maestre</a>, 
<a href="https://inf.ethz.ch/people/people-atoz/person-detail.MjQ5OTA3.TGlzdC8zMDQsLTIxNDE4MTU0NjA=.html">Yinwei Du</a>, 
<a href="https://inf.ethz.ch/people/people-atoz/person-detail.Mjk4MTgx.TGlzdC8zMDQsLTIxNDE4MTU0NjA=.html">Ronan Hinchet</a>, 
<a href="https://n.ethz.ch/~bthomasz/index.html">Bernhard Thomaszewski</a>, 
<a href="http://crl.ethz.ch/people/coros/index.html">Stelian Coros</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>)

</dd>

<dt><b>Deployable Strip Structures</b>
	<a href="https://www.geometrie.tuwien.ac.at/pottmann/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://cemse.kaust.edu.sa/cs/people/person/daoming-liu">Daoming Liu</a>* 
(<a href="https://www.kaust.edu.sa/en/">KAUST</a>), 
Davide Pellis* 
(<a href="https://www.isti.cnr.it/en/">ISTI-CNR</a>), 
Yu-Chou Chiang 
(<a href="https://www.nchu.edu.tw/en-index">National Chung Hsing University</a>), 
<a href="https://cemse.kaust.edu.sa/people/person/florian-rist">Florian Rist</a> 
(<a href="https://www.kaust.edu.sa/en/">KAUST</a>), 
<a href="https://wallner.ist.tugraz.at/">Johannes Wallner</a> 
(<a href="https://www.tugraz.at/en/home/">TU Graz</a>), 
<a href="https://www.geometrie.tuwien.ac.at/pottmann/">Helmut Pottmann</a> 
(<a href="https://www.kaust.edu.sa/en/">KAUST</a>)
* equally contributing authors
</dd>

<dt><b>B-rep Matching for Collaborating Across CAD Systems</b>
	<a href="https://homes.cs.washington.edu/~adriana/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://homes.cs.washington.edu/~benjones/">Benjamin Jones</a>*, 
<a href="https://sites.uw.edu/jamesn8/">James Noeckel</a>*, 
<a href="https://mkodnongbua.com/">Milin Kodnongbua</a>* 
(<a href="https://www.washington.edu/">University of Washington</a>), 
Ilya Baran 
(<a href="https://www.ptc.com/">PTC Inc.</a>), 
<a href="https://homes.cs.washington.edu/~adriana/">Adriana Schulz</a> 
(<a href="https://www.washington.edu/">University of Washington</a>)
* Equal contribution
</dd>

<dt><b><span>∇</span>-Prox: Differentiable Proximal Algorithm Modeling for Large-scale Optimization</b>
	<a href="https://light.princeton.edu/publication/delta_prox/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://light.princeton.edu/publication/delta_prox/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/princeton-computational-imaging/Delta-Prox"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://zeqiang-lai.github.io/">Zeqiang Lai</a> 
(<a href="https://english.bit.edu.cn/">Beijing Institute of Technology</a>), 
<a href="https://kxwei.net/">Kaixuan Wei</a> 
(<a href="https://www.mcgill.ca/">McGill University</a> and <a href="https://www.cs.princeton.edu/">Princeton University</a>), 
<a href="https://ying-fu.github.io/publication.html">Ying Fu</a> 
(<a href="https://english.bit.edu.cn/">Beijing Institute of Technology</a>), 
Philipp Hartel 
(<a href="https://www.iee.fraunhofer.de/en.html">Fraunhofer IEE</a> and <a href="https://www.uni-kassel.de/uni/">University of Kassel</a>), 
<a href="https://www.cs.princeton.edu/~fheide/">Felix Heide</a> 
(<a href="https://www.cs.princeton.edu/">Princeton University</a>) 
</dd>

<dt><b>Data-driven Digital Lighting Design for Residential Indoor Spaces</b>
	<a href="https://www.youtube.com/watch?v=Pxz3iSuNHDs"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Haocheng Ren, 
Hangming Fan, 
<a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a> 
(<a href="http://www.zju.edu.cn/">Zhejiang University</a>), 
Yuchi Huo 
(<a href="http://www.zju.edu.cn/">Zhejiang University</a> and <a href="https://en.zhejianglab.com/">Zhejiang Lab</a>), 
Rui Tang 
(KooLab, Manycore Tech Inc.), 
Lei Wang 
(<a href="https://www.raysengine.com/">RaysEngine Tech Inc.</a>), 
<a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a> 
(<a href="http://www.zju.edu.cn/">Zhejiang University</a>)
</dd>

</dl>

<h2>Material Rendering</h2>
<dl>

<dt><b>A Full-wave Reference Simulator for Computing Surface Reflectance</b>
	<a href="https://blaire9989.github.io/assets/1_BEMsim3D/project.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://blaire9989.github.io/assets/1_BEMsim3D/project.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://blaire9989.github.io/assets/1_BEMsim3D/project.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/blaire9989/BEMsim3D/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://blaire9989.github.io/">Yunchen Yu</a> 
(<a href="https://www.cornell.edu/">Cornell University</a>), 
<a href="https://mandyxmq.github.io/">Mengqi (Mandy) Xia</a> 
(<a href="https://www.epfl.ch/en/">EPFL</a>), 
<a href="https://www.graphics.cornell.edu/~bjw/">Bruce Walter</a> 
(<a href="https://www.cornell.edu/">Cornell University</a>), 
<a href="https://michielssen.engin.umich.edu/">Eric Michielssen</a> 
(<a href="https://umich.edu/">University of Michigan</a>), 
<a href="https://www.cs.cornell.edu/~srm/">Steve Marschner</a> 
(<a href="https://www.cornell.edu/">Cornell University</a>)
</dd>

<dt><b>Pyramid Texture Filtering</b>
	<a href="https://rewindl.github.io/pyramid_texture_filtering/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://rewindl.github.io/pyramid_texture_filtering/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/RewindL/pyramid_texture_filtering"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="http://zhangqing-home.net/">Qing Zhang</a>, 
<a href="https://github.com/RewindL/">Hao Jiang</a> 
(<a href="https://www.sysu.edu.cn/sysuen/">Sun Yat-sen University</a>), 
<a href="https://nieyongwei.net/">Yongwei Nie</a> 
(<a href="https://www.scut.edu.cn/en/">South China University of Technology</a>), 
<a href="https://isee-ai.cn/~zhwshi/index.html">Wei-Shi Zheng</a> 
(<a href="https://www.sysu.edu.cn/sysuen/">Sun Yat-sen University</a>)
</dd>

<dt><b>Textured Mesh Quality Assessment: Large-scale Dataset and Deep Learning-based Quality Metric</b>
	<a href="https://arxiv.org/abs/2202.02397"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2202.02397"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://datasets.liris.cnrs.fr/textured-mesh-quality-assessment-dataset-version1"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/MEPP-team/Graphics-LPIPS"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://yananehme.github.io/">Yana Nehme</a>, 
<a href="https://perso.liris.cnrs.fr/johanna.delanoy/">Johanna Delanoy</a>, 
<a href="https://liris.cnrs.fr/en/member-page/florent-dupont">Florent Dupont</a>, 
<a href="https://perso.univ-lyon1.fr/jean-philippe.farrugia/index_e.html">Jean-Philippe Farrugia</a> 
(Univ Lyon, UCBL, CNRS, INSA Lyon, LIRIS, UMR5205), 
<a href="http://pagesperso.ls2n.fr/~lecallet-p/">Patrick Le Callet</a> 
(Nantes Universite, Ecole Centrale Nantes, CNRS, LS2N, UMR 6004), 
<a href="https://perso.liris.cnrs.fr/guillaume.lavoue/">Guillaume Lavoue</a> 
(Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE,)
</dd>

<dt><b>NeuSample: Importance Sampling for Neural Materials</b>
	<a href="https://cseweb.ucsd.edu/~viscomp/projects/neusample/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://cseweb.ucsd.edu/~viscomp/projects/neusample/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://cseweb.ucsd.edu/~viscomp/projects/neusample/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/bing-xu-graphics/neusample_release"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	<img src="new.gif"></dt>
<dd>
<a href="https://bingxu.tech/">Bing Xu</a>, 
Liwen Wu 
(<a href="https://ucsd.edu/">UC San Diego</a>), 
<a href="http://www.miloshasan.net/">Milos Hasan</a>, 
Fujun Luan, 
<a href="http://iliyan.com/">Iliyan Georgiev</a>, 
Zexiang Xu
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a> 
(<a href="https://ucsd.edu/">UC San Diego</a>) 
</dd>

<dt><b>Metameric: Spectral Uplifting via Controllable Color Constraints</b>
	<a href="https://graphics.tudelft.nl/Publications-new/2023/RE23/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://graphics.tudelft.nl/Publications-new/2023/RE23/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://graphics.tudelft.nl/Publications-new/2023/RE23/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/computer-graphics-and-visualization/people/mark-van-de-ruit">Mark van de Ruit</a>, 
<a href="https://graphics.tudelft.nl/~eisemann/">Elmar Eisemann</a> 
(<a href="http://www.tudelft.nl/">Delft University of Technology</a>) 
</dd>

<dt><b>NeRF-Texture: Texture Synthesis With Neural Radiance Fields</b>
	<a href="https://yihua7.github.io/NeRF-Texture-web/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://yihua7.github.io/NeRF-Texture-web/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://yihua7.github.io/NeRF-Texture-web/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/yihua7/NeRF-Texture"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/yihua7/NeRF-Texture"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://yihua7.github.io/website/">Yi-Hua Huang</a>
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a> and <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>), 
<a href="https://yanpei.me/">Yan-Pei Cao</a>
(<a href="https://github.com/TencentARC">ARC Lab, Tencent PCG</a>), 
<a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a> 
(<a href="http://www.cardiff.ac.uk/">Cardiff University</a>), 
Ying Shan
(<a href="https://github.com/TencentARC">ARC Lab, Tencent PCG</a>), 
<a href="http://geometrylearning.com/">Lin Gao</a> 
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a> and <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>)
</dd>

</dl>

<h2>Most Def: Fast, Large and Learned Deformables</h2>
<dl>

<dt><b>Fast Complementary Dynamics via Skinning Eigenmodes</b>
	<a href="https://arxiv.org/abs/2303.11886"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2303.11886"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Otman Benchekroun 
(<a href="http://www.toronto.edu/">University of Toronto</a>), 
<a href="https://eriszhang.github.io/">Jiayi Eris Zhang</a> 
(<a href="https://engineering.stanford.edu/">Stanford University</a>), 
<a href="https://research.adobe.com/person/siddhartha-chaudhuri/">Siddhartha Chaudhuri</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://www.dgp.toronto.edu/~eitan/">Eitan Grinspun</a> 
(<a href="http://www.toronto.edu/">University of Toronto</a>), 
<a href="https://research.adobe.com/person/yi-zhou/">Yi Zhou</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://research.adobe.com/">Adobe Research</a>) 
</dd>

<dt><b>Motion From Shape Change</b>
	<a href="https://olligross.github.io/projects/MotionFromShapeChange/MotionFromShapeChange_project.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://olligross.github.io/projects/MotionFromShapeChange/MotionFromShapeChange_project.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://olligross.github.io/projects/MotionFromShapeChange/MotionFromShapeChange_project.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://olligross.github.io/projects/MotionFromShapeChange/MotionFromShapeChange_project.html"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://olligross.github.io/">Oliver Gross</a> 
(<a href="https://www.tu.berlin/">TU Berlin</a>), 
<a href="https://www.its.caltech.edu/~ysoliman/index.html">Yousuf Soliman</a> 
(<a href="https://www.caltech.edu/">Caltech</a>), 
<a href="https://marcelpadilla.github.io/">Marcel Padilla</a>, 
<a href="https://page.math.tu-berlin.de/~knoeppel/">Felix Knoppel</a>, 
<a href="https://page.math.tu-berlin.de/~pinkall/">Ulrich Pinkall</a> 
(<a href="https://www.tu.berlin/">TU Berlin</a>), 
<a href="http://users.cms.caltech.edu/~ps/">Peter Schroder</a> 
(<a href="https://www.caltech.edu/">Caltech</a>)
</dd>

<dt><b>A Sparse Distributed Gigascale Resolution Material Point Method</b>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://yuxingqiu.github.io/">Yuxing Qiu</a>
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>), 
Samuel Temple Reeve
(<a href="https://www.ornl.gov/">Oak Ridge National Laboratory</a>), 
<a href="https://www.math.ucla.edu/~minchen/">Minchen Li</a> 
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>), 
<a href="https://yangzzzy.github.io/">Yin Yang</a> 
(<a href="http://www.utah.edu/">University of Utah</a>), 
Stuart Slattery
(<a href="https://www.ornl.gov/">Oak Ridge National Laboratory</a>), 
<a href="https://www.math.ucla.edu/~cffjiang/">Chenfanfu Jiang</a> 
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>)
</dd>

<dt><b>Second-order Stencil Descent for Interior-point Hyperelasticity</b>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://lanlei.github.io/">Lei Lan</a> 
(<a href="http://www.utah.edu/">University of Utah</a>), 
<a href="https://www.math.ucla.edu/~minchen/">Minchen Li</a>, 
<a href="https://www.math.ucla.edu/~cffjiang/">Chenfanfu Jiang</a> 
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>), 
<a href="https://wanghmin.github.io/">Huamin Wang</a> 
(<a href="https://www.linctex.com/">Style3D</a>), 
<a href="https://yangzzzy.github.io/">Yin Yang</a> 
(<a href="http://www.utah.edu/">University of Utah</a>) 
</dd>

<dt><b>Nonlinear Compliant Modes for Large-deformation Analysis of Flexible Structures</b>
	<a href="http://crl.ethz.ch/publications/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://crl.ethz.ch/publications/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Simon Duenser,
<a href="https://n.ethz.ch/~bthomasz/index.html">Bernhard Thomaszewski</a>, 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="https://people.inf.ethz.ch/poranner/">Roi Poranne</a>, 
(<a href="https://www.haifa.ac.il/?lang=en">University of Haifa</a> and <a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="http://crl.ethz.ch/people/coros/index.html">Stelian Coros</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>)
</dd>

<dt><b>Data-Free Learning of Reduced-Order Kinematics</b>
	<a href="https://nmwsharp.com/research/neural-physics-subspaces/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://nmwsharp.com/research/neural-physics-subspaces/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://nmwsharp.com/research/neural-physics-subspaces/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/nmwsharp/neural-physics-subspaces"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://nmwsharp.com/">Nicholas Sharp</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://www.utoronto.ca/">University of Toronto</a>), 
<a href="https://crisrom002.gitlab.io/">Cristian Romero</a> 
(<a href="https://www.urjc.es/">Universidad Rey Juan Carlos</a>), 
<a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://www.cs.utexas.edu/users/evouga/">Etienne Vouga</a> 
(<a href="https://www.utexas.edu/">The University of Texas at Austin</a>), 
<a href="https://www.cs.mcgill.ca/~kry/">Paul G. Kry</a> 
(<a href="https://www.mcgill.ca/">McGill University</a>), 
<a href="http://142.93.146.228/researchdb/">David I.W. Levin</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>)
</dd>

</dl>

<h2>Surface Reconstruction</h2>
<dl>

<dt><b>Globally Consistent Normal Orientation for Point Clouds by Regularizing the Winding-Number Field</b>
	<a href="https://xrvitd.github.io/Projects/GCNO/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://xrvitd.github.io/Projects/GCNO/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://xrvitd.github.io/Projects/GCNO/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/Xrvitd/GCNO"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://xrvitd.github.io/index.html">Rui Xu</a> 
(<a href="https://www.en.sdu.edu.cn/">Shandong University</a>), 
<a href="https://frank-zy-dou.github.io/">Zhiyang Dou</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a>), 
<a href="https://ningnawang.github.io/">Ningna Wang</a> 
(<a href="https://www.utdallas.edu/">The University of Texas at Dallas</a>), 
<a href="http://irc.cs.sdu.edu.cn/~shiqing/index.html">Shiqing Xin</a> 
(<a href="https://www.en.sdu.edu.cn/">Shandong University</a>), 
Shuangmin Chen 
(<a href="https://en.qust.edu.cn/">Qingdao University of Science and Technology</a>), 
Mingyan Jiang 
(<a href="https://www.en.sdu.edu.cn/">Shandong University</a>), 
<a href="https://personal.utdallas.edu/~xguo/">Xiaohu Guo</a> 
(<a href="https://www.utdallas.edu/">The University of Texas at Dallas</a>), 
<a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html">Wenping Wang</a> 
(<a href="https://www.tamu.edu/">Texas A&amp;M University</a>), 
<a href="http://irc.cs.sdu.edu.cn/~chtu/index.html">Changhe Tu</a> 
(<a href="https://www.en.sdu.edu.cn/">Shandong University</a>) 
</dd>

<dt><b>Surface Reconstruction From Point Clouds Without Normals by Parametrizing the Gauss Formula</b>
	<a href="https://github.com/jsnln/ParametricGaussRecon"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	<a href="https://jsnln.github.io/tog2022_pgr/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://jsnln.github.io/tog2022_pgr/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://jsnln.github.io/tog2022_pgr/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://jsnln.github.io/tog2022_pgr/index.html"><img alt="Paper Presentation" src="Ppt.png" border="0"></a>
	<a href="https://github.com/jsnln/ParametricGaussRecon"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://jsnln.github.io/">Siyou Lin</a>, 
Dong Xiao 
(<a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>), 
<a href="https://shizqi.github.io/">Zuoqiang Shi</a> 
(<a href="https://ymsc.tsinghua.edu.cn/en/">Yau Mathematical Sciences Center</a> and <a href="https://www.bimsa.cn/">Yanqi Lake Beijing Institute of Mathematical Sciences and Applications (BIMSA)</a>), 
<a href="https://binwangthss.github.io/">Bin Wang</a> 
(<a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> and <a href="https://www.bnrist.tsinghua.edu.cn/bnristen/">Beijing National Research Center for Information Science and Technology (BNRIST)</a>)
</dd>

<dt><b>Restricted Delaunay Triangulation for Explicit Surface Reconstruction</b>
	</dt>
<dd>
Pengfei Wang
Zixiong Wang
Shiqing Xin
<a href="https://gaoxifeng.github.io/">Xifeng Gao</a> 
(<a href="https://www.lightspeed-studios.com/">LightSpeed Studios</a>), 
<a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html">Wenping Wang</a> 
(<a href="https://www.tamu.edu/">Texas A&amp;M University</a>), 
<a href="http://irc.cs.sdu.edu.cn/~chtu/index.html">Changhe Tu</a> 
(<a href="https://www.en.sdu.edu.cn/">Shandong University</a>) 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>Locally Meshable Frame Fields</b>
	<a href="https://www.algohex.eu/publications/locally-meshable-frame-fields/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.algohex.eu/publications/locally-meshable-frame-fields/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.algohex.eu/team/liu/">Heng Liu</a>, 
<a href="https://www.algohex.eu/team/bommes/">David Bommes</a> 
(<a href="https://www.unibe.ch/index_eng.html">University of Bern</a>)
</dd>

<dt><b>Surface and Edge Detection for Primitive Fitting of Point Clouds</b>
	</dt>
<dd>
Yuanqi Li, 
Shun Liu, 
Xinran Yang 
(<a href="https://www.nju.edu.cn/en/">Nanjing University</a>), 
Jianwei Guo 
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a>), 
Jie Guo, 
<a href="https://cs.nju.edu.cn/ywguo/index.htm">Yanwen Guo</a> 
(<a href="https://www.nju.edu.cn/en/">Nanjing University</a>)
</dd>

<dt><b>Variational Shape Reconstruction via Quadric Error Metrics</b>
	<a href="https://filesender.renater.fr/?s=download&amp;token=659700ce-9529-4118-b8d4-bf0b7323aa9b"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Tong Zhao 
(<a href="http://www-sop.inria.fr/index_en.shtml">Inria Sophia-Antipolis</a> / <a href="https://univ-cotedazur.fr/">Universite Cote dâ€™Azur</a> / <a href="https://www.telecom-paris.fr/en/research/laboratories/information-processing-and-communication-laboratory-ltci">LTCI, Telecom Paris</a>), 
<a href="http://www-sop.inria.fr/members/Laurent.Buse/index.html">Laurent Buse</a>, 
<a href="https://www-sop.inria.fr/members/David.Cohen-Steiner/">David Cohen-Steiner</a> 
(<a href="http://www-sop.inria.fr/index_en.shtml">Inria Sophia-Antipolis</a> and <a href="https://univ-cotedazur.fr/">Universite Cote dâ€™Azur</a>), 
<a href="https://perso.telecom-paristech.fr/boubek/">Tamy Boubekeur</a>, 
<a href="https://research.adobe.com/person/jean-thiery/">Jean-Marc Thiery</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://team.inria.fr/titane/pierre-alliez/">Pierre Alliez</a> 
(<a href="http://www-sop.inria.fr/index_en.shtml">Inria Sophia-Antipolis</a> and <a href="https://univ-cotedazur.fr/">Universite Cote dâ€™Azur</a>)
</dd>

</dl>

<h2>All About Meshes</h2>
<dl>

<dt><b>Surface Simplification using Intrinsic Error Metrics</b>
	<a href="https://markjgillespie.com/Research/intrinsic-coarsening/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://markjgillespie.com/Research/intrinsic-coarsening/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.dgp.toronto.edu/~hsuehtil/">Hsueh-Ti Derek Liu</a> 
(<a href="https://corp.roblox.com/research/">Roblox Research</a>), 
<a href="https://markjgillespie.com/">Mark Gillespie</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>), 
<a href="https://www.gitshowcase.com/benchislett">Benjamin Chislett</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a>), 
<a href="https://nmwsharp.com/">Nicholas Sharp</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a>), 
<a href="https://www.cs.cmu.edu/~kmcrane/">Keenan Crane</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
</dd>

<dt><b>Robust Low-poly Meshing for General 3D Models</b>
	<a href="https://zhenchen-jay.github.io/publication/robustlowpolymeshing/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://zhenchen-jay.github.io/publication/robustlowpolymeshing/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://zhenchen-jay.github.io/publication/robustlowpolymeshing/"><img alt="Paper Data" src="Data.png" border="0"></a>
	</dt>
<dd>
<a href="https://zhenchen-jay.github.io/">Zhen Chen</a> 
(<a href="https://www.lightspeed-studios.com/">LightSpeed Studios</a> and <a href="https://www.utexas.edu/">The University of Texas at Austin</a>), 
Zherong Pan, 
<a href="https://kuiwuchn.github.io/">Kui Wu</a> 
(<a href="https://www.lightspeed-studios.com/">LightSpeed Studios</a>), 
<a href="https://www.cs.utexas.edu/users/evouga/">Etienne Vouga</a> 
(<a href="https://www.utexas.edu/">The University of Texas at Austin</a>), 
<a href="https://gaoxifeng.github.io/">Xifeng Gao</a> 
(<a href="https://www.lightspeed-studios.com/">LightSpeed Studios</a>)
</dd>

<dt><b>Evolutionary Piecewise Developable Approximations</b>
	<a href="https://ustc-gcl-f.github.io/projects/EvolutionaryDevelop/EvoDevelop.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://ustc-gcl-f.github.io/projects/EvolutionaryDevelop/EvoDevelop.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://ustc-gcl-f.github.io/projects/EvolutionaryDevelop/EvoDevelop.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://ustc-gcl-f.github.io/projects/EvolutionaryDevelop/EvoDevelop.html"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Zheng-Yu Zhao*, 
Mo Li*, 
Zheng Zhang, 
<a href="https://qingfang1208.github.io/">Qing Fang</a>, 
<a href="http://staff.ustc.edu.cn/~lgliu/">Ligang Liu</a>, 
<a href="https://ustc-gcl-f.github.io/">Xiao-Ming Fu</a> 
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>)
(* Joint first authors)
</dd>

<dt><b>Micro-Mesh Construction</b>
	<a href="https://micromesh.di.unimi.it/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://micromesh.di.unimi.it/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://micromesh.di.unimi.it/"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://micromesh.di.unimi.it/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://homes.di.unimi.it/~maggiordomo/">Andrea Maggiordomo</a> 
(<a href="https://www.unimi.it/en">University of Milan</a>), 
<a href="https://developer.nvidia.com/blog/author/hmoreton/">Henry Moreton</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://tarini.di.unimi.it/">Marco Tarini</a> 
(<a href="https://www.unimi.it/en">University of Milan</a>)
</dd>

<dt><b>Somigliana Coordinates: An Elasticity-derived Approach for Cage Deformation</b>
	<a href="https://jiongchen.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://jiongchen.github.io/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://jiongchen.github.io/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://jiongchen.github.io/">Jiong Chen</a> 
(<a href="https://www.polytechnique.edu/en">Ecole Polytechnique</a>), 
<a href="http://fernandodegoes.org/">Fernando de Goes</a> 
(<a href="https://www.pixar.com/">Pixar Animation Studios</a>), 
<a href="https://pages.saclay.inria.fr/mathieu.desbrun/">Mathieu Desbrun</a> 
(<a href="https://www.inria.fr/en">Inria</a> and <a href="https://www.polytechnique.edu/en">Ecole Polytechnique</a>)
</dd>

<dt><b>Mesh Density Adaptation for Template-based Shape Reconstruction</b>
	<a href="https://arxiv.org/abs/2307.16205"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2307.16205"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://youtu.be/L-WNBUNyP-Y"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/ycjungSubhuman/density-adaptation/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://ycjung.info/">Yucheol Jung</a>, 
<a href="https://hyomin.me/">Hyomin Kim</a> 
(<a href="https://international.postech.ac.kr/">POSTECH</a>), 
<a href="https://sites.google.com/site/gyeonghahwang">Gyeongha Hwang</a> 
(<a href="https://www.yu.ac.kr/">Yeungnam University</a>), 
<a href="https://www.shbaek.com/">Seung-Hwan Baek</a>, 
<a href="http://cg.postech.ac.kr/leesy/">Seungyong Lee</a> 
(<a href="https://international.postech.ac.kr/">POSTECH</a>)
</dd>

</dl>

<h2>Fabrication-Oriented Design</h2>
<dl>

<dt><b>Constraint-based Simulation of Passive Suction Cups</b>
	<a href="https://eulaliecoevoet.com/publications/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://eulaliecoevoet.com/publications/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=PSKXglvD77I"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Antonin Bernardin, 
<a href="https://eulaliecoevoet.com/>Eulalie Coevoet</a>  
(<a href=" https:="" www.univ-rennes.fr="" "="">Univ. Rennes</a> / <a href="https://www.groupe-insa.fr/en">INSA</a> / <a href="https://www.irisa.fr/en">IRISA</a> / <a href="https://www.inria.fr/en">Inria</a>), 
<a href="https://www.cs.mcgill.ca/~kry/">Paul Kry</a> 
(<a href="https://www.mcgill.ca/">McGill University</a>), 
<a href="http://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a> 
(<a href="https://www.etsmtl.ca/">Ecole de technologie superieure</a>), 
Christian Duriez
(<a href="https://www.inria.fr/en">Inria</a> / <a href="https://www.univ-lille.fr/">Univ. Lille</a> / <a href="https://www.cnrs.fr/en">CNRS</a>), 
Maud Marchal
(<a href="https://www.univ-rennes.fr/">Univ. Rennes</a> / <a href="https://www.groupe-insa.fr/en">INSA</a> / <a href="https://www.irisa.fr/en">IRISA</a> / <a href="https://www.inria.fr/en">Inria</a>) 
</dd>

<dt><b>Masonry Shell Structures with Discrete Equivalence Classes</b>
	<a href="https://sutd-cgl.github.io/supp/Publication/projects/2023-SIGGRAPH-TileableShell/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://sutd-cgl.github.io/supp/Publication/projects/2023-SIGGRAPH-TileableShell/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://sutd-cgl.github.io/supp/Publication/projects/2023-SIGGRAPH-TileableShell/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/Linsanity81/TileableShell"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Rulin Chen, 
Pengyun Qiu, 
<a href="https://songpenghit.github.io/">Peng Song</a> 
(<a href="https://sutd.edu.sg/">SUTD</a>), 
<a href="http://www.bdeng.me/">Bailin Deng</a> 
(<a href="https://www.cardiff.ac.uk/">Cardiff University</a>), 
<a href="https://kiki007.github.io/">Ziqi Wang</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="https://personal.ntu.edu.sg/yhe/">Ying He</a> 
(<a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>)
</dd>

<dt><b>Generative Design of Sheet Metal Structures</b>
	<a href="https://homes.cs.washington.edu/~adriana/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.amirbar.net/">Amir Barda</a>, 
<a href="https://github.com/GuyTevet">Guy Tevet</a> 
(<a href="https://english.tau.ac.il/">Tel Aviv University</a>), 
<a href="https://homes.cs.washington.edu/~adriana/">Adriana Schulz</a> 
(<a href="https://www.washington.edu/">University of Washington</a>), 
<a href="https://www.cs.tau.ac.il/~amberman/">Amit Haim Bermano</a> 
(<a href="https://english.tau.ac.il/">Tel Aviv University</a>) 
</dd>

<dt><b>Inkjet 4D Print: Self-folding Tessellated Origami Objects by Inkjet UV Printing</b>
	<a href="https://narumi.me/inkjet4dprint"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://narumi.me/inkjet4dprint"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://narumi.me/work">Koya Narumi</a>* 
Kazuki Koyama* 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a>), 
Kai Suto 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a> and <a href="https://nature-architects.com/">Nature Architects, Inc.</a>), 
<a href="https://yutanoma.com/">Yuta Noma</a> 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a>), 
Hiroki Sato 
(<a href="https://www.myu.ac.jp/english/">Miyagi University</a>), 
<a href="https://www.u-tokyo.ac.jp/focus/en/people/people001930.html">Tomohiro Tachi</a> 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a>), 
Masaaki Sugimoto 
(<a href="https://www.elephantech.co.jp/en/">Elephantech Inc.</a>), 
<a href="https://www-ui.is.s.u-tokyo.ac.jp/~takeo/">Takeo Igarashi</a>, 
<a href="https://www.akg.t.u-tokyo.ac.jp/">Yoshihiro Kawahara</a> 
(<a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo</a>)
(* Joint first authors)
</dd>

<dt><b>MesoGen: Designing Procedural On-surface Stranded Mesostructures</b>
	<a href="https://eliemichel.github.io/MesoGen/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://eliemichel.github.io/MesoGen/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://eliemichel.github.io/MesoGen/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/eliemichel/MesoGen"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://research.adobe.com/person/elie-michel/">Elie Michel</a> 
<a href="https://perso.telecom-paristech.fr/boubek/">Tamy Boubekeur</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>) 
</dd>

<dt><b>Constructing Printable Surfaces With View-dependent Appearance</b>
	<a href="https://maxineaps.github.io/view-dependent-project-site/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://maxineaps.github.io/view-dependent-project-site/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://maxineaps.github.io/view-dependent-project-site/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://maxineps.com/">Maxine Perroni-Scharf</a>, 
<a href="https://www.cs.princeton.edu/~smr/">Szymon Rusinkiewicz</a> 
(<a href="https://www.princeton.edu/">Princeton University</a>)
</dd>

</dl>

<h2>Neural Capturing</h2>
<dl>

<dt><b>Neural Volumetric Reconstruction for Coherent Synthetic Aperture Sonar</b>
	<a href="https://awreed.github.io/Neural-Volumetric-Reconstruction-for-Coherent-SAS/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://awreed.github.io/Neural-Volumetric-Reconstruction-for-Coherent-SAS/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://awreed.github.io/Neural-Volumetric-Reconstruction-for-Coherent-SAS/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/awreed/Neural-Volumetric-Reconstruction-for-Coherent-SAS"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
Albert Reed 
(<a href="https://www.asu.edu/">Arizona State University</a>), 
Juhyeon Kim 
(<a href="https://home.dartmouth.edu/">Dartmouth College</a>), 
Thomas Blanford 
(<a href="https://www.psu.edu/">The Pennsylvania State University</a>), 
<a href="https://sites.google.com/view/adithyapediredla/">Adithya Pediredla</a> 
(<a href="https://home.dartmouth.edu/">Dartmouth College</a>), 
Daniel Brown 
(<a href="https://www.psu.edu/">The Pennsylvania State University</a>), 
<a href="https://csi.asu.edu/people/suren-jayasuriya/">Suren Jayasuriya</a> 
(<a href="https://www.asu.edu/">Arizona State University</a>)
</dd>

<dt><b>NeRO: Neural Geometry and BRDF Reconstruction of Reflective Objects From Multiview Images</b>
	<a href="https://liuyuan-pal.github.io/NeRO/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://liuyuan-pal.github.io/NeRO/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://connecthkuhk-my.sharepoint.com/:f:/g/personal/yuanly_connect_hku_hk/EvNz_o6SuE1MsXeVyB0VoQ0B7L4i2I1noCWGs2qu_S23BA?e=6fzVfH"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/liuyuan-pal/NeRO"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://liuyuan-pal.github.io/">Yuan Liu</a>, 
<a href="https://totoro97.github.io/">Peng Wang&gt;</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a>), 
<a href="https://clinplayer.github.io/">Cheng Lin</a> 
(<a href="https://www.tencent.com/en-us/">Tencent Games</a>), 
<a href="https://www.xxlong.site/">Xiaoxiao Long</a>, 
<a href="https://jiepengwang.github.io/">Jiepeng Wang</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a>), 
<a href="https://lingjie0206.github.io/">Lingjie Liu</a> 
(<a href="https://www.upenn.edu/">University of Pennsylvania</a> and <a href="http://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics</a>), 
<a href="https://homepages.inf.ed.ac.uk/tkomura/">Taku Komura</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a>), 
<a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html">Wenping Wang</a> 
(<a href="https://www.tamu.edu/">Texas A&amp;M University</a>), 
</dd>

<dt><b>BakedSDF: Meshing Neural SDFs for Real-time View Synthesis</b>
	<a href="https://bakedsdf.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://bakedsdf.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://bakedsdf.github.io/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://bakedsdf.github.io/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://lioryariv.github.io/">Lior Yariv</a>* 
(<a href="https://www.weizmann.ac.il/pages/">Weizmann Institute of Science</a> and <a href="https://research.google/">Google Research</a>), 
<a href="https://phogzone.com/">Peter Hedman</a>* 
(<a href="https://research.google/">Google Research</a>), 
<a href="https://creiser.github.io/">Christian Reiser</a> 
(<a href="https://tuebingen.ai/">Tubingen AI Center</a> and <a href="https://research.google/">Google Research</a>), 
<a href="https://dorverbin.github.io/">Dor Verbin</a>, 
<a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>, 
<a href="https://szeliski.org/RichardSzeliski.htm">Richard Szeliski</a>, 
<a href="https://jonbarron.info/">Jonathan T. Barron</a>, 
<a href="http://bmild.github.io/">Ben Mildenhall</a> 
(<a href="https://research.google/">Google Research</a>), 
* Denotes equal contribution 
</dd>

<dt><b>AvatarMAV: Fast 3D Head Avatar Reconstruction Using Motion-aware Neural Voxels</b>
	<a href="https://liuyebin.com/avatarmav/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://liuyebin.com/avatarmav/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://liuyebin.com/avatarmav/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Yuelang Xu 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>), 
<a href="https://lizhenwangt.github.io/">Lizhen Wang</a>, 
Xiaochen Zhao 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a> and <a href="https://nnkosmos.com">NNKosmos</a>), 
<a href="https://hongwenzhang.github.io/">Hongwen Zhang</a> 
<a href="http://www.liuyebin.com/">Yebin Liu</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>) 
</dd>

<dt><b>Deep SVBRDF Estimation From Single Image Under Learned Planar Lighting</b>
	</dt>
<dd>
Lianghao Zhang
Fangzhou Gao
Li Wang
Minjing Yu
Jiamin Cheng
Jiawan Zhang
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>PhotoMat: A Material Generator Learned From Single Flash Photos</b>
	<a href="https://people.engr.tamu.edu/nimak/Papers/SIGGRAPH2023_PhotoMat/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://people.engr.tamu.edu/nimak/Papers/SIGGRAPH2023_PhotoMat/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://people.engr.tamu.edu/nimak/Papers/SIGGRAPH2023_PhotoMat/index.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://xilongzhou.github.io/">Xilong Zhou</a> 
(<a href="https://www.tamu.edu/">Texas A&amp;M University</a>), 
<a href="http://www.miloshasan.net/">Milos Hasan</a>, 
<a href="https://valentin.deschaintre.fr/">Valentin Deschaintre</a>, 
<a href="https://research.adobe.com/person/paul-guerrero/">Paul Guerrero</a>, 
<a href="https://yannickhold.com/">Yannick Hold-Geoffroy</a>, 
<a href="http://www.kalyans.org/">Kalyan Sunkavalli</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://faculty.cs.tamu.edu/nimak/">Nima Khademi Kalantari </a> 
(<a href="https://www.tamu.edu/">Texas A&amp;M University</a>)
</dd>

</dl>

<h2>Going With the Flow</h2>
<dl>

<dt><b>A Contact Proxy Splitting Method for Lagrangian Solid-fluid Coupling</b>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.math.ucla.edu/multiples/publication/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://xpandora.github.io/">Tianyi Xie</a>, 
<a href="https://www.math.ucla.edu/~minchen/">Minchen Li</a> 
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>), 
<a href="https://yangzzzy.github.io/">Yin Yang</a> 
(<a href="http://www.utah.edu/">University of Utah</a>), 
<a href="https://www.math.ucla.edu/~cffjiang/">Chenfanfu Jiang</a> 
(<a href="https://www.ucla.edu/">University of California, Los Angeles</a>)
</dd>

<dt><b>Fluid-solid Coupling in Kinetic Two-phase Flow Simulation</b>
	<a href="https://pages.saclay.inria.fr/mathieu.desbrun/m@pubs.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://pages.saclay.inria.fr/mathieu.desbrun/m@pubs.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://pages.saclay.inria.fr/mathieu.desbrun/m@pubs.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Wei Li
(<a href="https://www.inria.fr/en">Inria</a> and <a href="https://www.lightspeed-studios.com/">Tencent Lightspeed Studios</a>), 
<a href="https://pages.saclay.inria.fr/mathieu.desbrun/">Mathieu Desbrun</a> 
(<a href="https://www.inria.fr/en">Inria</a> and <a href="https://www.polytechnique.edu/en">Ecole Polytechnique</a>)
</dd>

<dt><b>PolyStokes: A Polynomial Model Reduction Method for Viscous Fluid Simulation</b>
	<a href="https://jpanuelos.com/publications/2023-06-06-PolyStokes.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://jpanuelos.com/publications/2023-06-06-PolyStokes.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://jpanuelos.com/">Jonathan Panuelos</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a>), 
<a href="https://rgoldade.github.io/">Ryan Goldade</a> 
(<a href="https://uwaterloo.ca/">University of Waterloo</a>), 
<a href="https://www.dgp.toronto.edu/~eitan/">Eitan Grinspun</a>, 
<a href="http://142.93.146.228/researchdb/">David I.W. Levin</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a>), 
<a href="https://cs.uwaterloo.ca/~c2batty/">Christopher Batty</a>, 
(<a href="https://uwaterloo.ca/">University of Waterloo</a>)
</dd>

<dt><b>Building a Virtual Weakly-compressible Wind Tunnel Testing Facility</b>
	<a href="http://www.geometry.caltech.edu/pubs.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://www.geometry.caltech.edu/pubs.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://www.geometry.caltech.edu/pubs.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Chaoyang Lyu
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a> / SIMIT / UCAS), 
Kai Bai
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a> / AEROCAE Digital Ltd.), 
Yiheng Wu
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a>), 
<a href="https://pages.saclay.inria.fr/mathieu.desbrun/">Mathieu Desbrun</a> 
(<a href="https://www.inria.fr/en">Inria</a> and <a href="https://www.polytechnique.edu/en">Ecole Polytechnique</a>), 
<a href="http://www.cs.columbia.edu/~cxz/">Changxi Zheng</a> 
(Tencent Pixel Lab and <a href="http://www.columbia.edu/">Columbia University</a>), 
<a href="https://faculty.sist.shanghaitech.edu.cn/faculty/liuxp/">Xiaopei Liu</a> 
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a>)
</dd>

<dt><b>Fluid Cohomology</b>
	<a href="https://yhesper.github.io/fc23/fc23.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://yhesper.github.io/fc23/fc23.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://yhesper.github.io/">Hang Yin</a>, 
<a href="https://sinabiz.github.io/">Mohammad Sina Nabizadeh</a>, 
<a href="https://acsweb.ucsd.edu/~bwu/">Baichuan Wu</a>, 
<a href="https://stephaniewang.page/">Stephanie Wang</a>, 
<a href="https://cseweb.ucsd.edu/~alchern/">Albert Chern</a> 
(<a href="https://ucsd.edu/">University of California, San Diego</a>)
</dd>

<dt><b>Improved Water Sound Synthesis using Coupled Bubbles</b>
	<a href="https://graphics.stanford.edu/papers/coupledbubbles/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://graphics.stanford.edu/papers/coupledbubbles/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://graphics.stanford.edu/papers/coupledbubbles/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://web.stanford.edu/~kangruix/">Kangrui Xue</a>, 
Ryan M. Aronson 
(<a href="https://www.stanford.edu/">Stanford University</a>), 
<a href="http://juiwang.com/">Jui-Hsien Wang</a>, 
<a href="https://langlo.is/">Timothy R. Langlois</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://graphics.stanford.edu/~djames/">Doug L. James</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>) 
</dd>

</dl>

<h2>Marvelous Mappings</h2>
<dl>

<dt><b>Galaxy Maps: Localized Foliations for Bijective Volumetric Mapping</b>
	</dt>
<dd>
Steffen Hinderink
Marcel Campen
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>Symmetric Volume Maps: Order-invariant Volumetric Mesh Correspondence With Free Boundary</b>
	<a href="https://arxiv.org/abs/2202.02568"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2202.02568"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/mabulnaga/symmetric-volume-maps"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://people.csail.mit.edu/abulnaga/">Mazdak Abulnaga</a>, 
<a href="https://odedstein.com/">Oded Stein</a>, 
<a href="https://www.csail.mit.edu/person/polina-golland">Polina Golland</a>, 
<a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>)
</dd>

<dt><b>Variational Quasi-harmonic Maps for Computing Diffeomorphisms</b>
	<a href="https://wangyu9.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://wangyu9.github.io/">Yu Wang</a>, 
<a href="https://www.minghaoguo.com/">Minghao Guo</a>, 
<a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>)
</dd>

<dt><b>Expansion Cones: A Progressive Volumetric Mapping Framework</b>
	<a href="https://www.algohex.eu/publications/expansion-cones/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.algohex.eu/publications/expansion-cones/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/cgg-bern/expansion-cones"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.algohex.eu/team/nigolian/">Valentin Z. Nigolian</a> 
(<a href="https://www.unibe.ch/index_eng.html">University of Bern</a>), 
<a href="http://graphics.cs.uos.de/">Marcel Campen</a> 
(<a href="https://www.uni-osnabrueck.de/en/home/">Osnabruck University</a>), 
<a href="https://www.algohex.eu/team/bommes/">David Bommes</a> 
(<a href="https://www.unibe.ch/index_eng.html">University of Bern</a>)
</dd>

<dt><b>Unsupervised Learning of Robust Spectral Shape Matching</b>
	<a href="https://dongliangcao.github.io/urssm/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://dongliangcao.github.io/urssm/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://dongliangcao.github.io/urssm/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/dongliangcao/Unsupervised-Learning-of-Robust-Spectral-Shape-Matching"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://dongliangcao.github.io/">Dongliang Cao</a>, 
<a href="https://lovc.cs.uni-bonn.de/index.php/team/paul-roetzer/">Paul Roetzer</a>, 
<a href="https://lovc.cs.uni-bonn.de/index.php/team/florian-bernard/">Florian Bernard</a> 
(<a href="https://www.uni-bonn.de/en/university">University of Bonn</a>)
</dd>

<dt><b>An Elastic Basis for Spectral Shape Correspondence</b>
	<a href="https://josuasassen.com/#publications"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/flrneha/ElasticBasisForSpectralMatching"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://ins.uni-bonn.de/staff/hartwig">Florine Hartwig</a>, 
<a href="https://josuasassen.com/">Josua Sassen</a> 
(<a href="https://www.uni-bonn.de/en/university">University of Bonn</a>), 
<a href="https://omriazencot.com/">Omri Azencot</a> 
(<a href="https://in.bgu.ac.il/en/pages/default.aspx">Ben Gurion University of the Negev</a>), 
<a href="https://ins.uni-bonn.de/staff/rumpf">Martin Rumpf</a> 
(<a href="https://www.uni-bonn.de/en/university">University of Bonn</a>), 
<a href="https://mirela.net.technion.ac.il/">Mirela Ben-Chen</a> 
(<a href="http://www.technion.ac.il/en">Technion - Israel Institute of Technology</a>)
</dd>

</dl>

<h2>Real-Time Rendering: Gotta Go Fast!</h2>
<dl>

<dt><b>ETER: Elastic Tessellation for Real-Time Pixel-Accurate Rendering of Large-Scale NURBS Models</b>
	<a href="http://staff.ustc.edu.cn/~lgliu/Projects/2023_ETER/default.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="http://staff.ustc.edu.cn/~lgliu/Projects/2023_ETER/default.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="http://staff.ustc.edu.cn/~lgliu/Projects/2023_ETER/default.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Ruicheng Xiong* 
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>), 
Yang Lu*, 
Cong Chen 
(Sheyun Technology), 
Jiaming Zhu, 
Yajun Zeng, 
<a href="http://staff.ustc.edu.cn/~lgliu/">Ligang Liu</a> 
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>)
(* Joint first authors)
</dd>

<dt><b>Temporal Set Inversion for Animated Implicits</b>
	<a href="https://www.cryvosh.com/TemporalSetInversion/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.cryvosh.com/TemporalSetInversion/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.cryvosh.com/TemporalSetInversion/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.linkedin.com/in/kavosh-jazar/">Kavosh Jazar</a>, 
<a href="https://www.cs.mcgill.ca/~kry/">Paul G. Kry</a> 
(<a href="https://www.mcgill.ca/">McGill University</a>) 
</dd>

<dt><b>Live 3D Portrait: Real-Time Radiance Fields for Single-Image Portrait View Synthesis</b>
	<a href="https://research.nvidia.com/labs/nxp/lp3d/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/nxp/lp3d/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/nxp/lp3d/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://alextrevithick.github.io/">Alex Trevithick</a> 
(<a href="https://ucsd.edu/">UC San Diego</a>), 
<a href="https://matthew-a-chan.github.io/">Matthew Chan</a>, 
<a href="https://research.nvidia.com/person/michael-stengel">Michael Stengel</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://ericryanchan.github.io/">Eric R. Chan</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>), 
<a href="https://research.nvidia.com/person/chao-liu">Chao Liu</a>, 
<a href="https://chrisding.github.io/">Zhiding Yu</a>, 
<a href="https://www.samehkhamis.com/">Sameh Khamis</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://cseweb.ucsd.edu/~mkchandraker/">Manmohan Chandraker</a>, 
<a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a> 
(<a href="https://ucsd.edu/">UC San Diego</a>), 
<a href="https://luminohope.org/">Koki Nagano</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>)
</dd>

<dt><b>Kernel-based Frame Interpolation for Spatio-temporally Adaptive Rendering</b>
	<a href="https://studios.disneyresearch.com/2023/07/23/kernel-based-frame-interpolation-for-spatio-temporally-adaptive-rendering/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://studios.disneyresearch.com/2023/07/23/kernel-based-frame-interpolation-for-spatio-temporally-adaptive-rendering/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://studios.disneyresearch.com/2023/07/23/kernel-based-frame-interpolation-for-spatio-temporally-adaptive-rendering/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Karlis Martins Briedis 
(<a href="https://studios.disneyresearch.com/">Disney Research Studios</a> and <a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="https://adjelouah.github.io/">Abdelaziz Djelouah</a>, 
<a href="https://studios.disneyresearch.com/people/raphael-ortiz/">Raphael Ortiz</a> 
(<a href="https://studios.disneyresearch.com/">Disney Research Studios</a>), 
<a href="https://graphics.pixar.com/people/mmeyer/">Mark Meyer</a> 
(<a href="https://www.pixar.com/">Pixar Animation Studios</a>), 
<a href="https://inf.ethz.ch/people/person-detail.mgross.html">Markus Gross</a> 
(<a href="https://studios.disneyresearch.com/">Disney Research Studios</a> and <a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="https://studios.disneyresearch.com/people/christopher-schroers/">Christopher Schroers</a> 
(<a href="https://studios.disneyresearch.com/">Disney Research Studios</a>) 
</dd>

<dt><b>Neural Partitioning Pyramids for Denoising Monte Carlo Renderings</b>
	<a href="https://balint.io/nppd/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://balint.io/nppd/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://balint.io/nppd/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://balint.io/nppd/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://people.mpi-inf.mpg.de/~mbalint/">Martin Balint</a>, 
<a href="https://people.mpi-inf.mpg.de/~kwolski/">Krzysztof Wolski</a>, 
<a href="https://people.mpi-inf.mpg.de/~karol/">Karol Myszkowski</a>, 
<a href="https://people.mpi-inf.mpg.de/~hpseidel/english.html">Hans-Peter Seidel</a> 
(<a href="https://www.mpi-inf.mpg.de/home">Max Planck Institute for Informatics</a>), 
<a href="https://www.cl.cam.ac.uk/~rkm38/">Rafal Mantiuk</a> 
(<a href="https://www.cam.ac.uk/">University of Cambridge</a>)
</dd>

<dt><b>Deep Real-time Volumetric Rendering Using Multi-feature Fusion</b>
	<a href="https://onethousandwu.com/publication/mrpnn"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://onethousandwu.com/publication/mrpnn"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Jinkai Hu* 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>), 
Chengzhong Yu* 
(<a href="https://www.tus.ac.jp/en/">Tokyo University of Science</a>), 
Hongli Liu 
(<a href="https://www.tencent.com/">Tencent, Inc.</a>), 
<a href="https://sites.cs.ucsb.edu/~lingqi/">Ling-Qi Yan</a> 
(<a href="https://www.ucsb.edu/">University of California, Santa Barbara</a>), 
<a href="https://onethousandwu.com/">Yiqian Wu</a>, 
<a href="http://www.cad.zju.edu.cn/home/jin/">Xiaogang Jin</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>) 
*Authors contributed equally.
</dd>

</dl>

<h2>Text-Guided Generation</h2>
<dl>

<dt><b>UniTune: Text-driven Image Editing by Fine Tuning a Diffusion Model on a Single Image</b>
	<a href="https://arxiv.org/abs/2210.09477"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2210.09477"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Dani Valevski, 
Matan Kalman, 
Eyal Molad, 
Eyal Segalis, 
Yossi Matias, 
Yaniv Leviathan
(<a href="https://research.google/">Google Research</a>)
</dd>

<dt><b>TEXTure: Text-guided Texturing of 3D Shapes</b>
	<a href="https://texturepaper.github.io/TEXTurePaper/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://texturepaper.github.io/TEXTurePaper/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://texturepaper.github.io/TEXTurePaper/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/TEXTurePaper/TEXTurePaper"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://eladrich.github.io/">Elad Richardson</a>*, 
<a href="https://galmetzer.github.io/">Gal Metzer</a>*, 
<a href="https://yuval-alaluf.github.io/">Yuval Alaluf</a>, 
<a href="https://www.giryes.sites.tau.ac.il/">Raja Giryes</a>, 
<a href="https://danielcohenor.com/">Daniel Cohen-Or</a> 
(<a href="https://english.tau.ac.il/">Tel Aviv University</a>) 
* Denotes equal contribution
</dd>

<dt><b>Sketch-guided Text-to-image Diffusion Models</b>
	<a href="https://sketch-guided-diffusion.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://sketch-guided-diffusion.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://github.com/anvoynov">Andrey Voynov</a>, 
<a href="https://kfiraberman.github.io/">Kfir Aberman</a> 
(<a href="https://research.google/">Google Research</a>), 
<a href="https://danielcohenor.com/">Daniel Cohen-Or</a> 
(<a href="https://research.google/">Google Research</a> and <a href="https://english.tau.ac.il/">Tel Aviv University</a>) 
</dd>

<dt><b>FashionTex: Controllable Virtual Try-on With Text and Texture</b>
	<a href="https://arxiv.org/abs/2305.04451"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.04451"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Anran Lin 
(<a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a>), 
<a href="http://nxzhao.com/">Nanxuan Zhao</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
Shuliang Ning, 
Yuda Qiu 
(<a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a>), 
Baoyuan Wang
(<a href="http://www.xiaobing.ai/">Xiaobing.AI</a>), 
<a href="https://gaplab.cuhk.edu.cn/pages/people">Xiaoguang Han</a> 
(<a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a>)
</dd>

<dt><b>CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable and Controllable Text-Guided Face Manipulation</b>
	<a href="https://chenliang-zhou.github.io/CLIP-PAE/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://chenliang-zhou.github.io/CLIP-PAE/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/Chenliang-Zhou/CLIP-PAE"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://chenliang-zhou.github.io/">Chenliang Zhou </a>, 
<a href="https://www.cl.cam.ac.uk/~fz261/">Fangcheng Zhong</a>, 
<a href="https://www.cl.cam.ac.uk/~aco41/">Cengiz Oztireli</a> 
(<a href="https://www.cam.ac.uk/">University of Cambridge</a>)
</dd>

</dl>

<h2>Character Animation: Interaction</h2>
<dl>

<dt><b>Generating Activity Snippets by Learning Human-scene Interactions</b>
	<a href="https://changyangli.github.io/projects/siggraph23snippet/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://changyangli.github.io/projects/siggraph23snippet/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=U6LB3vmTWeE"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://changyangli.github.io/">Changyang Li</a>, 
<a href="https://craigyuyu.github.io/home/index.html">Lap-Fai Yu</a> 
(<a href="https://www.gmu.edu/">George Mason University</a>)
</dd>

<dt><b>GREIL-Crowds: Crowd Simulation With Deep Reinforcement Learning and Examples</b>
	<a href="https://veupnea.github.io/publication_pages/siggraph23-greil.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://veupnea.github.io/publication_pages/siggraph23-greil.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://veupnea.github.io/publication_pages/siggraph23-greil.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://totis77.github.io/">Panayiotis Charalambous</a> 
(<a href="https://www.cyens.org.cy/en-gb/">CYENS - Centre of Excellence</a>), 
<a href="http://people.rennes.inria.fr/Julien.Pettre/">Julien Pettre</a> 
(Univ Rennes, Inria, CNRS, IRISA), 
Vassilis Vassiliades 
(<a href="https://www.ucy.ac.cy/?lang=en">University of Cyprus</a>), 
<a href="http://www.cs.ucy.ac.cy/~yiorgos/">Yiorgos Chrysanthou</a> 
(<a href="https://www.cyens.org.cy/en-gb/">CYENS - Centre of Excellence</a> and <a href="https://www.ucy.ac.cy/?lang=en">University of Cyprus</a>), 
Nuria Pelechano 
(<a href="https://www.upc.edu/en">Universitat Politecnica de Catalunya</a>)
</dd>

<dt><b>QuestEnvSim: Environment-aware Simulated Motion Tracking From Sparse Sensor Input</b>
	<a href="https://sunny-codes.github.io/projects/questenvsim.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://sunny-codes.github.io/projects/questenvsim.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://sunny-codes.github.io/projects/questenvsim.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://sunny-codes.github.io/">Sunmin Lee</a> 
(<a href="http://snu.ac.kr/">Seoul National University</a>), 
<a href="https://www.sebastianxstarke.com/">Sebastian Starke</a>, 
<a href="http://yutingye.info/">Yuting Ye</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs Research</a>), 
<a href="https://sites.google.com/view/jungdam/">Jungdam Won</a> 
(<a href="http://snu.ac.kr/">Seoul National University</a>), 
<a href="https://alex-winkler.com/">Alexander Winkler</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs Research</a>), 
</dd>

<dt><b>Synthesizing Physical Character-Scene Interactions</b>
	<a href="https://research.nvidia.com/publication/2023-08_synthesizing-physical-character-scene-interactions"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/publication/2023-08_synthesizing-physical-character-scene-interactions"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://ps.is.mpg.de/person/mhassan">Mohamed Hassan</a> 
(<a href="https://www.ea.com/">Electronic Arts</a>), 
<a href="https://nv-tlabs.github.io/author/yunrong-guo/">Yunrong Guo</a>, 
<a href="https://tingwuwang.github.io/">Tingwu Wang</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://ps.is.mpg.de/~black">Michael Black</a> 
(<a href="https://is.mpg.de/">Max-Planck-Institute for Intelligent Systems</a>), 
<a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://xbpeng.github.io/">Xue Bin Peng</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://www.sfu.ca/">Simon Fraser University</a>)
</dd>

<dt><b>PMP: Learning to Physically Interact With Environments Using Part-wise Motion Priors</b>
	<a href="https://arxiv.org/abs/2305.03249"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.03249"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=WdLGvKdNG-0"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Jinseok Bae, 
<a href="https://sites.google.com/view/jungdam/">Jungdam Won</a>, 
Donggeun Lim, 
Cheol-Hui Min, 
Young Min Kim 
(<a href="http://snu.ac.kr/">Seoul National University</a>)
</dd>

<dt><b>Simulation and Retargeting of Complex Multi-character Interactions</b>
	<a href="https://research.facebook.com/publications/simulation_and_retargeting_of_complex_multi_character_interactions/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.facebook.com/publications/simulation_and_retargeting_of_complex_multi_character_interactions/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=iUsVCbI9OCI"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Yunbo Zhang
(<a href="https://www.gatech.edu/">Georgia Institute of Technology</a>), 
Deepak Gopinath 
(<a href="https://www.apple.com/">Apple</a>), 
<a href="http://yutingye.info/">Yuting Ye</a> 
(<a href="https://about.meta.com/realitylabs/">Meta Reality Labs Research</a>), 
<a href="https://www.cs.cmu.edu/~jkh/">Jessica Hodgins</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>), 
<a href="https://faculty.cc.gatech.edu/~turk/">Greg Turk</a> 
(<a href="https://www.gatech.edu/">Georgia Institute of Technology</a>), 
<a href="https://sites.google.com/view/jungdam/">Jungdam Won</a> 
(<a href="http://snu.ac.kr/">Seoul National University</a>)
<a href="https://sites.cc.gatech.edu/~yzhang3027/">Yunbo Zhang</a> 
</dd>

</dl>

<h2>Environment Rendering: NeRFs on Earth</h2>
<dl>

<dt><b>3D Gaussian Splatting for Real-Time Radiance Field Rendering</b>
	<a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://scholar.google.at/citations?user=jeasMB0AAAAJ&amp;hl=en">Bernhard Kerbl</a>, 
<a href="https://grgkopanas.github.io/">Georgios Kopanas</a> 
(<a href="https://www.inria.fr/en">Inria</a> and <a href="https://univ-cotedazur.fr/">Universite Cote d'Azur</a>), 
<a href="https://people.mpi-inf.mpg.de/~tleimkue/">Thomas Leimkuhler</a> 
(<a href="https://www.mpi-inf.mpg.de/home">MPI Informatik</a>), 
<a href="http://www-sop.inria.fr/members/George.Drettakis/">George Drettakis</a> 
(<a href="https://www.inria.fr/en">Inria</a> and <a href="https://univ-cotedazur.fr/">Universite Cote d'Azur</a>)
</dd>

<dt><b>Virtual Mirrors: Non-line-of-sight Imaging Beyond the Third Bounce</b>
	<a href="https://graphics.unizar.es/projects/VirtualMirrors_2023/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://graphics.unizar.es/projects/VirtualMirrors_2023/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://graphics.unizar.es/projects/VirtualMirrors_2023/"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://graphics.unizar.es/projects/VirtualMirrors_2023/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://diego.contact/">Diego Royo</a> 
(<a href="https://i3a.unizar.es/es">Universidad de Zaragoza - I3A</a>), 
<a href="http://compoptics.wisc.edu/people.html">Talha Sultan</a> 
(<a href="https://www.wisc.edu/">University of Wisconsin-Madison</a>), 
<a href="https://webdiis.unizar.es/~amunoz/en/">Adolfo Munoz</a> 
(<a href="https://i3a.unizar.es/es">Universidad de Zaragoza - I3A</a>), 
<a href="http://compoptics.wisc.edu/people.html">Khadijeh Masumnia-Bisheh</a>, 
Eric Brandt 
(<a href="https://www.wisc.edu/">University of Wisconsin-Madison</a>), 
<a href="http://giga.cps.unizar.es/~diegog/">Diego Gutierrez</a> 
(<a href="https://i3a.unizar.es/es">Universidad de Zaragoza - I3A</a>), 
<a href="https://biostat.wisc.edu/~velten/">Andreas Velten</a> 
(<a href="https://www.wisc.edu/">University of Wisconsin-Madison</a>), 
<a href="http://webdiis.unizar.es/~juliom/">Julio Marco</a> 
(<a href="https://i3a.unizar.es/es">Universidad de Zaragoza - I3A</a>) 
</dd>

<dt><b>ViP-NeRF: Visibility Prior for Sparse Input Neural Radiance Fields</b>
	<a href="https://arxiv.org/abs/2305.00041"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.00041"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://nagabhushansn95.github.io/publications/2023/ViP-NeRF.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/NagabhushanSN95/ViP-NeRF"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://nagabhushansn95.github.io/index.html">Nagabhushan Somraj</a>, 
<a href="https://ece.iisc.ac.in/~rajivs">Rajiv Soundararajan</a> 
(<a href="https://iisc.ac.in/">Indian Institute of Science</a>)
</dd>

<dt><b>Nerfstudio: A Modular Framework for Neural Radiance Field Development</b>
	<a href="https://arxiv.org/abs/2302.04264"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2302.04264"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://docs.nerf.studio/en/latest/"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	<a href="https://docs.nerf.studio/en/latest/"><img alt="Related Links" src="URL.png" border="0"></a>
	</dt>
<dd>

<a href="https://www.matthewtancik.com/about-me">Matthew Tancik</a>*, 
<a href="https://ethanweber.me/">Ethan Weber</a>*, 
<a href="http://people.eecs.berkeley.edu/~evonne_ng/">Evonne Ng</a>*, 
<a href="https://www.liruilong.cn/">Ruilong Li</a>, 
<a href="https://github.com/brentyi">Brent Yi</a>, 
<a href="https://kerrj.github.io/">Justin Kerr</a>, 
<a href="https://www.linkedin.com/in/terrance-wang/">Terrance Wang</a>, 
<a href="https://akristoffersen.com/">Alexander Kristoffersen</a>, 
<a href="https://www.linkedin.com/in/jake-austin-371770199/">Jake Austin</a>, 
<a href="https://kamyar.io/">Kamyar Salahi</a>, 
<a href="https://abhikahuja.com/">Abhik Ahuja</a>, 
<a href="https://mcallisterdavid.com/">David McAllister</a>, 
<a href="https://people.eecs.berkeley.edu/~kanazawa/">Angjoo Kanazawa</a> 
(<a href="https://www.berkeley.edu/">University of California, Berkeley</a>) 
* Authors contributed equally
</dd>

<dt><b>Relighting Neural Radiance Fields With Shadow and Highlight Hints</b>
	<a href="https://nrhints.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://nrhints.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://nrhints.github.io/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://nrhints.github.io/"><img alt="Paper Data" src="Data.png" border="0"></a>
	<a href="https://github.com/iamNCJ/NRHints"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.ncj.wiki/">Chong Zeng</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a> and <a href="http://research.microsoft.com/en-us/labs/asia/">Microsoft Research Asia</a>), 
<a href="https://www.microsoft.com/en-us/research/people/guoch/">Guojun Chen</a>, 
<a href="https://yuedong.shading.me/">Yue Dong</a> 
(<a href="http://research.microsoft.com/en-us/labs/asia/">Microsoft Research Asia</a>), 
<a href="https://www.cs.wm.edu/~ppeers/">Pieter Peers</a> 
(<a href="https://www.wm.edu/">College of William &amp; Mary</a>), 
<a href="https://svbrdf.github.io/">Hongzhi Wu</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>), 
<a href="http://research.microsoft.com/en-us/um/people/xtong/xtong.html">Xin Tong</a> 
(<a href="http://research.microsoft.com/en-us/labs/asia/">Microsoft Research Asia</a>) 
</dd>

<dt><b>DE-NeRF: DEcoupled Neural Radiance Fields for View-consistent Appearance Editing and High-frequency Environmental Relighting</b>
	<a href="http://geometrylearning.com/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=2Cr5i5iWs70"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Tong Wu, 
Jia-Mu Sun 
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a> and <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>), 
<a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a> 
(<a href="http://www.cardiff.ac.uk/">Cardiff University</a>), 
<a href="http://geometrylearning.com/">Lin Gao</a> 
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a> and <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>)
</dd>

</dl>

<h2>Fabulous Fabrication: From Knitting to Circuits</h2>
<dl>

<dt><b>Dense, Interlocking-free and Scalable Spectral Packing of Generic 3D Objects</b>
	<a href="https://inkbit3d.com/packing/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://inkbit3d.com/packing/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://inkbit3d.com/packing/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Qiaodong Cui
(<a href="https://inkbit3d.com/">Inkbit</a>), 
Victor Rong
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a>), 
<a href="http://people.csail.mit.edu/desaic/">Desai Chen</a>, 
(<a href="https://inkbit3d.com/">Inkbit</a>), 
<a href="https://cdfg.csail.mit.edu/wojciech">Wojciech Matusik</a> 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a> and <a href="https://inkbit3d.com/">Inkbit</a>) 
</dd>

<dt><b>PCBend: Light Up Your 3D Shapes With Foldable Circuit Boards</b>
	<a href="https://visualcomputing.ist.ac.at/publications/2023/PLUY3SWFCB/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://visualcomputing.ist.ac.at/publications/2023/PLUY3SWFCB/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://visualcomputing.ist.ac.at/publications/2023/PLUY3SWFCB/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://perso.eleves.ens-rennes.fr/people/marco.freire/">Marco Freire</a>* 
(<a href="http://welcome.univ-lorraine.fr/en">Universite de Lorraine</a> / <a href="http://www.cnrs.fr/index.html">CNRS</a> / <a href="https://www.inria.fr/en/centre/nancy">Inria</a>), 
<a href="https://manas-avi.github.io/">Manas Bhargava</a>* 
(<a href="https://ista.ac.at/">ISTA</a>), 
<a href="https://schreckc.github.io/">Camille Schreck</a>, 
<a href="https://www.instagram.com/pa_hugron/">Pierre-Alexandre Hugron</a> 
(<a href="http://welcome.univ-lorraine.fr/en">Universite de Lorraine</a> / <a href="http://www.cnrs.fr/index.html">CNRS</a> / <a href="https://www.inria.fr/en/centre/nancy">Inria</a>), 
<a href="http://berndbickel.com/">Bernd Bickel</a> 
(<a href="https://ista.ac.at/">ISTA</a>), 
<a href="https://www.antexel.com/sylefeb/">Sylvain Lefebvre</a> 
(<a href="http://welcome.univ-lorraine.fr/en">Universite de Lorraine</a> / <a href="http://www.cnrs.fr/index.html">CNRS</a> / <a href="https://www.inria.fr/en/centre/nancy">Inria</a>) 
(* Joint first authors)
</dd>

<dt><b>As-continuous-as-possible Extrusion-based Fabrication of Surface Models</b>
	<a href="https://fanchao98.github.io/ACAP%20page/acap.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://fanchao98.github.io/ACAP%20page/acap.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://fanchao98.github.io/ACAP%20page/acap.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://fanchao98.github.io/">Fanchao Zhong</a>, 
Yonglai Xu 
(<a href="http://en.sdu.edu.cn/">Shandong University</a>), 
<a href="https://haisenzhao.github.io/">Haisen Zhao</a> 
(<a href="http://en.sdu.edu.cn/">Shandong University</a> / <a href="https://ist.ac.at/en/home/">IST Austria</a> / <a href="http://www.washington.edu/">University of Washington</a>), 
<a href="http://irc.cs.sdu.edu.cn/~lulin">Lin Lu</a> 
(<a href="http://en.sdu.edu.cn/">Shandong University</a>) 
</dd>

<dt><b>Semantics and Scheduling for Machine Knitting Compilers</b>
	<a href="https://textiles-lab.github.io/publications/2023-knitout-semantics/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://textiles-lab.github.io/publications/2023-knitout-semantics/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/textiles-lab/fenced-tangle-supplemental"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="http://www.cs.cmu.edu/~jennylin/">Jenny Lin</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>), 
<a href="http://www.cs.cmu.edu/~nvidya/">Vidya Narayanan</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a> and <a href="https://www.amazon.com/">Amazon</a>), 
<a href="http://people.csail.mit.edu/yuka/">Yuka Ikarashi</a>, 
<a href="http://people.csail.mit.edu/jrk/">Jonathan Ragan-Kelley</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>), 
<a href="http://www.gilbertbernstein.com/">Gilbert Bernstein</a> 
(<a href="https://www.washington.edu/">University of Washington</a>), 
<a href="http://www.cs.cmu.edu/~jmccann/">James McCann</a> 
(<a href="https://www.cmu.edu/">Carnegie Mellon University</a>) 
</dd>

<dt><b>A Temporal Coherent Topology Optimization Approach for Assembly Planning of Bespoke Frame Structures</b>
	<a href="https://kiki007.github.io/publication/temporalcoherenttopologyoptimization/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://kiki007.github.io/publication/temporalcoherenttopologyoptimization/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://kiki007.github.io/publication/temporalcoherenttopologyoptimization/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://kiki007.github.io/#about">Ziqi Wang</a>, 
<a href="https://people.inf.ethz.ch/mafloria/">Florian Kennel-Maushart</a>, 
<a href="https://web.mit.edu/yijiangh/www/">Yijiang Huang</a>, 
<a href="https://n.ethz.ch/~bthomasz/index.html">Bernhard Thomaszewski</a>, 
<a href="http://crl.ethz.ch/people/coros/index.html">Stelian Coros</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>)
</dd>

<dt><b>Helix-free Stripes for Knit Graph Design</b>
	<a href="https://rahulmitra.xyz/projects/helix_free_stripes/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://rahulmitra.xyz/projects/helix_free_stripes/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://rahulmitra.xyz/">Rahul Mitra</a>, 
<a href="http://www.lianemakatura.com/">Liane Makatura</a>, 
<a href="https://cs-people.bu.edu/whiting/">Emily Whiting</a>, 
<a href="https://cs-people.bu.edu/edchien/">Edward Chien</a> 
(<a href="https://www.bu.edu/">Boston University</a>)
</dd>

</dl>

<h2>Making Faces With Neural Avatars</h2>
<dl>

<dt><b>DreamFace: Progressive Generation of Animatable 3D Faces Under Text Guidance</b>
	<a href="https://sites.google.com/view/dreamface"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://sites.google.com/view/dreamface"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://sites.google.com/view/dreamface"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Longwen Zhang*, 
Qiwei Qiu*, 
Hongyang Lin*, 
Qixuan Zhang 
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a> and <a href="https://deemos.com/">Deemos Technology Co., Ltd.</a>), 
Cheng Shi 
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a>), 
Wei Yang 
(<a href="http://english.hust.edu.cn/">Huazhong University of Science and Technology</a>), 
Ye Shi, 
Sibei Yang
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a>), 
Lan Xu, 
<a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54832/page.htm">Jingyi Yu</a> 
(<a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a> and Shanghai Engineering Research Center of Intelligent Vision and Imaging), 
* Equal contributions
</dd>

<dt><b>Efficient Video Portrait Reenactment via Grid-based Codebook</b>
	</dt>
<dd>
Kaisiyuan Wang
Hang Zhou
Qianyi Wu
Jiaxiang Tang
Zhiliang Xu
Borong Liang
Tianshu Hu
Errui Ding
Jingtuo Liu
Ziwei Liu
Jingdong Wang
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>StyleAvatar: Real-time Photo-realistic Neural Portrait Avatar From a Single Video</b>
	<a href="https://liuyebin.com/styleavatar/styleavatar.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://liuyebin.com/styleavatar/styleavatar.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://liuyebin.com/styleavatar/styleavatar.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/LizhenWangT/StyleAvatar"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://lizhenwangt.github.io/">Lizhen Wang</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a> and <a href="https://nnkosmos.com">NNKosmos</a>), 
Xiaochen Zhao, 
<a href="https://mrtornado24.github.io/">Jingxiang Sun</a>, 
Yuxiang Zhang, 
<a href="https://hongwenzhang.github.io/">Hongwen Zhang</a>, 
<a href="http://ytrock.com/">Tao Yu</a>, 
<a href="http://www.liuyebin.com/">Yebin Liu</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>) 
</dd>

<dt><b>Neural Face Rigging for Animating and Retargeting Facial Meshes in the Wild</b>
	<a href="https://arxiv.org/abs/2305.08296"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.08296"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Dafei Qin
(<a href="https://www.hku.hk/">The University of Hong Kong</a>), 
<a href="https://research.adobe.com/person/jun-saito/">Jun Saito</a>, 
<a href="https://noamaig.github.io/">Noam Aigerman</a>, 
<a href="https://research.adobe.com/person/thibault-groueix/">Thibault Groueix</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://homepages.inf.ed.ac.uk/tkomura/">Taku Komura</a> 
(<a href="https://www.hku.hk/">The University of Hong Kong</a>) 
</dd>

<dt><b>A Hybrid Generator Architecture for Controllable Face Synthesis</b>
	<a href="https://research.nvidia.com/publication/2023-08_hybrid-generator-architecture-controllable-face-synthesis"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/publication/2023-08_hybrid-generator-architecture-controllable-face-synthesis"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://github.com/DannMensah">Dann Mensah</a>, 
Nam Hee Kim 
(<a href="https://www.aalto.fi/en">Aalto University</a>), 
<a href="https://research.nvidia.com/person/miika-aittala">Miika Aittala</a>, 
<a href="https://research.nvidia.com/person/samuli-laine">Samuli Laine</a>, 
<a href="https://research.nvidia.com/person/jaakko-lehtinen">Jaakko Lehtinen</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>)
</dd>

<dt><b>ClipFace: Text-guided Editing of Textured 3D Morphable Models</b>
	<a href="https://shivangi-aneja.github.io/projects/clipface/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://shivangi-aneja.github.io/projects/clipface/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://shivangi-aneja.github.io/projects/clipface/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/shivangi-aneja/ClipFace"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://niessnerlab.org/members/shivangi_aneja/profile.html">Shivangi Aneja</a> 
(<a href="https://www.tum.de/en/">Technical University of Munich</a>), 
<a href="https://is.mpg.de/~jthies">Justus Thies</a> 
(<a href="https://is.mpg.de/">Max Planck Institute for Intelligent Systems</a>), 
<a href="https://www.professoren.tum.de/en/dai-angela">Angela Dai</a>, 
<a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Niessner</a> 
(<a href="https://www.tum.de/en/">Technical University of Munich</a>) 
</dd>

</dl>

<h2>Deep Geometric Learning</h2>
<dl>

<dt><b>OctFormer: Octree-based Transformers for 3D Point Clouds</b>
	<a href="https://wang-ps.github.io/octformer.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://wang-ps.github.io/octformer.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/octree-nn/octformer"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://wang-ps.github.io/">Peng-Shuai Wang</a> 
(<a href="https://www.pku.edu.cn/">Peking University</a>)
</dd>

<dt><b>Dictionary Fields: Learning a Neural Basis Decomposition</b>
	<a href="https://vlg.inf.ethz.ch/publications/Dictionary-Fields-Learning-a-Neural.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://vlg.inf.ethz.ch/publications/Dictionary-Fields-Learning-a-Neural.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://vlg.inf.ethz.ch/team/Dr-Anpei-Chen.html">Anpei Chen</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a> and <a href="https://uni-tuebingen.de/">University of Tubingen</a>), 
<a href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://sarahweiii.github.io/">Xinyue Wei</a> 
(<a href="https://ucsd.edu/">University of California San Diego</a>), 
<a href="https://vlg.inf.ethz.ch/team/Prof-Dr-Siyu-Tang.html">Siyu Tang</a> 
(<a href="https://ethz.ch/en.html">ETH Zurich</a>), 
<a href="http://ai.ucsd.edu/~haosu/">Hao Su</a> 
<a href="https://sarahweiii.github.io/">Xinyue Wei</a> 
<a href="https://www.cvlibs.net/">Andreas Geiger</a> 
(<a href="https://uni-tuebingen.de/">University of Tubingen</a> and <a href="https://tuebingen.ai/">Tubingen AI Center</a>)
</dd>

<dt><b>ScanBot: Autonomous Reconstruction via Deep Reinforcement Learning</b>
	<a href="https://hezhicao.github.io/Scanbot/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://hezhicao.github.io/Scanbot/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Hezhi Cao*, 
Xi Xia*, 
Guan Wu 
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>), 
<a href="https://csse.szu.edu.cn/staff/ruizhenhu/index.htm">Ruizhen Hu</a> 
(<a href="https://en.szu.edu.cn/">Shenzhen University</a>), 
<a href="http://staff.ustc.edu.cn/~lgliu/">Ligang Liu</a> 
(<a href="https://en.ustc.edu.cn/">University of Science and Technology of China</a>)
(* Joint first authors)
</dd>

<dt><b>TextDeformer: Geometry Manipulation Using Text Guidance</b>
	<a href="https://threedle.github.io/TextDeformer/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://threedle.github.io/TextDeformer/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://threedle.github.io/TextDeformer/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/threedle/TextDeformer"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
William Gao
(<a href="https://www.uchicago.edu/">University of Chicago</a>), 
<a href="https://noamaig.github.io/">Noam Aigerman</a>, 
<a href="https://research.adobe.com/person/thibault-groueix/">Thibault Groueix</a>, 
<a href="http://www.vovakim.com/">Vladimir G. Kim</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://people.cs.uchicago.edu/~ranahanocka/">Rana Hanocka</a> 
(<a href="https://www.uchicago.edu/">University of Chicago</a>)
</dd>

<dt><b>SSIF: Single-shot Implicit Morphable Faces with Consistent Texture Parameterization</b>
	<a href="https://research.nvidia.com/labs/toronto-ai/ssif/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/toronto-ai/ssif/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://research.nvidia.com/labs/toronto-ai/ssif/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://connorzlin.com/">Connor Zhizhen Lin</a> 
(<a href="https://www.stanford.edu/">Stanford University</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://luminohope.org/">Koki Nagano</a>, 
<a href="https://jankautz.com/">Jan Kautz</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://ericryanchan.github.io/">Eric Ryan Chan</a> 
(<a href="https://www.stanford.edu/">Stanford University</a> and <a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="http://www.umariqbal.info/">Umar Iqbal</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>, 
<a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a> 
(<a href="https://www.stanford.edu/">Stanford University</a>), 
<a href="https://www.samehkhamis.com/">Sameh Khamis</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>)
</dd>

<dt><b>Neural Progressive Meshes</b>
	<a href="https://www.cs.toronto.edu/~jacobson/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://yunchunchen.github.io/">Yun-Chun Chen</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="http://www.vovakim.com/">Vladimir G. Kim</a>, 
<a href="https://noamaig.github.io/">Noam Aigerman</a>, 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a> 
(<a href="https://www.utoronto.ca/">University of Toronto</a> and <a href="https://research.adobe.com/">Adobe Research</a>) 
</dd>

</dl>

<h2>Making Contact: Simulating and Detecting Collisions</h2>
<dl>

<dt><b>In-Timestep Remeshing for Contacting Elastodynamics</b>
	<a href="https://zferg.us/research/in-timestep-remeshing/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://zferg.us/research/in-timestep-remeshing/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://zferg.us/research/in-timestep-remeshing/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://zferg.us/">Zachary Ferguson</a> 
(<a href="https://www.nyu.edu/">New York University</a>), 
<a href="https://web.uvic.ca/~teseo/">Teseo Schneider</a> 
(<a href="https://www.uvic.ca/">University of Victoria</a>), 
<a href="https://research.adobe.com/person/danny-kaufman/">Danny Kaufman</a>+ 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://cims.nyu.edu/gcl/daniele.html">Daniele Panozzo</a>+ 
(<a href="https://www.nyu.edu/">New York University</a>) 
+ Joint last authors
</dd>

<dt><b>Shortest Path to Boundary for Self-intersecting Meshes</b>
	<a href="https://graphics.cs.utah.edu/research/projects/shortest-path-to-boundary/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://graphics.cs.utah.edu/research/projects/shortest-path-to-boundary/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://graphics.cs.utah.edu/research/projects/shortest-path-to-boundary/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://ankachan.github.io/">He Chen</a>, 
<a href="https://diaz-elie.com/">Elie Diaz</a> 
(<a href="http://www.utah.edu/">University of Utah</a>)), 
<a href="http://www.cemyuksel.com/">Cem Yuksel</a> 
(<a href="http://www.utah.edu/">University of Utah</a> and <a href="https://corp.roblox.com/research/">Roblox Research</a>) 
</dd>

<dt><b>P2M: A Fast Solver for Querying Distance From Point to Mesh Surface</b>
	</dt>
<dd>
Chen Zong
Jiacheng Xu
Jiantao Song
Shuangmin Chen
Shiqing Xin
<a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html">Wenping Wang</a> 
(<a href="https://www.tamu.edu/">Texas A&amp;M University</a>), 
<a href="http://irc.cs.sdu.edu.cn/~chtu/index.html">Changhe Tu</a> 
(<a href="https://www.en.sdu.edu.cn/">Shandong University</a>) 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>), 
<a href=""></a> 
(<a href=""></a>)
</dd>

<dt><b>Fast GPU-based Two-way Continuous Collision Handling</b>
	<a href="https://wanghmin.github.io/publications.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://wanghmin.github.io/publications.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
	
<dd>
<a href="https://wtyatzoo.github.io/">Tianyu Wang</a> 
(<a href="https://www.faceunity.com/">FaceUnity</a>), 
<a href="https://jiongchen.github.io/">Jiong Chen</a> 
(<a href="https://www.polytechnique.edu/en">Ecole Polytechnique</a>), 
<a href="https://cn.linkedin.com/in/%E5%86%AC%E5%B9%B3-%E6%9D%8E-87a61798">Dongping Li</a>, 
Xiaowei Liu 
(<a href="https://www.faceunity.com/">FaceUnity</a>), 
<a href="https://wanghmin.github.io/">Huamin Wang</a> 
(<a href="https://www.linctex.com/">Style3D</a>), 
<a href="http://kunzhou.net/">Kun Zhou</a> 
(<a href="http://www.zju.edu.cn/">Zhejiang University</a>)
</dd>

<dt><b>Sum-of-squares Collision Detection for Curved Shapes and Paths</b>
	</dt>
<dd>
<a href="https://people.csail.mit.edu/pzpzpzp1/">Paul Zhang</a>*, 
<a href="https://zoemarschner.com/">Zoe Marschner</a>*, 
<a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a> 
(<a href="https://www.mit.edu/">Massachusetts Institute of Technology</a>), 
<a href="https://studios.disneyresearch.com/people/rasmus-tamstorf/">Rasmus Tamstorf</a> 
(<a href="https://studios.disneyresearch.com/">Disney Research Studios</a>) 
* denotes equal contribution
</dd>

<dt><b>High-order Incremental Potential Contact for Elastodynamic Simulation on Curved Meshes</b>
	<a href="https://zferg.us/research/high-order-ipc/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://zferg.us/research/high-order-ipc/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://zferg.us/research/high-order-ipc/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://zferg.us/">Zachary Ferguson</a>, 
Pranav Jain, 
<a href="https://cims.nyu.edu/gcl/denis.html">Denis Zorin</a> 
(<a href="https://www.nyu.edu/">New York University</a>), 
<a href="https://web.uvic.ca/~teseo/">Teseo Schneider</a> 
(<a href="https://www.uvic.ca/">University of Victoria</a>), 
<a href="https://cims.nyu.edu/gcl/daniele.html">Daniele Panozzo</a> 
(<a href="https://www.nyu.edu/">New York University</a>)
</dd>

</dl>

<h2>Material Acquisition</h2>
<dl>

<dt><b>Ultra-high Resolution SVBRDF Recovery From a Single Image</b>
	</dt>
<dd>
Jie Guo, 
Shuichang Lai, 
Qinghao Tu, 
Chengzhi Tao 
(<a href="https://www.nju.edu.cn/en/">Nanjing University</a>), 
<a href="https://person.zju.edu.cn/en/changqingzou">Changqing Zou</a> 
(<a href="https://www.zju.edu.cn/english/">Zhejiang University</a>), 
<a href="https://cs.nju.edu.cn/ywguo/index.htm">Yanwen Guo</a> 
(<a href="https://www.nju.edu.cn/en/">Nanjing University</a>)
</dd>

<dt><b>Towards Material Digitization With a Dual-scale Optical System</b>
	<a href="https://www.elenagarces.es/projects/SEDDIDome/web/index.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.elenagarces.es/projects/SEDDIDome/web/index.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.elenagarces.es/projects/SEDDIDome/web/index.html"><img alt="Paper Data" src="Data.png" border="0"></a>
	</dt>
<dd>
<a href="http://elenagarces.es/">Elena Garces</a> 
(<a href="https://www.urjc.es/">Universidad Rey Juan Carlos</a> and <a href="https://seddi.com/">SEDDI</a>), 
<a href="http://elenagarces.es/authors/victor-arellano/">Victor Arellano</a> 
(<a href="https://seddi.com/">SEDDI</a>), 
<a href="http://carlosrodriguezpardo.es/">Carlos Rodriguez-Pardo</a> 
(<a href="https://www.urjc.es/">Universidad Rey Juan Carlos</a> and <a href="https://seddi.com/">SEDDI</a>), 
<a href="http://elenagarces.es/authors/david-pascual-hernandez/">David Pascual-Hernandez</a>, 
<a href="http://elenagarces.es/authors/sergio-suja/">Sergio Suja</a> 
(<a href="https://seddi.com/">SEDDI</a>), 
<a href="http://www.jorg3.com/">Jorge Lopez-Moreno</a> 
(<a href="https://www.urjc.es/">Universidad Rey Juan Carlos</a> and <a href="https://seddi.com/">SEDDI</a>) 
</dd>

<dt><b>End-to-end Procedural Material Capture With Proxy-free Mixed-integer Optimization</b>
	<a href="https://cdfg.mit.edu/publications/diffmatv2"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://cdfg.mit.edu/publications/diffmatv2"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Beichen Li, 
<a href="https://people.csail.mit.edu/liangs/">Liang Shi</a>, 
<a href="https://cdfg.csail.mit.edu/wojciech">Wojciech Matusik</a> 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a>) 
</dd>

<dt><b>Materialistic: Selecting Similar Materials in Images</b>
	<a href="https://prafullsharma.net/materialistic/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://prafullsharma.net/materialistic/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://prafullsharma.net/">Prafull Sharma</a> 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a> and <a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://julienphilip.com/">Julien Philip</a>, 
<a href="http://mgharbi.com/">Michael Gharbi</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://billf.mit.edu/">William T. Freeman</a>, 
<a href="https://people.csail.mit.edu/fredo/">Fredo Durand</a> 
(<a href="https://www.csail.mit.edu/">MIT CSAIL</a>), 
<a href="https://valentin.deschaintre.fr/">Valentin Deschaintre</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>)
</dd>

<dt><b>Single Image Neural Material Relighting</b>
	<a href="https://www.cs.wm.edu/~ppeers/showPublication.php?id=Bieron:2023:SIN"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://www.cs.wm.edu/~ppeers/showPublication.php?id=Bieron:2023:SIN"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.cs.wm.edu/~ppeers/showPublication.php?id=Bieron:2023:SIN"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://www.cs.wm.edu/~ppeers/showPublication.php?id=Bieron:2023:SIN"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
James Bieron 
(<a href="https://www.wm.edu/">College of William &amp; Mary</a>), 
<a href="http://research.microsoft.com/en-us/um/people/xtong/xtong.html">Xin Tong</a> 
(<a href="http://research.microsoft.com/en-us/labs/asia/">Microsoft Research Asia</a>), 
<a href="https://www.cs.wm.edu/~ppeers/">Pieter Peers</a> 
(<a href="https://www.wm.edu/">College of William &amp; Mary</a>) 
</dd>

<dt><b>Neural Biplane Representation for BTF Rendering and Acquisition</b>
	<a href="https://wangningbei.github.io/2023/BIPLANEBTF.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://wangningbei.github.io/2023/BIPLANEBTF.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://whois-jiahui.fun/">Jiahui Fan</a> 
(<a href="https://english.njust.edu.cn/">Nanjing University of Science and Technology</a>),
<a href="https://wangningbei.github.io/">Beibei Wang</a> 
(<a href="https://en.nankai.edu.cn/">Nankai University</a> and <a href="https://english.njust.edu.cn/">Nanjing University of Science and Technology</a>), 
<a href="http://www.miloshasan.net/">Milos Hasan</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
Jian Yang 
(<a href="https://english.njust.edu.cn/">Nanjing University of Science and Technology</a>),
<a href="https://sites.cs.ucsb.edu/~lingqi/">Ling-Qi Yan</a> 
(<a href="https://www.ucsb.edu/">University of California, Santa Barbara</a>)
</dd>

</dl>

<h2>Neural Image Generation and Editing</h2>
<dl>

<dt><b>Attend-and-Excite: Attention-based Semantic Guidance for Text-to-image Diffusion Models</b>
	<a href="https://yuval-alaluf.github.io/Attend-and-Excite/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://yuval-alaluf.github.io/Attend-and-Excite/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://yuval-alaluf.github.io/Attend-and-Excite/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/yuval-alaluf/Attend-and-Excite"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://hila-chefer.github.io/">Hila Chefer</a>*, 
<a href="https://yuval-alaluf.github.io/">Yuval Alaluf</a>*, 
<a href="https://yael-vinker.github.io/website/">Yael Vinker</a>, 
<a href="http://www.cs.tau.ac.il/~wolf/">Lior Wolf</a>, 
<a href="https://danielcohenor.com/">Daniel Cohen-Or</a> 
(<a href="https://english.tau.ac.il/">Tel-Aviv University</a>)
* Denotes equal contribution
</dd>

<dt><b>Blended Latent Diffusion</b>
	<a href="https://omriavrahami.com/blended-latent-diffusion-page/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://omriavrahami.com/blended-latent-diffusion-page/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://omriavrahami.com/blended-latent-diffusion-page/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/omriav/blended-latent-diffusion"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://omriavrahami.com/">Omri Avrahami</a> 
(<a href="https://en.huji.ac.il/">The Hebrew University of Jerusalem</a>), 
<a href="https://www.ohadf.com/">Ohad Fried</a> 
(<a href="https://www.runi.ac.il/en">Reichman University</a>), 
<a href="https://www.cs.huji.ac.il/~danix/">Dani Lischinski</a> 
(<a href="https://en.huji.ac.il/">The Hebrew University of Jerusalem</a>)
</dd>

<dt><b>Encoder-based Domain Tuning for Fast Personalization of Text-to-Image Models</b>
	<a href="https://tuning-encoder.github.io/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://tuning-encoder.github.io/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
<a href="https://rinongal.github.io/">Rinon Gal</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a> and <a href="https://english.tau.ac.il/">Tel-Aviv University</a>), 
<a href="https://research.nvidia.com/person/yuval-atzmon">Yuval Atzmon</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://www.cs.tau.ac.il/~amberman/">Amit Bermano</a> 
(<a href="https://english.tau.ac.il/">Tel-Aviv University</a>), 
<a href="https://research.nvidia.com/person/gal-chechik">Gal Chechik</a> 
(<a href="https://www.nvidia.com/">NVIDIA</a>), 
<a href="https://danielcohenor.com/">Daniel Cohen-Or</a> 
(<a href="https://english.tau.ac.il/">Tel-Aviv University</a>)
</dd>

<dt><b>Word-as-image for Semantic Typography</b>
	<a href="https://arxiv.org/abs/2303.01818"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2303.01818"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://github.com/Shiriluz/Word-As-Image"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://shiriluz.github.io/">Shir Iluz</a>*, 
<a href="https://yael-vinker.github.io/website/">Yael Vinker</a>*, 
<a href="https://amirhertz.github.io/">Amir Hertz</a> 
(<a href="https://english.tau.ac.il/">Tel-Aviv University</a>), 
<a href="https://www.gold.ac.uk/computing/people/berio-daniel-/">Daniel Berio</a> 
(<a href="https://www.gold.ac.uk/">Goldsmiths University</a>), 
<a href="https://danielcohenor.com/">Daniel Cohen-Or</a> 
(<a href="https://english.tau.ac.il/">Tel-Aviv University</a>), 
<a href="https://faculty.runi.ac.il/arik/site/index.asp">Ariel Shamir</a> 
(<a href="https://www.runi.ac.il/en">Reichman University</a>)
* Denotes equal contribution
</dd>

<dt><b>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</b>
	<a href="https://vcai.mpi-inf.mpg.de/projects/DragGAN/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://vcai.mpi-inf.mpg.de/projects/DragGAN/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://vcai.mpi-inf.mpg.de/projects/DragGAN/"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/XingangPan/DragGAN"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://xingangpan.github.io/">Xingang Pan</a> 
(<a href="http://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics</a> and <a href="https://www.via-center.science/">Saarbrucken Research Center for Visual Computing, Interaction and AI </a>), 
<a href="https://ayushtewari.com/">Ayush Tewari</a> 
(<a href="https://www.mit.edu/">MIT</a>), 
<a href="https://people.mpi-inf.mpg.de/~tleimkue/">Thomas Leimkuhler</a> 
(<a href="http://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics</a>), 
<a href="https://lingjie0206.github.io/">Lingjie Liu</a> 
(<a href="http://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics</a> and <a href="https://www.upenn.edu/">University of Pennsylvania</a>), 
<a href="https://www.meka.page/">Abhimitra Meka</a> 
(<a href="https://arvr.google.com/">Google AR/VR</a>), 
<a href="http://www.mpi-inf.mpg.de/~theobalt/">Christian Theobalt</a> 
(<a href="http://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics</a> and <a href="https://www.via-center.science/">Saarbrucken Research Center for Visual Computing, Interaction and AI </a>) 
</dd>

<dt><b>Diffusion Image Analogies</b>
	<a href="https://dcgi.fel.cvut.cz/home/sykorad/dia.html"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://dcgi.fel.cvut.cz/home/sykorad/dia.html"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://dcgi.fel.cvut.cz/home/sykorad/dia.html"><img alt="Paper Video" src="Video.png" border="0"></a>
	<a href="https://github.com/subrtadel/DIA"><img alt="Demo Program or Source Code" src="Code.png" border="0"></a>
	</dt>
<dd>
<a href="https://cmp.felk.cvut.cz/~subrtade/">Adela Subrtova</a> 
(<a href="https://www.cvut.cz/en">CTU in Prague</a>), 
<a href="https://research.adobe.com/person/michal-lukac/">Michal Lukac</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://cmp.felk.cvut.cz/~cechj/">Jan Cech</a>, 
<a href="https://dcgi.fel.cvut.cz/people/futscdav/">David Futschik</a> 
(<a href="https://www.cvut.cz/en">CTU in Prague</a>), 
<a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a> 
(<a href="https://research.adobe.com/">Adobe Research</a>), 
<a href="https://dcgi.felk.cvut.cz/~sykorad/">Daniel Sykora</a> 
(<a href="https://www.cvut.cz/en">CTU in Prague</a>)
</dd>

</dl>

<h2>NeRFs for Avatars</h2>
<dl>

<dt><b>AvatarReX: Real-time Expressive Full-body Avatars</b>
	<a href="https://liuyebin.com/AvatarRex/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://liuyebin.com/AvatarRex/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://liuyebin.com/AvatarRex/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="http://zhengzerong.github.io/">Zerong Zheng</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>), 
Xiaochen Zhao 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a> and <a href="https://nnkosmos.com">NNKosmos</a>), 
<a href="https://hongwenzhang.github.io/">Hongwen Zhang</a> 
Boning Liu
<a href="http://www.liuyebin.com/">Yebin Liu</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>) 
</dd>

<dt><b>SketchFaceNeRF: Sketch-based Facial Generation and Editing in Neural Radiance Fields</b>
	<a href="http://geometrylearning.com/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://www.youtube.com/watch?v=5ipABLyVSV4"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="http://geometrylearning.com/">Lin Gao</a>, 
Feng-Lin Liu
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a> and <a href="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences</a>), 
Shu-Yu Chen 
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a>), 
Kaiwen Jiang
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a> and <a href="http://en.bjtu.edu.cn/">Beijing Jiaotong University</a>), 
Chun-Peng Li
(<a href="https://english.cas.cn/">Chinese Academy of Sciences</a>), 
<a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a> 
(<a href="http://www.cardiff.ac.uk/">Cardiff University</a>), 
<a href="http://sweb.cityu.edu.hk/hongbofu/">Hongbo Fu</a> 
(<a href="http://www.cityu.edu.hk/">City Univ. of Hong Kong</a>)
</dd>

<dt><b>HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion</b>
	<a href="https://synthesiaresearch.github.io/humanrf/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2305.06356"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://synthesiaresearch.github.io/humanrf/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://www.mustafaisik.net/">Mustafa Isik</a>, 
<a href="https://www.martinruenz.de/">Martin Ruenz</a>, 
Markos Georgopoulos, 
<a href="https://khakhulin.github.io/">Taras Khakhulin</a>, 
Jonathan Starck 
(<a href="https://www.synthesia.io/">Synthesia</a>), 
<a href="http://www0.cs.ucl.ac.uk/staff/l.agapito/">Lourdes Agapito</a> 
(<a href="https://www.ucl.ac.uk/">University College London</a>), 
<a href="https://niessnerlab.org/">Matthias Niessner</a> 
(<a href="https://www.tum.de/en/">Technical University of Munich</a>)
</dd>

<dt><b>NeRSemble: Multi-view Radiance Field Reconstruction of Human Heads</b>
	<a href="https://tobias-kirschstein.github.io/nersemble/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://tobias-kirschstein.github.io/nersemble/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://tobias-kirschstein.github.io/nersemble/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
<a href="https://tobias-kirschstein.github.io/">Tobias Kirschstein</a>, 
<a href="https://shenhanqian.com/">Shenhan Qian</a>, 
<a href="https://simongiebenhain.github.io/">Simon Giebenhain</a>, 
<a href="https://www.linkedin.com/in/tim-walter-7203aa20b/?originalSubdomain=de">Tim Walter</a>, 
<a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Niessner</a> 
(<a href="https://www.tum.de/en/">Technical University of Munich</a>) 
</dd>

<dt><b>NOFA: NeRF-based One-shot Facial Avatar Reconstruction</b>
	<a href="https://arxiv.org/abs/2307.03441"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://arxiv.org/abs/2307.03441"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	</dt>
<dd>
Wangbo Yu, 
Yanbo Fan, 
Yong Zhang 
(<a href="https://ai.tencent.com/">Tencent AI Lab</a>), 
Xuan Wang 
(<a href="https://www.antgroup.com/en">Ant Group</a>), 
Fei Yin, 
Yunpeng Bai 
(<a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>), 
<a href="https://yanpei.me/">Yan-Pei Cao</a>, 
<a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&amp;hl=en">Ying Shan</a>, 
Yang Wu, 
Zhongqian Sun 
(<a href="https://ai.tencent.com/">Tencent AI Lab</a>), 
Baoyuan Wu
(<a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a>)
</dd>

<dt><b>LatentAvatar: Learning Latent Expression Code for Expressive Neural Head Avatar</b>
	<a href="https://liuyebin.com/latentavatar/"><img alt="Paper Abstract" src="Abstract.png" border="0"></a>
	<a href="https://liuyebin.com/latentavatar/"><img alt="Author Preprint" src="Preprint.png" border="0"></a>
	<a href="https://liuyebin.com/latentavatar/"><img alt="Paper Video" src="Video.png" border="0"></a>
	</dt>
<dd>
Yuelang Xu, 
<a href="https://hongwenzhang.github.io/">Hongwen Zhang</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>), 
<a href="https://lizhenwangt.github.io/">Lizhen Wang</a>, 
Xiaochen Zhao 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a> and <a href="https://nnkosmos.com">NNKosmos</a>), 
Han Huang, 
Guojun Qi 
(OPPO Research), 
<a href="http://www.liuyebin.com/">Yebin Liu</a> 
(<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>) 
</dd>

</dl>

<hr>
<address>kesen.huang@gmail.com</address>

<script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-1845250-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</body></html>