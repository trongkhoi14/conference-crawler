<!DOCTYPE html><html lang="" style="font-size: 10px;"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="/favicon.ico"><title>ACM Multimedia 2024 Regular Papers</title><script>fnResize();
        window.onresize = function() {
            fnResize();
        }

        function fnResize() {
            var deviceWidth = document.documentElement.clientWidth || window.innerWidth;
            if (deviceWidth >= 750) {
                deviceWidth = 750;
            }
            if (deviceWidth <= 320) {
                deviceWidth = 320;
            }
            document.documentElement.style.fontSize = (deviceWidth / 75) + 'px';
        }</script><link href="/css/chunk-00275525.307f3a9c.css" rel="prefetch"><link href="/css/chunk-002c98f1.ae926bb6.css" rel="prefetch"><link href="/css/chunk-0310f786.ee53db89.css" rel="prefetch"><link href="/css/chunk-05904019.49ce9fc1.css" rel="prefetch"><link href="/css/chunk-09fc40d6.cc5204a1.css" rel="prefetch"><link href="/css/chunk-0c766ffe.6f61322f.css" rel="prefetch"><link href="/css/chunk-0e515bff.68f63abd.css" rel="prefetch"><link href="/css/chunk-0ec1906d.5bdf1d57.css" rel="prefetch"><link href="/css/chunk-100c9f6e.de50714c.css" rel="prefetch"><link href="/css/chunk-106e4f92.75c7fef2.css" rel="prefetch"><link href="/css/chunk-10bfa71e.a3b398d3.css" rel="prefetch"><link href="/css/chunk-159b8fd4.2de0f3c8.css" rel="prefetch"><link href="/css/chunk-17717c04.3b0d8f8e.css" rel="prefetch"><link href="/css/chunk-2b89dfb0.ef094932.css" rel="prefetch"><link href="/css/chunk-30033741.422d1e9d.css" rel="prefetch"><link href="/css/chunk-3367d36e.b3c50de7.css" rel="prefetch"><link href="/css/chunk-34fc95de.5f838d1d.css" rel="prefetch"><link href="/css/chunk-3701ebc3.63fcdbda.css" rel="prefetch"><link href="/css/chunk-3913992c.2af11ee3.css" rel="prefetch"><link href="/css/chunk-39bcb628.83ef3f3d.css" rel="prefetch"><link href="/css/chunk-3aeafc3c.60e3f6c0.css" rel="prefetch"><link href="/css/chunk-44ad53eb.aace57ea.css" rel="prefetch"><link href="/css/chunk-46fc0122.c051c59b.css" rel="prefetch"><link href="/css/chunk-48660f17.8dc87d27.css" rel="prefetch"><link href="/css/chunk-4a2f9872.ac5dae0b.css" rel="prefetch"><link href="/css/chunk-5552ce06.d4321371.css" rel="prefetch"><link href="/css/chunk-59df60b5.30ed5b41.css" rel="prefetch"><link href="/css/chunk-5c6ec5c0.79de4274.css" rel="prefetch"><link href="/css/chunk-5ea97935.664ee228.css" rel="prefetch"><link href="/css/chunk-6761ea0e.5b9d54ea.css" rel="prefetch"><link href="/css/chunk-687c8740.407aff46.css" rel="prefetch"><link href="/css/chunk-70520f5c.58bfde60.css" rel="prefetch"><link href="/css/chunk-719a41bd.1df07e0e.css" rel="prefetch"><link href="/css/chunk-751a6d84.3ccc495f.css" rel="prefetch"><link href="/css/chunk-7e2c3fb1.d50f8594.css" rel="prefetch"><link href="/css/chunk-8ad5fe6c.5caac8c4.css" rel="prefetch"><link href="/css/chunk-96b53e20.b4167742.css" rel="prefetch"><link href="/css/chunk-a9b35862.53a3aecf.css" rel="prefetch"><link href="/css/chunk-be3b1ea2.2914146d.css" rel="prefetch"><link href="/css/chunk-d1157b08.bda5aecf.css" rel="prefetch"><link href="/css/chunk-ddf6bcf6.7af4cd9a.css" rel="prefetch"><link href="/css/chunk-f240d640.05081903.css" rel="prefetch"><link href="/css/chunk-f36676f8.9e9a83df.css" rel="prefetch"><link href="/js/chunk-00275525.48b58170.js" rel="prefetch"><link href="/js/chunk-002c98f1.fd6ace63.js" rel="prefetch"><link href="/js/chunk-0310f786.30076c7c.js" rel="prefetch"><link href="/js/chunk-05904019.f061d64a.js" rel="prefetch"><link href="/js/chunk-09fc40d6.3a011c3e.js" rel="prefetch"><link href="/js/chunk-0c766ffe.154917f1.js" rel="prefetch"><link href="/js/chunk-0e515bff.aa7ea4b8.js" rel="prefetch"><link href="/js/chunk-0ec1906d.a3347673.js" rel="prefetch"><link href="/js/chunk-100c9f6e.7cdb6a69.js" rel="prefetch"><link href="/js/chunk-106e4f92.35760136.js" rel="prefetch"><link href="/js/chunk-10bfa71e.db9e5ef9.js" rel="prefetch"><link href="/js/chunk-159b8fd4.4b4b8dd2.js" rel="prefetch"><link href="/js/chunk-17717c04.4ad1743d.js" rel="prefetch"><link href="/js/chunk-2b89dfb0.abde8864.js" rel="prefetch"><link href="/js/chunk-30033741.c7f1c651.js" rel="prefetch"><link href="/js/chunk-3367d36e.291e6f85.js" rel="prefetch"><link href="/js/chunk-34fc95de.dd33aa3a.js" rel="prefetch"><link href="/js/chunk-3701ebc3.24a82b06.js" rel="prefetch"><link href="/js/chunk-3913992c.0013cfba.js" rel="prefetch"><link href="/js/chunk-39bcb628.b5d925ee.js" rel="prefetch"><link href="/js/chunk-3aeafc3c.c6b0fad8.js" rel="prefetch"><link href="/js/chunk-44ad53eb.d8d1c946.js" rel="prefetch"><link href="/js/chunk-46fc0122.2b2fe560.js" rel="prefetch"><link href="/js/chunk-48660f17.0deaf1ee.js" rel="prefetch"><link href="/js/chunk-4a2f9872.881ad9af.js" rel="prefetch"><link href="/js/chunk-5552ce06.5b8dacbc.js" rel="prefetch"><link href="/js/chunk-59df60b5.1f6363e8.js" rel="prefetch"><link href="/js/chunk-5c6ec5c0.7adc09da.js" rel="prefetch"><link href="/js/chunk-5ea97935.7b8fc86c.js" rel="prefetch"><link href="/js/chunk-6761ea0e.8f0d8133.js" rel="prefetch"><link href="/js/chunk-687c8740.13d5ea1e.js" rel="prefetch"><link href="/js/chunk-70520f5c.d1800267.js" rel="prefetch"><link href="/js/chunk-719a41bd.9cd79bd8.js" rel="prefetch"><link href="/js/chunk-751a6d84.bab6ed55.js" rel="prefetch"><link href="/js/chunk-7e2c3fb1.d326f978.js" rel="prefetch"><link href="/js/chunk-8ad5fe6c.d06a8225.js" rel="prefetch"><link href="/js/chunk-96b53e20.5639d122.js" rel="prefetch"><link href="/js/chunk-a9b35862.02b74f3a.js" rel="prefetch"><link href="/js/chunk-be3b1ea2.5d306968.js" rel="prefetch"><link href="/js/chunk-d1157b08.1966bd42.js" rel="prefetch"><link href="/js/chunk-ddf6bcf6.e6a0050b.js" rel="prefetch"><link href="/js/chunk-f240d640.7aa301a7.js" rel="prefetch"><link href="/js/chunk-f36676f8.72f55395.js" rel="prefetch"><link href="/css/app.22c5f11d.css" rel="preload" as="style"><link href="/css/chunk-vendors.fc89d090.css" rel="preload" as="style"><link href="/js/app.91b1967e.js" rel="preload" as="script"><link href="/js/chunk-vendors.eeb61fec.js" rel="preload" as="script"><link href="/css/chunk-vendors.fc89d090.css" rel="stylesheet"><link href="/css/app.22c5f11d.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="/css/chunk-39bcb628.83ef3f3d.css"><script charset="utf-8" src="/js/chunk-39bcb628.b5d925ee.js"></script><link rel="stylesheet" type="text/css" href="/css/chunk-05904019.49ce9fc1.css"><script charset="utf-8" src="/js/chunk-05904019.f061d64a.js"></script><link rel="stylesheet" type="text/css" href="/css/chunk-f240d640.05081903.css"><script charset="utf-8" src="/js/chunk-f240d640.7aa301a7.js"></script></head><body><noscript><strong>We're sorry but acmmm doesn't work properly without JavaScript enabled. Please enable it to continue.</strong></noscript><div data-v-2dbd005e="" id="app"><div data-v-2dbd005e="" class="totop flexCenter" style="display: none;"><i data-v-2dbd005e="" class="el-icon-top" style="color: rgb(255, 255, 255);"></i></div><div data-v-1a17618c="" data-v-2dbd005e=""><div data-v-1a17618c="" class="header el-row"><div data-v-1a17618c="" class="el-col el-col-24"><div data-v-7d0facd2="" data-v-1a17618c=""><nav data-v-7d0facd2="" class="navbar navbar-default"><div data-v-7d0facd2="" class="container-fluid"><div data-v-7d0facd2="" class="navbar-header"><button data-v-7d0facd2="" type="button" id="button-menu" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false" class="navbar-toggle collapsed"><span data-v-7d0facd2="" class="sr-only">Toggle navigation</span><span data-v-7d0facd2="" class="icon-bar"></span><span data-v-7d0facd2="" class="icon-bar"></span><span data-v-7d0facd2="" class="icon-bar"></span></button><div data-v-7d0facd2="" class="navbar-header"><a data-v-7d0facd2="" href="#" class="navbar-brand"><a data-v-7d0facd2="" href="/" class="router-link-active"><img data-v-7d0facd2="" alt="Brand" src="/img/mm_logo_nobg.9dc2d630.png" class="logImage"></a></a></div></div><div data-v-7d0facd2="" id="bs-example-navbar-collapse-1" class="collapse navbar-collapse"><ul data-v-7d0facd2="" class="nav navbar-nav navbar-collapse"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/" class="router-link router-link-active">Home</a></a></li><li data-v-7d0facd2="" class="dropdown"><a data-v-7d0facd2="" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle">Registration </a><ul data-v-7d0facd2="" class="dropdown-menu"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/registration" class="router-link">Registration</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/accommodation" class="router-link">Accommodation </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/visa_information" class="router-link">Visa Information </a></a></li></ul></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/important-dates" class="router-link">Important Dates</a></a></li><li data-v-7d0facd2="" class="dropdown"><a data-v-7d0facd2="" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle">Calls for Submission </a><ul data-v-7d0facd2="" class="dropdown-menu"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/regular-papers" aria-current="page" class="router-link router-link-exact-active router-link-active">Regular Papers</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/multimedia-grand-challenge-proposals" class="router-link">Multimedia Grand Challenge Proposals </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/multimedia-grand-challenge-submissions" class="router-link">Multimedia Grand Challenge </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/panel-proposals" class="router-link">Panel Proposals</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/workshop-proposals" class="router-link">Workshop Proposals</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/technical-demos-and-videos-program" class="router-link">Technical Demos and Videos Program </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/tutorial-proposals" class="router-link">Tutorial Proposals</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/brave-new-ideas-proposals" class="router-link">Brave New Ideas Proposals </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/industrial-demo" class="router-link">Call For Industry Demonstrations </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/open-source-software-competition" class="router-link">Open Source Software Competition </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/doctoral-cymposium" class="router-link">Doctoral Symposium</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/reproducibility-companion-papers" class="router-link">Reproducibility Companion Papers </a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/authors-advocate" class="router-link">Author’s Advocate </a></a></li></ul></li><li data-v-7d0facd2="" class="dropdown"><a data-v-7d0facd2="" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle">Guidelines</a><ul data-v-7d0facd2="" class="dropdown-menu"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/policies" class="router-link">Policies</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/reviewer_guidelines" class="router-link">Reviewer Guidelines</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/volunteer_ac" class="router-link">Call for Volunteer Area Chairs and Reviewers</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/major_differences" class="router-link">Major Differences: MM24 vs Previous</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/ac_guidelines" class="router-link">AC and SAC Guidelines</a></a></li></ul></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle">Program</a><ul data-v-7d0facd2="" class="dropdown-menu"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/keynotes" class="router-link">Conference Keynotes</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/multimedia-grand-challenge-submissions" class="router-link">Multimedia Grand Challenge</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/workshop-papers" class="router-link">Workshop</a></a></li></ul></a></li><li data-v-7d0facd2="" class="dropdown"><a data-v-7d0facd2="" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle">Organisation</a><ul data-v-7d0facd2="" class="dropdown-menu"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/organisation-committee" class="router-link">Organisation Committee</a></a></li></ul></li><li data-v-7d0facd2="" class="dropdown"><a data-v-7d0facd2="" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle">Sponsorship</a><ul data-v-7d0facd2="" class="dropdown-menu"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/call_for_sponsor_aus" class="router-link">Call for Sponsors</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/our_sponsors" class="router-link">Our Sponsors</a></a></li></ul></li><li data-v-7d0facd2="" class="dropdown"><a data-v-7d0facd2="" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" class="dropdown-toggle">Destination</a><ul data-v-7d0facd2="" class="dropdown-menu"><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/explore_melbourne" class="router-link">Explore Melbourne</a></a></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/visit_victoria" class="router-link">Visit Victoria</a></a></li></ul></li><li data-v-7d0facd2=""><a data-v-7d0facd2="" href="#"><a data-v-7d0facd2="" href="/contact" class="router-link">Contact Us</a></a></li></ul></div></div></nav></div></div></div><div data-v-1a17618c="" class="context el-row"><div data-v-1a17618c="" class="el-col el-col-24 el-col-xs-2 el-col-sm-2 el-col-md-2 el-col-lg-4 el-col-xl-6"><div data-v-1a17618c="" class="grid-content"></div></div><div data-v-1a17618c="" class="el-col el-col-24 el-col-xs-20 el-col-sm-20 el-col-md-20 el-col-lg-16 el-col-xl-12"><div data-v-c73391dc="" data-v-1a17618c=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="title-admin el-col el-col-24"> Call for Regular Papers </div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="primaryTitle el-row"><div data-v-c73391dc="" class="el-col el-col-2"><img data-v-c73391dc="" src="/img/bullet_point.ec17d8ed.png" alt="" class="icon"></div><div data-v-c73391dc="" class="el-col el-col-22"><p data-v-c73391dc="" class="title">Introduction</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">ACM Multimedia is the premier conference in multimedia, a research field that discusses emerging computing methods from a perspective in which each medium — e.g. images, text, audio — is a strong component of the complete, integrated exchange of information. The multimedia community has a tradition of being able to handle big data, has been a pioneer in large-scale evaluations and dataset creations, and is uniquely angled towards novel applications and cutting-edge industrial challenges. As such the conference openly embraces new intellectual angles from both industry as well as academia and welcomes submissions from related fields, such as data science, HCI, and signal processing.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">ACM Multimedia 2024 calls for research papers presenting novel theoretical and algorithmic solutions to address problems across multimedia and related application fields. The conference also calls for papers presenting novel, thought-provoking ideas, and promising (preliminary) results in realizing these ideas. Topics of interest include but are not limited to four major themes of multimedia: Engagement, Experience, Systems, and Understanding.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">The conference invites research papers of varying lengths from 6 to 8 pages, plus additional pages for the reference pages; i.e., the reference page(s) are not counted towards the page limit of 6 to 8 pages. Please note that there is no longer a distinction between long and short papers, but the authors may themselves decide on the appropriate length of the paper. All papers will undergo the same review process and review period.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Submit your paper to Open Review: <a class="demo-link" href="https://openreview.net/group?id=acmmm.org/ACMMM/2024/Conference">https://openreview.net/group?id=acmmm.org/ACMMM/2024/Conference</a>.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryMiddleTitle el-col el-col-24"><p data-v-c73391dc="">Theme: Engaging Users with Multimedia</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">The engagement of multimedia with society as a whole requires research that addresses how multimedia can be used to connect people with multimedia artifacts that meet their needs in a variety of contexts. The topic areas included under this theme include:</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Emotional and Social Signals</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">This area focuses on the analysis of emotional, cognitive (e.g., brain-based) and interactive social behavior in the spectrum of individual to small group settings. It calls for novel contributions with a strong human-centered focus specializing in supporting or developing automated techniques for analyzing, processing, interpreting, synthesizing, or exploiting human social, affective and cognitive signals for multimedia applications.)</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Multimedia Search and Recommendation</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">To engage user in information access, search and recommendation requires not only understanding of data but also user and context. This area calls for novel solutions for user-centric multimedia search and recommendations, in either automatic or interactive mode, with topics ranging from optimization, user intent prediction, to personalized, collaborative or exploratory algorithms. (Note: Topics focusing primarily on indexing and scalability should be submitted to <b>"Multimedia systems: Data Systems indexing and management"</b>)</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Summarization, Analytics, and Storytelling</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">The information underlying multimedia is by nature multi-perspective. Allowing efficient multi-perspective and context-adaptive information access remains an open problem. This area calls for new and novel solutions that can compose, link, edit and summarize multimedia data into a compact but insightful, enjoyable and multi-perspective presentation to facilitate tasks such as multimedia analytics, decision making, searching and browsing.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryMiddleTitle el-col el-col-24"><p data-v-c73391dc="">Theme: Experience</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">One of the core tenants of our research community is that multimedia contributes to the user experience in a rich and meaningful manner. The topics organized under this theme are concerned with innovative uses of multimedia to enhance the user experience, how this experience is manifested in specific domains, and metrics for qualitatively and quantitatively measuring that experience in useful and meaningful ways. Specific topic areas addressed this year include:</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Interactions and Quality of Experience</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Papers under this topic area should address human-centered issues. Topics include (i) novel interaction techniques and modalities for accessing, authoring, and consuming multimedia data, (ii) design and implementation of novel interactive media (iii) new methodologies, models, and metrics to understand and/or measure multimedia quality of experience.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Art and Culture</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Papers under this topic area should develop techniques that enable effective engagement of the public with art and other forms of cultural expression, balancing between sophisticated computational/engineering techniques and artistic / cultural purposes. Topics include (i) digital artworks, including hybrid physical digital installations; dynamic, generative, and interactive multimedia artworks; (ii) computational tools to support creativity, cultural preservation, and curation.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Multimedia Applications</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Papers under this topic area should push the envelope of how multimedia can be used to improve the user experience in a rich and meaningful manner. We solicit papers that design, implement, and evaluate applications that employ multimedia data in surprising new ways or in application scenarios that user experience remains challenging based on today's start-of-the-art, such as immersive telepresence, distance education, and metaverse.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryMiddleTitle el-col el-col-24"><p data-v-c73391dc="">Theme: Multimedia Systems</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Research in multimedia systems is generally concerned with understanding fundamental trade-offs between competing resource requirements, developing practical techniques and heuristics for realizing complex optimization and allocation strategies, and demonstrating innovative mechanisms and frameworks for building large-scale multimedia applications. Within this theme, we have focused on three target topic areas:</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Systems and Middleware</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">This area seeks novel contributions that address performance issues in one of the systems components. Topics include operating systems, mobile systems, storage systems, distributed systems, programming systems and abstractions, and embedded systems. Papers must establish performance improvement or non-trivial trade-offs through integration of multiple systems components or enhancing one of the system components.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Transport and Delivery</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Papers under this topic area should address improvement to multimedia transport and delivery mechanisms over a computer network. Topics include network protocol enhancement, supporting multimedia data with network mechanisms such as SDN and NFV, in-network content placement.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Data Systems Management and Indexing</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Papers under this topic area should address performance issues related to data management and indexing to support multimedia access at a large scale, including browsing, searching, recommendation, analysis, processing, and mining. Topics include scalable systems and indexing techniques that support multimedia access and analytics.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryMiddleTitle el-col el-col-24"><p data-v-c73391dc="">Theme: Multimedia Content Understanding</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Multimedia data types by their very nature are complex and often involve intertwined instances of different kinds of information. We can leverage this multi-modal perspective in order to extract meaning and understanding of the world, often with surprising results. Specific topics addressed this year include:</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Multimodal Fusion</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">In the real world, some problems are addressable only through a combination of multiple media and/or modalities. This area seeks new insights and solutions of how multi-perspective media information should be fused and embedded for novel problems as well as innovative systems.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Vision and Language</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Recent research has driven the merging of vision and language in different ways, for example, captioning, question-answering, multi-modal chatbots. This area seeks new solutions and results that are specific to the problems of combining or bridging vision and language.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Multimedia Interpretation</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">This area seeks novel processing of media-related information in any form that can lead to new ways of interpreting or creating multimedia content. Examples include processing of visual, audio, music, language, speech, or other modalities, for interpretation, knowledge inference, understanding and generation.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryMiddleTitle el-col el-col-24"><p data-v-c73391dc="">Theme: Multimedia in the Generative AI Era</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Generative AI empowered by foundation models and multi-modal training data have made exciting advancements in the past few years. This theme collects the latest techniques and applications in this generative AI era that benefit multimedia applications. Topics of interest are listed below. </p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Multimedia Foundation Models</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Large language models (LLMs) are representatives of foundation models. There are numerous improvements marrying LLMs with other diverse modalities such as images, videos, and audios. This topic seeks state-of-the-art techniques in multimedia alignment, architecture design, new applications and fundamental insights.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Generative Multimedia</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">This topic focuses on generative models such as Diffusion models and Generative Adversarial Networks that allow multimedia systems to generate content with unparalleled realism and diversity. Emphasis is also placed on interactive and personalized systems that allow for better user experience.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Social Aspects of Generative AI</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">The success of generative AI requires deep thinking into its social impact. This topic calls for research works in promoting privacy, security fairness and transparency of generative AI models. New applications to improve social well-being and AI interpretability are also a focus.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="primaryTitle el-row"><div data-v-c73391dc="" class="el-col el-col-2"><img data-v-c73391dc="" src="/img/bullet_point.ec17d8ed.png" alt="" class="icon"></div><div data-v-c73391dc="" class="el-col el-col-22"><p data-v-c73391dc="" class="title">Important Dates</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Please note: The submission deadline is at 11:59 p.m. of the stated deadline date <a class="demo-link" href="https://www.timeanddate.com/time/zones/aoe">Anywhere on Earth</a>.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Abstract submission deadline: <b>April 8, 2024</b></div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Full paper submission deadline: <b>April 12, 2024</b></div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Regular Paper Reviews to Author: <b>June 10, 2024</b></div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Regular Paper Rebuttal Deadline: <b>June 17, 2024</b></div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Notification: <b>July 15, 2024</b></div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Regular Paper camera-ready submission: <b>July 29, 2024</b></div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="primaryTitle el-row"><div data-v-c73391dc="" class="el-col el-col-2"><img data-v-c73391dc="" src="/img/bullet_point.ec17d8ed.png" alt="" class="icon"></div><div data-v-c73391dc="" class="el-col el-col-22"><p data-v-c73391dc="" class="title">Submission Instructions</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Submission System:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text"><a class="demo-link" href="https://openreview.net/group?id=acmmm.org/ACMMM/2024/Conference">https://openreview.net/group?id=acmmm.org/ACMMM/2024/Conference</a>.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">ACM MM24 uses OpenReview for paper submission and peer review. To handle conflict of interest, we require every author to (1) have an OpenReview profile and (2) keep it update with publications, employment and email addresses.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Important Note: We may desk-reject papers which has authors without a valid OpenReview profile after the full paper submission deadline <b>(April 12, 2024)</b>.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">For any question or inquiry, please contact <a class="demo-link" href="mailto:acmmm2024pc@gmail.com"> &lt;acmmm2024pc@gmail.com&gt;</a></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:red">(New &amp; Important)</span> <span style="color:black">Multimedia/multimodality statement for paper submissions:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">As the volume of submissions to the MM conference continues to grow annually, the SIGMM community seeks to distinguish itself from other communities such as NeurIPS, CVPR, and ECCV. Our focus lies in promoting research that is inherently multimedia or multimodal in nature. To achieve this, all paper authors are required to submit a concise 200-word statement outlining how their work contributes to the advancement of multimedia and multimodal processing. While papers that involve unimedia/unimodal processing will not necessarily be rejected, papers that make multimedia/multimodal research contributions will be preferred for publication in the conference proceedings.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:red">(New &amp; Important)</span> <span style="color:black"> Paper Format:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Submitted papers (.pdf format) must use the ACM Article Template: <a class="demo-link" href="/files/ACM-MM24-paper-templates.zip">paper template</a>. Please remember to add Concepts and Keywords. Please use the template in traditional double-column format to prepare your submissions. For example, word users may use <b>Word Interim Template</b>, and latex users may use <b>sample-sigconf-authordraft</b> template. When using <b>sample-sigconf-authordraft</b> template, please comment all the author information for submission and review of manuscript, instead of changing the documentclass command to <b>'\documentclass[manuscript, screen, review]{acmart}'</b> as told by instructions.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Pls ensure that you submit your papers subscribing to <b>this format</b> for full consideration during the review process.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:red">(New &amp; Important)</span> <span style="color:black">Policy on authorship and generative AI tools:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Generative AI tools and technologies, such as ChatGPT, may not be listed as authors of an ACM published Work. The use of generative AI tools and technologies to create content is permitted but must be fully disclosed in the Work. If generative AI language tools generate inappropriate language, plagiarized content, errors, mistakes, incorrect references, or misleading content, and that output is included in scientific works, author(s) will take full responsibility for the same. For details and more polices, please see <a class="demo-link" href="https://2024.acmmm.org/policies">here</a>.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Length:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Submitted papers may consist of up to 8 pages. Up to two additional pages may be added for references. The reference pages must only contain references. Overlength papers will be rejected without review. Optionally, you may upload supplementary material that complements your submission (<b>50Mb</b> limit).</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">All the content other than that in the main paper should be written in the separate supplementary material. We do not allow appendix that follow right after the main paper in the main submission file.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Blinding:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Paper submissions must conform with the “double-blind” review policy. This means that the authors should not know the names of the reviewers of their papers, and reviewers should not know the names of the authors. Please prepare your paper in a way that preserves anonymity of the authors.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Do not put the authors’ names under the title.</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Avoid using phrases such as “our previous work” when referring to earlier publications by the authors.</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Remove information that may identify the authors in the acknowledgments (e.g., co-workers and grant IDs).</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Check supplemental material (e.g., titles in the video clips, or supplementary documents) for information that may identify the authors’ identities.</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Avoid providing links to websites that identify the authors.</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Papers without appropriate blinding will be rejected without review.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Originality:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Papers submitted to ACM Multimedia must be the original work of the authors. The may not be simultaneously under review elsewhere. Publications that have been peer-reviewed and have appeared at other conferences or workshops may not be submitted to ACM Multimedia (see also the arXiv/Archive policy below). Authors should be aware that ACM has a strict policy with regard to plagiarism and self-plagiarism (<a class="demo-link" href="https://www.acm.org/publications/policies/plagiarism">https://www.acm.org/publications/policies/plagiarism</a>). The authors’ prior work must be cited appropriately.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Author List:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Please ensure that you submit your papers with the full and final list of authors in the correct order. The author list registered for each submission is not allowed to change in any way after the <b>full paper submission deadline</b>. (Note that this rule regards the identity of authors, e.g., typos are correctable.)</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Proofreading:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Please proofread your submission carefully. It is essential that the language used in the paper is clear and correct so that it is easily understandable. (Either US English or UK English spelling conventions are acceptable.)</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">ArXiv/Archive Policy:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">In accordance with ACM guidelines, all SIGMM-sponsored conferences adhere to the following policy regarding arXiv papers:</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">We define a publication as a written piece documenting scientific work that was submitted for review by peers for either acceptance or rejection, and, after review, has been accepted.</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">Documentation of scientific work that is published in a not-for-profit archive without any form of peer-review (departmental Technical Report, arXiv.org, etc.) is <b>not</b> considered a publication.</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc="">However, this definition of publication does include peer-reviewed workshop papers, even if they do not appear in formal proceedings. Any submission to ACM Multimedia must not have substantial overlap with prior publications or other work currently undergoing peer review anywhere.</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Note that documents published on website archives are subject to change. Citing such documents is discouraged. Furthermore, ACM Multimedia will review the documents formally submitted and any additional information in a web archive version will not affect the review.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="secondaryTitle el-col el-col-24"><p data-v-c73391dc=""><span style="color:black">Rebuttal Policies:</span></p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">After receiving the reviews, the authors may optionally submit a rebuttal to address the reviewers' comments. The rebuttal is limited to a One page PDF file using the <a class="demo-link" href="/files/template-for-rebuttal-acmmm24.zip">rebuttal template</a>. Responses longer than one page will simply not be reviewed. This includes responses where the margins and formatting are deemed to have been significantly altered from those specified by the style guide (deleting the title to get some space is acceptable).</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">The rebuttal must maintain anonymity. It cannot include links to external material such as code, videos, etc.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">Authors may optionally contact the Author’s Advocate, whose role is to listen to the authors, and to help them if reviews are clearly below average quality. The Author’s Advocate operates independently from the Technical Program Committee.</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="primaryTitle el-row"><div data-v-c73391dc="" class="el-col el-col-2"><img data-v-c73391dc="" src="/img/bullet_point.ec17d8ed.png" alt="" class="icon"></div><div data-v-c73391dc="" class="el-col el-col-22"><p data-v-c73391dc="" class="title">Contacts</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><p data-v-c73391dc="" class="demo-text">For any questions, please contact the Technical Program Chairs: <a class="demo-link" href="mailto:acmmm2024pc@gmail.com"> &lt;acmmm2024pc@gmail.com&gt;</a>:</p></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc=""><b>Ramanathan Subramanian</b>, University of Canberra, Australia</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc=""><b>Vivek K. Singh</b>, Rutgers University, USA</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc=""><b>Lexing Xie</b> , Australian National University, Australia</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc=""><b>Pablo Cesar</b> , Centrum Wiskunde &amp; Informatica, Netherlands</div></li></div></div></div><div data-v-c73391dc=""><div data-v-c73391dc="" class="el-row"><div data-v-c73391dc="" class="el-col el-col-24"><li data-v-c73391dc="" class="noList"><div data-v-c73391dc=""><b>Liang Zheng</b> , Australian National University, Australia</div></li></div></div></div></div></div><div data-v-1a17618c="" class="el-col el-col-24 el-col-xs-2 el-col-sm-2 el-col-md-2 el-col-lg-4 el-col-xl-6"><div data-v-1a17618c="" class="grid-content"></div></div></div><div data-v-1a17618c="" class="footer el-row"><div data-v-1a17618c="" class="el-col el-col-24"><div data-v-1505acee="" data-v-1a17618c=""><div data-v-1505acee="" class="acmfooter_top el-row"><p data-v-1505acee=""> Sponsors: </p><div data-v-1505acee="" class="el-col el-col-8"><div data-v-1505acee="" class="sponsors"><img data-v-1505acee="" src="/img/Melbourne_Convention_Bureau_logo.a8c745d2.png" alt="Sponsors" class="sponsorImage"></div></div><div data-v-1505acee="" class="el-col el-col-8"><div data-v-1505acee="" class="sponsors"><img data-v-1505acee="" src="/img/business_event_aus.337f3faa.png" alt="Sponsors" class="sponsorImage"></div></div><div data-v-1505acee="" class="el-col el-col-8"><div data-v-1505acee="" class="sponsors"><img data-v-1505acee="" src="/img/Victorian_State_Government_logo.c92740cc.png" alt="Sponsors" class="sponsorImage"></div></div></div><div data-v-1505acee="" class="acmfooter_bottom el-row"><div data-v-1505acee="" class="el-col el-col-24"><p data-v-1505acee="">© ACM Multimedia 2024</p></div></div></div></div></div></div></div><script src="/js/chunk-vendors.eeb61fec.js"></script><script src="/js/app.91b1967e.js"></script></body></html>